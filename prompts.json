{
  "source": "Prompts",
  "generated_at": "2024-02-12T13:43:50+00:00",
  "count": 160,
  "prompts": [
    {
      "path": "Prompts/Business Analysis/Churn reduction from customer data and exit survey analysis.md",
      "title": "Churn reduction from customer data and exit survey analysis",
      "category": "Business Analysis",
      "tags": [
        "pm",
        "business-analysis",
        "churn",
        "retention",
        "analytics"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{CHURN_DATA}}\n- {{EXIT_SURVEY_RESPONSES}}\n- {{ACTIVE_CUSTOMERS_BY_PERIOD_COHORT}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Churn reduction from customer data and exit survey analysis.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Follow these task requirements:\n<task_requirements>\n- Use only evidence from `CHURN_DATA`, `EXIT_SURVEY_RESPONSES`, and `ACTIVE_CUSTOMERS_BY_PERIOD_COHORT`; if data is missing, state assumptions explicitly.\n- Use these metric definitions:\n  - Customer churn rate = `churned_customers_in_period / active_customers_start`.\n  - MRR churn rate = `churned_mrr_in_period_usd / active_mrr_start_usd`.\n  - \"Average customer lifetime\" must be labeled as `churned-user tenure proxy` unless full customer lifecycle data is provided.\n- Compute churn rate using denominator data from `ACTIVE_CUSTOMERS_BY_PERIOD_COHORT`; include overall and cohort-level rates when possible.\n- If denominator data is insufficient for any requested slice, state \"not computable for this slice\" and use explicit proxy metrics (churn events, churned MRR) for that slice.\n- Analyze both quantitative patterns (rate, lifetime, segment/time trends) and qualitative churn reasons (theme categories from exits).\n- Prioritize interventions by estimated impact x feasibility.\n- Include short-term (0-30 days), medium-term (31-90 days), and long-term (90+ days) actions.\n- Every recommendation must trace to a specific churn reason or segment pattern.\n- For each prioritized key insight, provide at least one specific strategy.\n- If churned-user sample counts in `CHURN_DATA`/`EXIT_SURVEY_RESPONSES` differ from denominator totals in `ACTIVE_CUSTOMERS_BY_PERIOD_COHORT`, explicitly disclose the mismatch and treat sample-derived insights as directional.\n- Do not add impact estimates from overlapping cohorts (e.g., `incident_exposed` and `price_change_seen`) as if independent; call out overlap risk.\n- Do not give generic advice without a data link.\n</task_requirements>\n\nFORMAT\nReturn exactly this structure:\n\n<churn_reduction_plan>\n1. Data Analysis Summary\n- Current churn rate (overall + by key period/cohort), churned-user tenure proxy, and relevant baseline metrics\n- Denominator coverage check (which churn rates are computable vs not computable)\n- Sample alignment check (sample sizes, coverage, and mismatch disclosure if present)\n- Churned-user profile patterns (segments, behavior, timing)\n- Exit-survey theme breakdown with frequency or relative weight\n\n2. Key Insights (3-5, prioritized)\n- Insight title\n- Evidence (data points/themes supporting it)\n- Why it matters for churn reduction\n\n3. Targeted Strategies\n- Linked insight:\n- Issue to solve:\n- Action plan:\n- Time horizon: Short-term | Medium-term | Long-term\n- Owner suggestion:\n- Success metrics (leading + lagging):\n- Expected effect on churn:\n\n4. Monitoring and Adjustment\n- Review cadence\n- Instrumentation and dashboard checks\n- Decision rules for doubling down, iterating, or stopping actions\n\n5. Expected Impact\n- Estimated churn reduction range using scenario bands: Conservative | Base | Aggressive\n- Time to observe impact\n- Key assumptions and risks\n</churn_reduction_plan>\n\nFAILURE\n- Output misses required sections, steps, or reasoning required by `<task_requirements>`.\n- Required format/schema is missing, malformed, or incomplete.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Business Analysis/Customer journey map based on user behavior data.md",
      "title": "Customer journey map based on user behavior data",
      "category": "Business Analysis",
      "tags": [
        "pm",
        "business-analysis",
        "customer-journey",
        "analytics",
        "research"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{USER_BEHAVIOR_DATA}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Customer journey map based on user behavior data.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Follow these task requirements:\n<task_requirements>\n- Identify stages in chronological order and include key touchpoints + decision moments per stage.\n- Quantify time spent per stage; if unavailable, provide an estimate and label it as an assumption.\n- Highlight friction points and delight points with supporting signals/metrics where available.\n- Map emotional states to interactions using observed behavior, sentiment, or explicit feedback signals.\n- Include corresponding metrics per stage (for example: conversion, engagement, abandonment, CSAT/NPS, retention proxies).\n- Keep insights specific and actionable.\n</task_requirements>\n\nFORMAT\nReturn exactly this structure:\n\n<journey_map>\n<stage>\n<name>[Stage Name]</name>\n<touchpoints>[List key touchpoints and decision moments]</touchpoints>\n<time_spent>[Average time spent]</time_spent>\n<friction_points>[Identified friction points]</friction_points>\n<delight_points>[Identified delight points]</delight_points>\n<emotional_state>[Inferred emotional state]</emotional_state>\n<metrics>[Relevant metrics with values]</metrics>\n</stage>\n[Repeat the <stage> structure for each identified stage in the journey]\n</journey_map>\n\n<summary>\n[Brief summary of key insights, notable trends, major pain points, and opportunity areas]\n</summary>\n\nFAILURE\n- Output misses required sections, steps, or reasoning required by `<task_requirements>`.\n- Required format/schema is missing, malformed, or incomplete.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Business Analysis/Defining the niche from user input.md",
      "title": "Defining the niche from user input",
      "category": "Business Analysis",
      "tags": [
        "pm",
        "business-analysis",
        "positioning",
        "segmentation",
        "niche"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{USER_INPUT}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Defining the niche from user input.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Follow these task requirements:\n<task_requirements>\n- Analyze input for: audience demographics, interests/behaviors, geography/context, product/service attributes, and unique value points.\n- Each niche must combine multiple dimensions (at least 3 of: demographics, interests, geography/context, use case, value driver).\n- Avoid broad segments; each niche should be narrow enough to target with specific messaging.\n- Do not invent unrelated industries, audiences, or value propositions not implied by `USER_INPUT`.\n- Ensure all 10 niches are materially different from each other.\n</task_requirements>\n\nFORMAT\nReturn exactly this structure:\n\n<niche_definitions>\n<analysis_summary>\n[Brief synthesis of key input signals used to define niches]\n</analysis_summary>\n1. <niche>[Highly specific niche definition]</niche>\n2. <niche>[Highly specific niche definition]</niche>\n3. <niche>[Highly specific niche definition]</niche>\n4. <niche>[Highly specific niche definition]</niche>\n5. <niche>[Highly specific niche definition]</niche>\n6. <niche>[Highly specific niche definition]</niche>\n7. <niche>[Highly specific niche definition]</niche>\n8. <niche>[Highly specific niche definition]</niche>\n9. <niche>[Highly specific niche definition]</niche>\n10. <niche>[Highly specific niche definition]</niche>\n</niche_definitions>\n\nFAILURE\n- Output misses required sections, steps, or reasoning required by `<task_requirements>`.\n- Required format/schema is missing, malformed, or incomplete.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Business Analysis/Event tracking schemas from UI and metrics requirements.md",
      "title": "Event tracking schemas from UI and metrics requirements",
      "category": "Business Analysis",
      "tags": [
        "pm",
        "business-analysis",
        "analytics",
        "event-tracking",
        "metrics"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{UI_DESCRIPTION}}\n- {{METRICS_AND_BEHAVIORS}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Event tracking schemas from UI and metrics requirements.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Follow these task requirements:\n<task_requirements>\n- Identify key interactive UI elements and user actions implied by `UI_DESCRIPTION`.\n- Map each proposed event to one or more items in `METRICS_AND_BEHAVIORS`.\n- For each event, include only high-value properties needed for analysis and decision-making.\n- Avoid duplicate or redundant events that measure the same action at the same granularity.\n- Use descriptive, implementation-ready event names and property descriptions.\n</task_requirements>\n\nFORMAT\nReturn exactly this structure:\n\n<event_tracking_proposal>\n<event>\n<name>[Event Name]</name>\n<trigger>[When the event should be triggered]</trigger>\n<schema>\n- property1: [description]\n- property2: [description]\n- ...\n</schema>\n<justification>[Brief explanation of why this event and its properties are important for the given metrics/behaviors]</justification>\n</event>\n[Repeat for each proposed event]\n</event_tracking_proposal>\n\nFAILURE\n- Output misses required sections, steps, or reasoning required by `<task_requirements>`.\n- Required format/schema is missing, malformed, or incomplete.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Business Analysis/Feature impact models from KPIs and assumptions.md",
      "title": "Feature impact models from KPIs and assumptions",
      "category": "Business Analysis",
      "tags": [
        "pm",
        "business-analysis",
        "financial-modeling",
        "kpi-impact"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{FEATURE_INFO}}\n- {{KPIS_TO_ESTIMATE}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Feature impact models from KPIs and assumptions.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Follow these task requirements:\n<task_requirements>\n- Build a procedural task list that covers:\n  - key assumptions,\n  - baseline metric calculations,\n  - per-KPI impact estimation,\n  - sensitivity analysis.\n- Execute the tasks and show calculations step by step using explicit formulas/equations.\n- For each KPI, provide:\n  - point estimate,\n  - assumptions and calculations used,\n  - brief explanation of feature-to-KPI impact mechanism.\n- If information is missing, state what is missing, add a reasonable assumption, label it clearly, and proceed.\n- Prioritize transparent math and reasoning over spreadsheet-like verbosity.\n- Keep conclusions focused on executive decision-making (investment impact, major drivers, key risks).\n</task_requirements>\n\nFORMAT\nReturn exactly this structure:\n\n<impact_size_model>\n<procedural_tasks>\n[List the procedural tasks used to build the model]\n</procedural_tasks>\n\n<calculations_and_assumptions>\n[Step-by-step calculations, formulas, assumptions, and point estimates for each KPI]\n</calculations_and_assumptions>\n\n<summary>\n[Feature overview, KPI estimate table/list, key assumptions, sensitivity-analysis takeaways, and executive conclusions]\n</summary>\n</impact_size_model>\n\nFAILURE\n- Output misses required sections, steps, or reasoning required by `<task_requirements>`.\n- Required format/schema is missing, malformed, or incomplete.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Business Analysis/Feature results analysis from draft to final report.md",
      "title": "\"Feature results analysis from draft to final report\"",
      "category": "\"Business Analysis\"",
      "tags": [
        "pm",
        "business-analysis",
        "experimentation",
        "ab-testing",
        "analysis",
        "reporting"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{FRW_DRAFT}}\n</provided_inputs>\n\nGOAL\nEvaluate an FRW draft rigorously and produce both prioritized feedback and a stronger rewritten FRW with placeholders where data is missing.\nSuccess metric:\n- Feedback identifies critical analytical and reporting issues in priority order.\n- Rewritten FRW demonstrates sound experimentation logic, statistical interpretation, and business relevance.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Follow these task requirements:\n<task_requirements>\n- Review `FRW_DRAFT` thoroughly for:\n  - statistical validity/significance claims,\n  - methodology clarity/completeness,\n  - interpretation quality,\n  - alignment to business goals,\n  - potential bias/confounding factors,\n  - actionability and decision-readiness,\n  - structure and narrative flow.\n- Provide prioritized feedback (highest-risk issues first), including:\n  - strengths,\n  - issues and improvements,\n  - additional metrics/data recommendations,\n  - presentation/communication improvements,\n  - stronger conclusion/recommendation guidance.\n- Rewrite the FRW with placeholders where data is absent.\n- In the rewrite, include at minimum:\n  - experiment context/objective,\n  - methodology and guardrails,\n  - results with statistical interpretation,\n  - business impact interpretation,\n  - risks/limitations,\n  - recommendations and next actions.\n- Mark assumptions and placeholders explicitly (e.g., `[ASSUMPTION]`, `[PLACEHOLDER_METRIC]`).\n</task_requirements>\n\nFORMAT\nReturn exactly this structure:\n\n<Feedback>\n[Detailed, prioritized feedback with clear subheadings]\n</Feedback>\n<Rewritten_FRW>\n[Complete rewritten FRW using placeholders and explicit assumptions where needed]\n</Rewritten_FRW>\n\nFAILURE\n- Output misses required sections, steps, or reasoning required by `<task_requirements>`.\n- Required format/schema is missing, malformed, or incomplete.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Business Analysis/Metric drops diagnosis with rigorous stepwise decomposition.md",
      "title": "Metric drops diagnosis with rigorous stepwise decomposition",
      "category": "Business Analysis",
      "tags": [
        "pm",
        "business-analysis",
        "analytics",
        "metrics",
        "diagnosis"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{METRIC_NAME}}\n- {{FORMULA}}\n- {{BASELINE_VALUE}}\n- {{CURRENT_VALUE}}\n- {{TIMEFRAME}}\n- {{COMPARISON_WINDOWS}}\n- {{DATA_SOURCES}}\n- {{SEGMENT_DIMENSIONS}}\n- {{KNOWN_EVENTS}}\n</provided_inputs>\n\nGOAL\nDiagnose the root cause of a metric drop using stepwise decomposition from metric-level to driver-level to segment-level causes.\nSuccess metric:\n- Identifies whether the drop is real vs artifact.\n- Isolates top driver(s), break timing, and highest-impact segment(s).\n- Produces 1-3 testable hypotheses with confirm/refute criteria and next actions.\n- Follows the required output structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Analyze in this exact sequence:\n  1. Confirm drop validity (artifact checks).\n  2. Decompose metric into 2-3 drivers from formula.\n  3. Trend drivers to find break timing/pattern.\n  4. Segment culprit driver and rank impact.\n  5. Compare bad vs stable segments.\n  6. Produce 1-3 ranked, testable hypotheses.\n- For each subproblem include:\n  - Goal\n  - Method (queries/breakdowns/plots)\n  - Decision rule\n  - Findings\n  - Next step\n- Use explicit calculations where possible (delta or contribution attribution).\n- If SQL schema is incomplete, provide minimal-field request plus pseudocode with placeholders.\n- Always label confidence (`High`, `Med`, `Low`) and all assumptions.\n- Do not stop at symptom-level statements; identify driver, segment, break date, and likely causal mechanism.\n\nFORMAT\nReturn exactly this structure:\n\n<metric_drop_diagnosis>\n<subproblem_1>\n[Goal, method, decision rule, findings, next step]\n[Include table: period -> metric -> numerator/denominator -> data quality signals]\n[Verdict: Real drop | Measurement artifact | Baseline skew]\n</subproblem_1>\n<subproblem_2>\n[Driver tree]\n[Driver table: driver -> baseline -> current -> % change -> contribution]\n[Top culprit driver(s)]\n</subproblem_2>\n<subproblem_3>\n[Break-date analysis by driver: break date, pattern (step/gradual), confidence]\n[Candidate correlates from KNOWN_EVENTS]\n</subproblem_3>\n<subproblem_4>\n[Impact-ranked segment table: segment -> baseline -> current -> delta -> volume share -> impact score]\n[Largest contributing segment or broad-based note]\n</subproblem_4>\n<subproblem_5>\n[Side-by-side comparison of bad vs stable segments]\n[3-5 discriminative differences with numbers]\n</subproblem_5>\n<subproblem_6>\n[1-3 ranked hypotheses]\nHypothesis:\nEvidence so far:\nPrediction:\nTest:\nConfirm if:\nRefute if:\nOwner/next action:\n</subproblem_6>\n<recommended_next_actions>[Immediate mitigations, next data pulls, experiments/rollbacks]</recommended_next_actions>\n</metric_drop_diagnosis>\n\nFAILURE\n- Any required subproblem section is missing or out of sequence.\n- Output lacks methods/decision rules/findings/next-step per subproblem.\n- No driver decomposition or no impact-ranked segmentation.\n- Hypotheses are not testable (missing confirm/refute criteria).\n- Claims are generic or not grounded in provided inputs.\n- Assumptions or confidence labels are missing.\n- Required schema is malformed or incomplete."
    },
    {
      "path": "Prompts/Business Analysis/NPS feedback for prioritized customer experience initiatives.md",
      "title": "NPS feedback for prioritized customer experience initiatives",
      "category": "Business Analysis",
      "tags": [
        "pm",
        "business-analysis",
        "nps",
        "customer-experience",
        "prioritization"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{NPS_FEEDBACK}}\n</provided_inputs>\n\nGOAL\nTranslate `NPS_FEEDBACK` into a prioritized initiative backlog that reduces detractor pain and amplifies promoter value.\nSuccess metric:\n- Separates detractors (0-6) and promoters (9-10) correctly.\n- Identifies top recurring themes with evidence (frequency + representative quote).\n- Produces prioritized initiatives with transparent scoring and clear ownership-ready descriptions.\n- Follows the required output structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Treat only scores `0-6` as detractors and `9-10` as promoters; ignore or label neutral scores (`7-8`) if present.\n- Identify top 5 detractor pain themes and top 5 promoter benefit themes from recurring signals.\n- For each theme, include:\n  - short theme label,\n  - brief description,\n  - frequency signal (count or relative frequency),\n  - at least one representative quote.\n- For each proposed initiative, provide a `Priority Score` from `1-5` based on:\n  - Frequency (how often theme appears),\n  - Impact (customer experience importance),\n  - Feasibility (implementation realism).\n- Keep initiatives concrete and implementation-ready (avoid generic statements).\n\nFORMAT\nReturn exactly this structure:\n\n<output>\n<theme_analysis>\n<detractor_themes>\n1. [Theme]\n   - Description: [Brief description]\n   - Frequency: [Count or relative frequency]\n   - Representative Quote: \"[Quote]\"\n[Repeat to top 5]\n</detractor_themes>\n<promoter_themes>\n1. [Theme]\n   - Description: [Brief description]\n   - Frequency: [Count or relative frequency]\n   - Representative Quote: \"[Quote]\"\n[Repeat to top 5]\n</promoter_themes>\n</theme_analysis>\n\n<detractor_initiatives>\n1. [Initiative Name] (Priority Score: X)  \n   - Description: [Brief description of the initiative]  \n   - Addresses: [Pain point being addressed]  \n   - Scoring Rationale: [Frequency / Impact / Feasibility rationale]\n   - Representative Quote: \"[Direct quote from feedback]\"\n\n[Repeat for top 3-5 detractor initiatives]\n</detractor_initiatives>\n\n<promoter_initiatives>\n1. [Initiative Name] (Priority Score: X)  \n   - Description: [Brief description of the initiative]  \n   - Amplifies: [Benefit being amplified]  \n   - Scoring Rationale: [Frequency / Impact / Feasibility rationale]\n   - Representative Quote: \"[Direct quote from feedback]\"\n\n[Repeat for top 3-5 promoter initiatives]\n</promoter_initiatives>\n\n<summary>\n[Provide a brief summary of the key findings and the potential impact of implementing these initiatives]\n</summary>\n</output>\n\nFAILURE\n- Detractor/promoter segmentation is incorrect or not shown.\n- Theme analysis is missing top recurring themes, frequencies, or quotes.\n- Initiatives are missing priority scores or scoring rationale.\n- Recommendations are generic or not linked to identified themes.\n- Required schema is missing, malformed, or incomplete.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Business Analysis/Onboarding flow optimization from product data to user success.md",
      "title": "Onboarding flow optimization from product data to user success",
      "category": "Business Analysis",
      "tags": [
        "pm",
        "onboarding",
        "growth",
        "user-success",
        "business-analysis"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{PRODUCT_DESCRIPTION}}\n- {{TARGET_AUDIENCE}}\n- {{CURRENT_ONBOARDING_PROCESS}}\n</provided_inputs>\n\nGOAL\nDesign an actionable onboarding optimization plan that moves users from initial state to first meaningful success faster and more reliably.\nSuccess metric:\n- Clearly defines user transformation and first meaningful success step.\n- Maps desired outcomes to current blockers and practical small-win interventions.\n- Proposes progress/momentum mechanics that can be directly used in a PRD or design brief.\n- Follows the required output schema exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, section logic, or actionable recommendation details.\n- Keep recommendations grounded in `PRODUCT_DESCRIPTION`, `TARGET_AUDIENCE`, and `CURRENT_ONBOARDING_PROCESS`.\n- Perform this sequence:\n  1. Define transformation:\n     - user before state,\n     - user after state,\n     - smallest step to experience meaningful progress.\n  2. Map dream to reality:\n     - desired end state,\n     - current blockers,\n     - confidence-building small wins.\n  3. Design progress (not just features):\n     - visible progress signals,\n     - small-win celebrations,\n     - obvious next-step mechanics,\n     - momentum loops.\n- Recommendations must be concrete enough to be implemented in a PRD/design brief.\n- Explicitly label assumptions where data/process detail is missing.\n\nFORMAT\nReturn exactly this structure:\n\n<onboarding_improvement_plan>\n<transformation_definition>\n[Your analysis and recommendations for step 1]\n</transformation_definition>\n\n<dream_to_reality_mapping>\n[Your analysis and recommendations for step 2]\n</dream_to_reality_mapping>\n\n<progress_design>\n[Your analysis and recommendations for step 3]\n</progress_design>\n\n<conclusion>\n[Summarize the key points of your improvement plan and highlight the most impactful changes]\n</conclusion>\n</onboarding_improvement_plan>\n\nFAILURE\n- Required schema is missing, malformed, or incomplete.\n- Any of the 3 core steps (transformation, dream-to-reality mapping, progress design) is missing or shallow.\n- Recommendations are generic, not tied to provided product/audience/process context.\n- Output lacks concrete actions suitable for a PRD/design brief.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Business Analysis/PRDs from industry and feature specifications.md",
      "title": "PRDs from industry and feature specifications",
      "category": "Business Analysis",
      "tags": [
        "pm",
        "prd",
        "requirements",
        "documentation",
        "business-analysis"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{INDUSTRY}}\n- {{COMPANY_NAME}}\n- {{FEATURE_NAME}}\n- {{DEVELOPMENT_STAGE}}\n- {{CURRENT_KNOWLEDGE}}\n- {{CURRENT_SOLUTION}}\n</provided_inputs>\n\nGOAL\nCreate a complete, implementation-ready PRD for `FEATURE_NAME` in the specified `INDUSTRY` and `DEVELOPMENT_STAGE`.\nSuccess metric:\n- Covers all required PRD sections with actionable detail.\n- Aligns recommendations to current stage, known constraints, and existing solution context.\n- Uses explicit assumptions where information is missing.\n- Follows the required output structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip any required PRD section.\n- Ground requirements in `CURRENT_KNOWLEDGE` and `CURRENT_SOLUTION`; do not contradict provided context without explicit rationale.\n- Use the exact PRD heading/table structure specified in `FORMAT`.\n- Keep requirements testable and implementation-oriented where possible.\n- Maintain a professional, industry-appropriate tone.\n\nFORMAT\nReturn exactly this structure:\n\n<PRD>\n# [Product Name]\n\n## About\n[High-level overview of the product and goal.]\n\n## Market Insights\n[Market context, competitors, trends, and target users.]\n\n## Problem\n[Core user problem, pain points, and why existing solutions are insufficient.]\n\n## Solution\n[Proposed AI product solution and how it addresses the problem.]\n\n## Feature Prioritization\n| Feature | Reach | Impact | Confidence | Effort | RICE Score | Priority |\n|---------|-------|--------|------------|--------|------------|----------|\n|  |  |  |  |  |  |  |\n|  |  |  |  |  |  |  |\n|  |  |  |  |  |  |  |\n\n## Requirements\n**Functional Requirements:**\n- FR1:\n- FR2:\n- FR3:\n\n**AI/ML Model Requirements:**\n- MR1:\n- MR2:\n- MR3:\n\n**Non-Functional Requirements:**\n- NFR1:\n- NFR2:\n- NFR3:\n\n## Challenges\n[Key product, technical, data, and go-to-market challenges.]\n\n## Positioning\n| Use Case | Target User | Key Benefit | Differentiator |\n|----------|-------------|-------------|----------------|\n|  |  |  |  |\n|  |  |  |  |\n|  |  |  |  |\n\n## Metrics\n[Success metrics and north star metric.]\n\n## Rollout Plan\n- **Stakeholders & Communication**\n  - [Stakeholder groups and communication plan]\n\n- **Roll-out Strategy**\n  - [Launch phases, gating criteria, and post-GA plan]\n</PRD>\n\nFAILURE\n- Any required section/table/list item pattern from `FORMAT` is missing or materially incomplete.\n- Content is generic and not grounded in provided inputs.\n- Requirements are not actionable/testable.\n- Development-stage alignment is missing.\n- Required output schema is missing or malformed."
    },
    {
      "path": "Prompts/Business Analysis/PRDs from product information and assumptions.md",
      "title": "PRDs from product information and assumptions",
      "category": "Business Analysis",
      "tags": [
        "pm",
        "business-analysis",
        "prd",
        "requirements",
        "documentation",
        "impact-sizing"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{PRD_KNOWN_INFORMATION}}\n</provided_inputs>\n\nGOAL\nDraft a complete PRD from `PRD_KNOWN_INFORMATION`, using explicit assumptions where information is missing.\nSuccess metric:\n- Covers all required PRD sections in actionable detail.\n- Includes clear metrics and impact sizing logic with transparent assumptions.\n- Produces focused follow-up questions for critical unknowns.\n- Follows the required output structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Use the exact PRD heading/table structure specified in `FORMAT`.\n- Start from known information, then extend with clearly labeled assumptions.\n- Keep language precise, unambiguous, and implementation-oriented for design/engineering stakeholders.\n- Ensure metrics are measurable and prioritization logic is explicit.\n- Keep non-goals and risks explicit to reduce scope ambiguity.\n- Use markdown-friendly structure inside the PRD for readability.\n- Output follow-up questions only for meaningful unknowns that affect decision quality.\n\nFORMAT\nReturn exactly this structure:\n\n<PRD>\n# [Product Name]\n\n## About\n[High-level overview of the product and goal.]\n\n## Market Insights\n[Market context, competitors, trends, and target users.]\n\n## Problem\n[Core user problem, pain points, and why existing solutions are insufficient.]\n\n## Solution\n[Proposed AI product solution and how it addresses the problem.]\n\n## Feature Prioritization\n| Feature | Reach | Impact | Confidence | Effort | RICE Score | Priority |\n|---------|-------|--------|------------|--------|------------|----------|\n|  |  |  |  |  |  |  |\n|  |  |  |  |  |  |  |\n|  |  |  |  |  |  |  |\n\n## Requirements\n**Functional Requirements:**\n- FR1:\n- FR2:\n- FR3:\n\n**AI/ML Model Requirements:**\n- MR1:\n- MR2:\n- MR3:\n\n**Non-Functional Requirements:**\n- NFR1:\n- NFR2:\n- NFR3:\n\n## Challenges\n[Key product, technical, data, and go-to-market challenges.]\n\n## Positioning\n| Use Case | Target User | Key Benefit | Differentiator |\n|----------|-------------|-------------|----------------|\n|  |  |  |  |\n|  |  |  |  |\n|  |  |  |  |\n\n## Metrics\n[Success metrics and north star metric.]\n\n## Rollout Plan\n- **Stakeholders & Communication**\n  - [Stakeholder groups and communication plan]\n\n- **Roll-out Strategy**\n  - [Launch phases, gating criteria, and post-GA plan]\n</PRD>\n<QUESTIONS>\n[Follow-up questions for major assumptions, missing information, or high-risk unknowns]\n</QUESTIONS>\n\nFAILURE\n- Any required section/table/list item pattern from `FORMAT` is missing or materially incomplete.\n- Metrics/prioritization are vague, unquantified, or unsupported.\n- Content is generic or not grounded in provided inputs.\n- Required output schema (`<PRD>`, `<QUESTIONS>`) is missing or malformed.\n- Major unknowns, dependencies, or assumption-sensitive decisions are not captured in `<QUESTIONS>`."
    },
    {
      "path": "Prompts/Business Analysis/Post-launch feedback into v2 improvements.md",
      "title": "Post-launch feedback into v2 improvements synthesis",
      "category": "Business Analysis",
      "tags": [
        "pm",
        "business-analysis",
        "iteration",
        "roadmap",
        "feedback"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{FEEDBACK_SOURCES}}\n- {{ANALYTICS_DATA}}\n- {{SUPPORT_TICKETS}}\n- {{USER_INTERVIEWS}}\n- {{PRODUCT_VISION}}\n</provided_inputs>\n\nGOAL\nSynthesize post-launch signals into a defensible, prioritized v2 improvement plan and phased roadmap.\nSuccess metric:\n- Identifies cross-source themes with evidence and impact framing.\n- Produces explicit prioritization logic and concrete improvement definitions.\n- Delivers a sequenced roadmap with validation and monitoring plans.\n- Follows the required output schema exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Use all inputs as evidence sources (`FEEDBACK_SOURCES`, `ANALYTICS_DATA`, `SUPPORT_TICKETS`, `USER_INTERVIEWS`, `PRODUCT_VISION`).\n- Synthesize cross-source themes; do not rely on a single source for prioritization.\n- Prioritize with explicit criteria at minimum: frequency, severity, reach, business impact, strategic alignment, effort, confidence.\n- Use a defensible scoring approach (RICE, ICE, MoSCoW, or explicit custom model) and state the choice.\n- For each prioritized theme, define concrete v2 improvements with user impact, solution, success criteria, dependencies, risks, and validation plan.\n- Build a phased roadmap (critical fixes, high-impact, polish, future) with timeline, metrics, and go/no-go criteria.\n- Include pre-launch and post-launch validation/monitoring loops.\n- Keep recommendations actionable and explicitly linked to evidence.\n- Explicitly call out assumptions when source quality or coverage is incomplete.\n\nFORMAT\nReturn exactly this structure:\n\n<v2_improvement_plan>\n<executive_summary>\n**Feedback Volume:** [Total pieces of feedback analyzed across all sources]\n\n**Time Period:** [When was feedback collected? e.g., \"30 days post-launch\" or \"Q1 2024\"]\n\n**Top 3 Themes:**\n1. [Theme]: [Brief description] - [X% of feedback mentions this]\n2. [Theme]: [Brief description] - [Y% of feedback mentions this]\n3. [Theme]: [Brief description] - [Z% of feedback mentions this]\n\n**Recommended v2 Focus:**\n[High-level strategy: e.g., \"Prioritize onboarding improvements and performance fixes to reduce churn, defer advanced features to v3\"]\n\n**Expected Impact:**\n[What will improve if we execute this plan? e.g., \"Reduce drop-off during signup by 30%, increase feature adoption by 20%, reduce support tickets by 40%\"]\n</executive_summary>\n\n<feedback_analysis>\n<source_breakdown>\n## Analytics Data\n\n**Key Findings:**\n- [Metric]: [Value] - [Interpretation]\n- [Drop-off point]: [X% abandon] - [Hypothesis why]\n- [Underused feature]: [Y% adoption] - [Why low?]\n- [Performance issue]: [Average load time Z seconds] - [Impact]\n\n**Patterns Observed:**\n[Describe usage patterns, unexpected behaviors, segment differences]\n\n**Critical Metrics:**\n- Activation rate: [X%]\n- Retention (D7/D30): [Y%/Z%]\n- Feature adoption: [List top and bottom features]\n- Error rate: [N per session]\n\n---\n\n## Support Tickets\n\n**Volume:** [Total tickets in period]\n\n**Top 5 Issues:**\n1. [Issue]: [N tickets, X% of total] - [Severity]\n2. [Issue]: [N tickets, Y% of total] - [Severity]\n3. [Issue]: [N tickets, Z% of total] - [Severity]\n4. [Issue]: [N tickets] - [Severity]\n5. [Issue]: [N tickets] - [Severity]\n\n**Average Resolution Time:** [Hours/days]\n\n**Escalations:** [How many required engineering/product involvement?]\n\n**Workarounds:** [What are support agents telling users to do?]\n\n---\n\n## User Interviews\n\n**Participants:** [N users, describe demographics/segments]\n\n**Key Quotes:**\n- \"[Direct quote about pain point]\" - [User type]\n- \"[Direct quote about unmet need]\" - [User type]\n- \"[Direct quote about competitor comparison]\" - [User type]\n\n**Jobs-to-be-done:**\n[What are users trying to accomplish with the product?]\n\n**Unmet Needs:**\n[What can't users do today that they wish they could?]\n\n**Surprises:**\n[Unexpected learnings about how users think about the product]\n\n---\n\n## App Store / Reviews\n\n**Average Rating:** [X.X stars]  \n**Total Reviews:** [N]\n\n**Rating Distribution:**\n- 5 star: [X%]\n- 4 star: [Y%]\n- 3 star: [Z%]\n- 2 star: [W%]\n- 1 star: [V%]\n\n**Common Themes in Reviews:**\n- Positive: [What users love]\n- Negative: [What users hate]\n- Feature requests: [What users ask for]\n\n**Competitor Mentions:**\n[How are users comparing to alternatives?]\n\n---\n\n## Sales/Customer Success Feedback\n\n**Deal Blockers:** [Features missing that prevent sales]\n\n**Churn Reasons:** [Why are users leaving?]\n\n**Feature Parity Gaps:** [What do competitors have that we don't?]\n\n**Implementation Challenges:** [What makes onboarding difficult?]\n\n---\n\n## Internal Stakeholder Input\n\n**Engineering Concerns:**\n[Technical debt, scalability issues, maintenance burden]\n\n**Design Concerns:**\n[Design debt, inconsistent patterns, accessibility gaps]\n\n**Operations Concerns:**\n[Support burden, deployment challenges, monitoring gaps]\n\n**Business Concerns:**\n[Revenue impact, competitive threats, strategic misalignment]\n</source_breakdown>\n\n<thematic_clustering>\nFor each identified theme, provide:\n\n## Theme 1: [Theme Name]\n\n**Description:** [What is this theme about?]\n\n**Frequency:** [X mentions across Y sources]\n\n**Affected Users:** [What % of users? Which segments?]\n\n**Severity:** [Critical/High/Medium/Low - how much does this hurt?]\n\n**Sources:**\n- Analytics: [Specific data points]\n- Support: [N tickets, common complaints]\n- Interviews: [Key quotes or findings]\n- Reviews: [Rating impact, common mentions]\n\n**User Impact:**\n[Describe how this affects users' ability to accomplish their goals]\n\n**Business Impact:**\n[Effect on key metrics: conversion, retention, revenue, NPS, support costs]\n\n**Current Workarounds:**\n[How are users coping with this problem today?]\n\n**Root Cause Hypothesis:**\n[Why does this problem exist? Design flaw? Technical limitation? Missing feature?]\n\n---\n\n[Repeat for Theme 2, Theme 3, etc.]\n\n</thematic_clustering>\n\n<prioritization_analysis>\n<scoring_framework>\n**Framework Used:** [RICE / ICE / MoSCoW / Custom]\n\n**Scoring Criteria:**\n- [Criterion 1]: [How we measure it]\n- [Criterion 2]: [How we measure it]\n- [Criterion 3]: [How we measure it]\n- [Criterion 4]: [How we measure it]\n\n**Thresholds for Prioritization:**\n- Must-fix: [Score > X or meets Y criteria]\n- High priority: [Score > Z]\n- Medium priority: [Score > W]\n- Low priority / Defer: [Score < W]\n</scoring_framework>\n\n<prioritized_themes>\nRank themes by priority with clear rationale:\n\n**Priority 1: [Theme Name]**\n- Score: [Numeric score if using framework]\n- Rationale: [Why this is top priority - combine frequency, severity, business impact, strategic fit]\n- Reach: [X% of users affected]\n- Impact: [Expected improvement in key metric]\n- Confidence: [How sure are we this is the right priority?]\n- Effort: [Estimated work - S/M/L/XL]\n- ROI: [High/Medium/Low]\n\n**Priority 2: [Theme Name]**\n[Same structure]\n\n**Priority 3: [Theme Name]**\n[Same structure]\n\n---\n\n**Deferred Themes:**\n[Themes that didn't make the cut and why - e.g., \"Low frequency, high effort, doesn't align with strategic direction\"]\n</prioritized_themes>\n</prioritization_analysis>\n\n<v2_improvements>\nFor each high-priority theme, define specific improvements:\n\n## Improvement 1: [Name]\n\n**Addresses Theme:** [Theme name]\n\n**Problem Statement:**\n[Clear description of what's broken and why it matters]\n\n**User Impact:**\n- **Who:** [User segment(s) affected]\n- **How:** [How does this problem hurt them?]\n- **Frequency:** [How often do they encounter this?]\n\n**Proposed Solution:**\n[Describe what you'll build/fix/improve - be specific but not prescriptive about implementation]\n\n**User Stories:**\n1. As a [user type], I want [capability], so that [benefit]\n   - Acceptance criteria: [Specific, testable requirements]\n2. [Additional user stories as needed]\n\n**Success Criteria:**\n[How will we know this improvement worked?]\n- Metric: [Specific metric] improves from [current] to [target]\n- User feedback: [Qualitative signal - e.g., \"Support tickets about X decrease by 50%\"]\n- Adoption: [Y% of users use this feature within 30 days]\n\n**Design Requirements:**\n- [Specific UX/UI needs]\n- [Accessibility requirements]\n- [Responsive behavior]\n- [Error states and edge cases to handle]\n\n**Technical Requirements:**\n- [API changes]\n- [Database schema updates]\n- [Performance targets - e.g., \"Load in <200ms\"]\n- [Third-party integrations]\n- [Security considerations]\n\n**Dependencies:**\n[What needs to happen before this can be built?]\n\n**Risks:**\n- [What could go wrong?]\n- [How will we mitigate?]\n\n**Effort Estimate:** [S/M/L/XL or sprint count]\n\n**Priority:** [Must-have / Should-have / Could-have]\n\n**Validation Plan:**\n[How will we test this before launch?]\n- User testing: [With whom, testing what?]\n- A/B test: [Control vs. variant, success metric]\n- Beta: [Rollout to X% of users for Y days]\n\n---\n\n[Repeat for Improvement 2, 3, etc.]\n\n</v2_improvements>\n\n<v2_roadmap>\n<phase_1_critical_fixes>\n**Timeline:** [Weeks or months]\n\n**Goal:** [What must be fixed before anything else?]\n\n**Improvements Included:**\n1. [Improvement name]: [One-line description] - [Effort] - [Impact on metric]\n2. [Improvement name]: [One-line description] - [Effort] - [Impact on metric]\n\n**Success Metrics:**\n- [Metric]: Improve from [X] to [Y]\n- [Metric]: Reduce [problem] by [Z%]\n\n**Go/No-Go Criteria:**\n[What must be true to move to Phase 2?]\n\n**Risks:**\n[What could delay or derail Phase 1?]\n</phase_1_critical_fixes>\n\n<phase_2_high_impact>\n**Timeline:** [Weeks or months after Phase 1]\n\n**Goal:** [What strategic improvements drive key metrics?]\n\n**Improvements Included:**\n1. [Improvement name]: [One-line description] - [Effort] - [Impact on metric]\n2. [Improvement name]: [One-line description] - [Effort] - [Impact on metric]\n\n**Success Metrics:**\n- [Metric]: Improve from [X] to [Y]\n\n**Go/No-Go Criteria:**\n[What must be true to move to Phase 3?]\n\n**Risks:**\n[What could delay or derail Phase 2?]\n</phase_2_high_impact>\n\n<phase_3_polish>\n**Timeline:** [Weeks or months after Phase 2]\n\n**Goal:** [What delights users and differentiates from competitors?]\n\n**Improvements Included:**\n1. [Improvement name]: [One-line description] - [Effort] - [Impact on metric]\n2. [Improvement name]: [One-line description] - [Effort] - [Impact on metric]\n\n**Success Metrics:**\n- [Metric]: Improve from [X] to [Y]\n- User sentiment: [NPS or satisfaction score improvement]\n\n**Go/No-Go Criteria:**\n[What must be true to consider v2 complete?]\n</phase_3_polish>\n\n<phase_4_future>\n**Timeline:** [Post-v2, v3 timeframe]\n\n**Goal:** [What longer-term bets are worth exploring?]\n\n**Improvements Under Consideration:**\n1. [Improvement name]: [Why deferred - needs more research, high uncertainty, strategic pivot]\n2. [Improvement name]: [Why deferred]\n\n**Research Needed:**\n[What questions must be answered before prioritizing these?]\n</phase_4_future>\n\n<resource_requirements>\n**Team Needed:**\n- Engineering: [X people for Y weeks/months]\n- Design: [X people for Y weeks/months]\n- Product: [X people for Y weeks/months]\n- QA: [X people for Y weeks/months]\n- Other: [Content, legal, ops, etc.]\n\n**Total Effort Estimate:** [Person-months or sprint count]\n\n**Target Launch Date:** [When will v2 ship?]\n\n**Milestones:**\n- [Date]: Phase 1 complete\n- [Date]: Phase 2 complete\n- [Date]: Phase 3 complete\n- [Date]: v2 launch\n\n**Budget Considerations:**\n[Any costs beyond team time - infrastructure, tools, licensing, contractors]\n</resource_requirements>\n</v2_roadmap>\n\n<validation_and_monitoring>\n<pre_launch_validation>\n**User Testing:**\n- Participants: [N users from segments X, Y, Z]\n- Testing: [Prototypes, beta builds, specific workflows]\n- Success criteria: [Task completion rate >X%, satisfaction score >Y]\n\n**A/B Testing Plan:**\n- Control: [Current experience]\n- Variant: [New v2 improvements]\n- Rollout: [Gradual - 5% → 25% → 50% → 100%]\n- Primary metric: [What are we optimizing for?]\n- Secondary metrics: [What else are we tracking?]\n- Duration: [How long to run test?]\n- Decision criteria: [What result causes us to ship/rollback?]\n\n**Beta Program:**\n- Participants: [N users, selection criteria]\n- Duration: [X weeks before public launch]\n- Feedback collection: [Surveys, interviews, in-app prompts]\n- Success criteria: [What feedback validates we're ready to launch?]\n</pre_launch_validation>\n\n<post_launch_monitoring>\n**Week 1 Monitoring:**\n- Track: [Key metrics daily]\n- Alert on: [Regressions, errors, drop-offs]\n- Review: Daily standups to assess impact\n\n**Week 2-4 Monitoring:**\n- Track: [Key metrics weekly]\n- Review: Weekly summaries of adoption, satisfaction, support tickets\n\n**Month 2-3 Monitoring:**\n- Deep dive: Did we achieve success criteria?\n- User feedback: Survey users who adopted v2 features\n- Support analysis: Did tickets decrease as expected?\n\n**Success Criteria Review:**\n- [Metric]: Target was [X], achieved [Y] - [Met/Missed/Exceeded]\n- [Metric]: Target was [A], achieved [B] - [Met/Missed/Exceeded]\n\n**Learnings:**\n[What worked? What didn't? What would we do differently for v3?]\n</post_launch_monitoring>\n\n<iteration_plan>\n**Feedback Loops:**\n- User interviews: [Every X weeks with Y users]\n- Analytics review: [Weekly/monthly cadence]\n- Support ticket analysis: [Weekly summaries]\n- NPS surveys: [Quarterly]\n\n**v3 Planning:**\n[When will we start gathering feedback for the next iteration?]\n</iteration_plan>\n</validation_and_monitoring>\n</v2_improvement_plan>\n\nFAILURE\n- Any required top-level section in `FORMAT` is missing or malformed.\n- Output does not use cross-source evidence for themes and prioritization.\n- Prioritization lacks clear scoring logic or rationale.\n- Improvements are vague, non-actionable, or not tied to user/business impact.\n- Roadmap phases are missing sequencing, success metrics, or go/no-go criteria.\n- Validation/monitoring plans are missing or superficial.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Business Analysis/Post-launch feedback loop.md",
      "title": "Post-launch feedback loop",
      "category": "Business Analysis",
      "tags": [
        "pm",
        "feedback-loop",
        "iteration",
        "post-launch",
        "continuous-improvement",
        "business-analysis"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{CURRENT_PROCESS}}\n- {{PRODUCT_CONTEXT}}\n- {{LAUNCH_TIMELINE}}\n- {{TEAM_STRUCTURE}}\n- {{AVAILABLE_DATA_SOURCES}}\n</provided_inputs>\n\nGOAL\nDesign a complete post-launch feedback loop system that turns product signals into prioritized iteration decisions.\nSuccess metric:\n- Defines checkpoint cadence with clear purpose and decision outputs.\n- Specifies what to measure, how to synthesize signals, and how to prioritize action.\n- Connects learnings to roadmap iteration and team operating rituals.\n- Follows the required schema exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Keep recommendations grounded in `CURRENT_PROCESS`, `PRODUCT_CONTEXT`, `LAUNCH_TIMELINE`, `TEAM_STRUCTURE`, and `AVAILABLE_DATA_SOURCES`.\n- Do not skip required analysis layers:\n  - Current-state audit (gaps, latency, silos)\n  - Time-based checkpoints (week 1, month 1, month 3, month 6, month 12)\n  - Measurement framework (quantitative, qualitative, behavioral, technical)\n  - Retrospective and learning capture process\n  - Iteration planning integration and triage model\n- For each checkpoint, define:\n  - key questions,\n  - data sources,\n  - success criteria,\n  - review meeting structure and outputs.\n- Include both leading and lagging indicators with definitions, targets, source systems, and review cadence.\n- Ensure triage rules are operational (SLA, owner, scoring logic, planning window).\n\nFORMAT\nReturn exactly this structure:\n\n<feedback_loop_framework>\n<current_state_assessment>\n[Existing feedback mechanisms, identified gaps, latency issues, and organizational silos/blockers]\n</current_state_assessment>\n\n<checkpoint_calendar>\n<week_1_checkpoint>[Timeline, primary focus, key questions, data sources, success criteria, meeting/review details]</week_1_checkpoint>\n<month_1_checkpoint>[Timeline, primary focus, key questions, data sources, success criteria, meeting/review details]</month_1_checkpoint>\n<month_3_checkpoint>[Timeline, primary focus, key questions, data sources, success criteria, meeting/review details]</month_3_checkpoint>\n<month_6_checkpoint>[Timeline, primary focus, key questions, data sources, success criteria, meeting/review details]</month_6_checkpoint>\n<month_12_checkpoint>[Timeline, primary focus, key questions, data sources, success criteria, meeting/review details]</month_12_checkpoint>\n</checkpoint_calendar>\n\n<measurement_framework>\n<quantitative_metrics>\n[Leading indicators table/list + lagging indicators table/list + technical health indicators with definition, target, source, frequency]\n</quantitative_metrics>\n<qualitative_insights>\n[User research schedule, support analysis method, sales/marketing feedback integration cadence]\n</qualitative_insights>\n<behavioral_monitoring>\n[Unexpected pattern detection, workaround identification, feature misuse tracking]\n</behavioral_monitoring>\n</measurement_framework>\n\n<retrospective_process>\n<template>\n[Structured template covering goals/hypotheses, validated and invalidated assumptions, surprises, key learnings, user quotes, quantitative highlights, recommendations]\n</template>\n<documentation_location>[Where learnings are stored and how they are indexed/retrieved]</documentation_location>\n<review_meeting_structure>[Attendees, duration, pre-work, agenda, outputs]</review_meeting_structure>\n</retrospective_process>\n\n<iteration_planning_integration>\n<triage_framework>\n**Critical Issues (Address Immediately):**\n- Definition: [What qualifies]\n- Response time: [SLA]\n- Decision maker: [Who can approve]\n\n**High Priority (Next Sprint):**\n- Definition: [What qualifies]\n- Scoring formula: [How prioritized]\n- Review cadence: [How often re-evaluated]\n\n**Medium Priority (Next Quarter):**\n- Definition: [What qualifies]\n- Planning cycle: [When incorporated into roadmap]\n\n**Low Priority (Backlog):**\n- Definition: [What qualifies]\n- Archive criteria: [When to deprioritize]\n</triage_framework>\n</iteration_planning_integration>\n</feedback_loop_framework>\n\nFAILURE\n- Any required top-level section is missing or malformed.\n- Checkpoint plan lacks timeline, data sources, success criteria, or decision outputs.\n- Measurement framework lacks explicit metrics, definitions, or cadence.\n- Triage/iteration process is vague or non-operational.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Business Analysis/Product feature impact sizing from metrics and usage data.md",
      "title": "Product feature impact sizing from metrics and usage data",
      "category": "Business Analysis",
      "tags": [
        "pm",
        "business-analysis",
        "impact-sizing",
        "metrics",
        "analytics"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{PRODUCT_FEATURE}}\n- {{METRICS}}\n</provided_inputs>\n\nGOAL\nEstimate the potential impact of `PRODUCT_FEATURE` using `METRICS` with transparent assumptions, calculations, and sensitivity ranges.\nSuccess metric:\n- Builds a usage funnel from exposure to actual usage.\n- Quantifies engagement, top-line, and bottom-line effects with explicit math.\n- Identifies weakest assumptions and proposes de-risk actions plus scenarios.\n- Follows the required output structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis stages:\n  1. Usage funnel estimation (exposed -> activated -> used).\n  2. Impact quantification (engagement, top-line, bottom-line).\n  3. Risk/assumption analysis (weakest assumptions, de-risk methods, scenarios).\n  4. Strategic takeaways and recommendations.\n- Show formulas and intermediate calculations; avoid unsupported point estimates.\n- Include assumptions next to each major calculation.\n- Keep outputs concrete and grounded in provided metrics/context.\n\nFORMAT\nReturn exactly this structure:\n\n<analysis>\n<introduction>[Brief role/task framing]</introduction>\n<usage_funnel>[Exposure-to-usage funnel with assumptions and drop-off reasoning]</usage_funnel>\n<impact_calculations>\n<engagement>[DAU/MAU/retention impact estimates with formulas]</engagement>\n<top_line>[GMV/revenue impact estimates with formulas]</top_line>\n<bottom_line>[Contribution margin/net income impact estimates with formulas]</bottom_line>\n</impact_calculations>\n<assumption_risk_and_scenarios>[Riskiest assumptions, de-risk plan, conservative/base/aggressive scenarios]</assumption_risk_and_scenarios>\n<takeaways>[Implications for planning, experimentation, and feature design]</takeaways>\n</analysis>\n\nFAILURE\n- Any required section in `FORMAT` is missing or malformed.\n- Impact estimates are provided without formulas/intermediate reasoning.\n- Usage funnel is missing or does not connect exposure to actual usage.\n- No sensitivity scenarios or no de-risk actions for weak assumptions.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Business Analysis/Product simplification via Via Negativa analysis.md",
      "title": "Product simplification via Via Negativa analysis",
      "category": "Business Analysis",
      "tags": [
        "pm",
        "business-analysis",
        "simplification",
        "via-negativa",
        "strategy"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{INPUT}}\n</provided_inputs>\n\nGOAL\nApply Via Negativa to simplify `INPUT` by removing non-essential elements while preserving core purpose and functional integrity.\nSuccess metric:\n- Clearly defines core purpose.\n- Identifies non-essential elements with rationale, benefits of removal, and tradeoffs.\n- Produces a simplified version that remains aligned to the core purpose.\n- Follows the required output structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required reasoning steps:\n  1. Identify core purpose.\n  2. Enumerate major elements/components.\n  3. Test each element for necessity, value, replaceability, and complexity cost.\n  4. Select removals/simplifications that preserve purpose.\n  5. Evaluate downside risks of each removal.\n- Keep recommendations concrete and grounded in provided input details.\n- Prefer removal/simplification over additive fixes.\n- Explicitly label assumptions when input details are ambiguous.\n\nFORMAT\nReturn exactly this structure:\n\n<via_negativa_analysis>\n<core_purpose>\nBriefly state the identified core purpose or main objective of the input.\n</core_purpose>\n\n<non_essential_elements>\nList the elements you've identified as non-essential, explaining for each:\n- Why it's considered non-essential\n- How removing it could benefit the overall input\n- Any potential drawbacks of its removal\n</non_essential_elements>\n\n<simplified_version>\nProvide a simplified version of the input, focusing only on the essential elements that directly contribute to the core purpose.\n</simplified_version>\n\n<conclusion>\nSummarize how the simplified version aligns better with the principles of Via Negativa and how it improves upon the original input in terms of clarity, efficiency, and focus.\n</conclusion>\n</via_negativa_analysis>\n\nFAILURE\n- Any required schema section is missing or malformed.\n- Non-essential elements are listed without rationale, benefit, and drawback analysis.\n- Simplified version changes core purpose or omits critical essentials.\n- Claims are generic or not grounded in provided input.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Business Analysis/SQL queries from requirements and data tables.md",
      "title": "SQL query from requirements and data tables",
      "category": "Business Analysis",
      "tags": [
        "pm",
        "sql",
        "analytics",
        "data",
        "business-analysis"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{DATA_TABLES_OVERVIEW}}\n- {{QUERY_CRAFTING_REQUIREMENTS}}\n</provided_inputs>\n\nGOAL\nProduce a correct, performant, and maintainable SQL query from `DATA_TABLES_OVERVIEW` and `QUERY_CRAFTING_REQUIREMENTS`.\nSuccess metric:\n- SQL satisfies requirements and uses valid joins/filters/aggregations.\n- Query is optimized for readability and execution efficiency.\n- Major logic choices and assumptions are clearly explained.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required SQL design steps:\n  - relevant table joins,\n  - filter conditions,\n  - aggregations/calculations,\n  - subqueries/CTEs where helpful.\n- Prefer explicit selected columns (avoid `SELECT *` unless explicitly required).\n- Use meaningful aliases and readable formatting.\n- Add concise inline comments only for non-obvious logic.\n- Include assumptions when schema or requirements are ambiguous.\n- If requirements are under-specified, produce best-effort SQL and state what data/constraints would finalize it.\n- Default policy for ambiguities (apply unless `QUERY_CRAFTING_REQUIREMENTS` explicitly overrides):\n  - **Top-5 rule:** return exactly 5 rows per month using `ROW_NUMBER()` with deterministic tie-break (`ORDER BY net_revenue_usd DESC, category ASC`).\n  - **Multi-category revenue attribution:** allocate order revenue proportionally by category share of item extended value (`quantity * unit_price`) within each order; do not attribute full order revenue to every category.\n  - **Payment-attempt attribution by category:** attribute payment attempts/failures to each category touched by an order (order-category level attribution), and explicitly disclose that summed category-level counts can exceed overall totals.\n  - **Payment time scope:** when reporting period filters are defined for orders, filter payment attempts to the same period using `payments.attempted_at` unless explicitly instructed otherwise.\n- SQL must be executable with standard ASCII SQL syntax:\n  - Use `'single quotes'` for string literals.\n  - Use `--` for line comments.\n  - Do not use typographic quotes/dashes or other smart punctuation.\n- Keep explanation plain text (no unusual control characters, copy artifacts, or decorative bullets).\n- If metrics are attributed to multiple categories (for multi-category orders), explicitly state that totals across categories may exceed overall order/payment totals.\n\nFORMAT\nReturn exactly this structure:\n\n<sql_query>\n-- SQL query with formatting and comments\n</sql_query>\n<query_explanation>\n- Join strategy and why each join type is used\n- Filter logic and business-rule mapping\n- Aggregations/calculations rationale\n- Performance considerations (indexes, cardinality, scan reduction, CTE/subquery choices)\n- Assumptions and known limitations\n</query_explanation>\n\nFAILURE\n- Missing `<sql_query>` or `<query_explanation>` section.\n- SQL does not match stated requirements.\n- Uses `SELECT *` without explicit requirement.\n- Join/filter/aggregation logic is unclear or unsupported in explanation.\n- SQL contains non-ASCII smart punctuation that breaks execution (e.g., `‘ ’`, `“ ”`, `–`).\n- Explanation contains copy artifacts or unreadable formatting.\n- Output violates default ambiguity policies (top-5 cardinality, revenue attribution, payment attribution, or payment time scope) without explicit requirement override.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Business Analysis/Structured requirements from conversation transcripts.md",
      "title": "Structured requirements from conversation transcripts",
      "category": "Business Analysis",
      "tags": [
        "pm",
        "business-analysis",
        "requirements",
        "analysis",
        "transcripts"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{CONVERSATION_TRANSCRIPT}}\n- {{CONTEXT}}\n</provided_inputs>\n\nGOAL\nConvert `CONVERSATION_TRANSCRIPT` (+ `CONTEXT`) into a MECE-structured requirements set, then provide a rigorous self-critique of extraction quality.\nSuccess metric:\n- Requirements are clear, actionable, and grouped with MECE logic.\n- Each requirement is source-traceable and includes dependency/relationship notes where relevant.\n- Self-criticism identifies weaknesses without proposing solutions.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip these analysis steps:\n  1. Identify explicit requests, constraints, concerns, and implied needs.\n  2. Organize requirements into MECE categories / issue-tree logic.\n  3. Write requirements in precise, actionable language.\n  4. Annotate source traceability and dependency relationships.\n- Keep language unambiguous and implementation-relevant without over-specifying design/engineering internals.\n- In self-criticism, identify issues only; do not propose fixes.\n- Explicitly label assumptions inferred from context.\n\nFORMAT\nReturn exactly this structure:\n\n<requirements_analysis>\n<executive_summary>[Main themes and scope]</executive_summary>\n<requirements_categories>[MECE categories and issue-tree structure]</requirements_categories>\n<individual_requirements>[Numbered requirements per category with source/dependency notes]</individual_requirements>\n<dependencies_and_relationships>[Cross-references between requirements]</dependencies_and_relationships>\n<assumptions>[Implied assumptions not explicitly stated in transcript]</assumptions>\n</requirements_analysis>\n<self_criticism>\n<inconsistencies>[List only]</inconsistencies>\n<contradictions>[List only]</contradictions>\n<over_specification>[List only]</over_specification>\n<under_specification>[List only]</under_specification>\n<missing_elements>[List only]</missing_elements>\n<scope_creep>[List only]</scope_creep>\n</self_criticism>\n\nFAILURE\n- Any required schema section is missing or malformed.\n- Requirements are generic, non-actionable, or not traceable to transcript/context.\n- MECE structure is absent or internally overlapping/confusing.\n- Self-criticism includes solution proposals instead of issue identification only.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Business Analysis/Structured requirements from design assets.md",
      "title": "\"Structured requirements from design assets\"",
      "category": "\"Business Analysis\"",
      "tags": [
        "pm",
        "business-analysis",
        "requirements",
        "design"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{IMAGE}}\n</provided_inputs>\n\nGOAL\nTranslate `IMAGE` design assets into actionable, testable product requirements and acceptance criteria.\nSuccess metric:\n- Produces clear, numbered user stories/requirements covering key flows and behaviors shown or implied in the design.\n- Provides detailed acceptance criteria mapped to each requirement.\n- Keeps requirements implementation-agnostic (focus on \"what\", not \"how\").\n- Follows the required output schema exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip analysis of visual structure, information hierarchy, interactions, states, and implied business rules.\n- Number each requirement/story and keep it measurable and implementation-agnostic.\n- Acceptance criteria must map to requirements explicitly (by requirement number/id).\n- Include inferred assumptions only when necessary and label them clearly.\n- Do not include internal reasoning tags like `<scratchpad>` in final output.\n\nFORMAT\nReturn exactly this structure:\n\n<requirements>\n<user_stories>\n[List numbered user stories or requirements here]\n</user_stories>\n\n<acceptance_criteria>\n[List detailed acceptance criteria for each user story or requirement here]\n</acceptance_criteria>\n</requirements>\n\nFAILURE\n- Required schema is missing or malformed.\n- Requirements are generic, non-measurable, or not grounded in the design asset.\n- Acceptance criteria are missing, vague, or not mapped to requirements.\n- Output contains implementation-detail overreach instead of product requirements.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Business Analysis/Success metrics for design decisions.md",
      "title": "Success metrics for design decisions",
      "category": "Business Analysis",
      "tags": [
        "pm",
        "success-metrics",
        "business-analysis",
        "design"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{DESIGN_GOALS}}\n- {{PRODUCT_CONTEXT}}\n- {{USER_OUTCOMES}}\n</provided_inputs>\n\nGOAL\nTranslate `DESIGN_GOALS`, `PRODUCT_CONTEXT`, and `USER_OUTCOMES` into a measurable success-metrics system for design decisions.\nSuccess metric:\n- Defines success from user, business, and product perspectives.\n- Produces primary/secondary/guardrail/leading metrics with SMART definitions.\n- Includes instrumentation, baseline/target logic, and decision-ready analysis plan.\n- Follows the required output structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required metric-design steps:\n  1. Define success (user/business/product).\n  2. Map metric types (behavior, outcome, business, quality, leading).\n  3. Apply SMART criteria to each key metric.\n  4. Define measurement approach (instrumentation, tools, sample/stat criteria).\n  5. Set baselines and targets (minimum, target, stretch, timeframe).\n  6. Add guardrails for unintended consequences.\n- Keep metrics decision-oriented and linked to design goals (avoid vanity metrics).\n- Explicitly note risks/limitations where metrics may not capture full reality.\n- Label assumptions clearly when baseline/tooling/sample data is incomplete.\n\nFORMAT\nReturn exactly this structure:\n\n<success_metrics_framework>\n<success_definitions>\n**User Success Means:**\n[Describe what improves from user perspective - concrete outcomes]\n\n**Business Success Means:**\n[Describe what improves from business perspective - concrete outcomes]\n\n**Product Success Means:**\n[Describe what improves in the product - concrete outcomes]\n</success_definitions>\n\n<primary_metrics>\n<metric_1>\n**Metric Name:** [Clear, specific metric name]\n\n**What It Measures:** [Exactly what behavior or outcome]\n\n**Why It Matters:** [How it connects to goals]\n\n**Type:** [Behavior/Outcome/Business/Quality]\n\n**Measurement Method:**\n- How: [Specific tracking approach]\n- Where: [What system/tool]\n- Frequency: [How often measured]\n- Sample: [Who/what is included]\n\n**Current Baseline:** [If known, current performance]\n\n**Targets:**\n- Minimum acceptable: [X%/number]\n- Target: [Y%/number]\n- Stretch: [Z%/number]\n- Timeframe: [When to measure]\n\n**Statistical Criteria:**\n- Sample size needed: [N users/sessions]\n- Significance level: [e.g., 95% confidence]\n- Minimum detectable effect: [smallest meaningful change]\n\n**Risks/Limitations:**\n[What could make this metric misleading? What doesn't it capture?]\n</metric_1>\n\n<metric_2>\n[Repeat structure for 3-5 primary metrics]\n</metric_2>\n</primary_metrics>\n\n<supporting_metrics>\n[List 3-5 secondary metrics that provide additional context:\n- Metric name: [Description, why it's useful]\n- Metric name: [Description, why it's useful]]\n</supporting_metrics>\n\n<guardrail_metrics>\n[Metrics to ensure you're not causing harm:\n- Metric: [Description]\n- Threshold: [What value would indicate a problem]\n- Why: [What unintended consequence this guards against]]\n</guardrail_metrics>\n\n<leading_indicators>\n[Metrics that predict success before primary metrics show results:\n- Indicator: [Description]\n- Why it predicts success: [Connection to outcomes]\n- When to measure: [Timeline]]\n</leading_indicators>\n\n<measurement_plan>\n**Implementation Requirements:**\n- Events to track: [List specific events]\n- Properties to capture: [Data points per event]\n- Tools needed: [Analytics platform, A/B test framework, survey tool, etc.]\n- Team dependencies: [Who needs to implement]\n- Timeline: [When instrumentation will be ready]\n\n**Analysis Plan:**\n- Segments to analyze: [User cohorts, use cases, etc.]\n- Comparison approach: [A/B test, before/after, cohort comparison]\n- Reporting cadence: [Daily/Weekly/Monthly]\n- Decision timeline: [When to make go/no-go decision]\n\n**Baseline Collection:**\n[If redesign, describe how to establish current state before changes]\n</measurement_plan>\n\n<tradeoff_framework>\n[How to make decisions when metrics conflict:\n- If [Metric A] improves but [Metric B] declines, prioritize [A/B] because [rationale]\n- Acceptable tradeoffs: [What you're willing to sacrifice for what gain]\n- Unacceptable tradeoffs: [What must never decline]]\n</tradeoff_framework>\n\n<qualitative_validation>\n[How to supplement quantitative metrics:\n- User interviews: [What to ask]\n- Usability testing: [What to observe]\n- Support tickets: [What patterns to look for]\n- Feedback surveys: [What questions to include]]\n</qualitative_validation>\n\n<one_page_dashboard>\n[Describe what a single-page success dashboard should show:\n- Key metric tiles\n- Trend visualization\n- Segment breakdowns\n- Guardrail status\n- Action triggers]\n</one_page_dashboard>\n</success_metrics_framework>\n\nFAILURE\n- Any required schema section is missing or malformed.\n- Metrics are not SMART or not clearly tied to design goals/outcomes.\n- Baselines/targets/timeframes are missing for primary metrics.\n- Guardrail or leading indicators are missing.\n- Measurement plan lacks instrumentation detail or decision cadence.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Business Analysis/Support tickets as actionable product improvements.md",
      "title": "Support tickets as actionable product improvements",
      "category": "Business Analysis",
      "tags": [
        "pm",
        "business-analysis",
        "support",
        "product-improvements",
        "feedback"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{SUPPORT_TICKETS}}\n</provided_inputs>\n\nGOAL\nConvert `SUPPORT_TICKETS` into evidence-backed trends and a prioritized product-improvement backlog.\nSuccess metric:\n- Categorizes ticket themes with clear frequency/severity signals.\n- Identifies major recurring patterns and notable critical issues.\n- Produces prioritized improvements tied to explicit ticket evidence.\n- Follows the required output schema exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps:\n  1. Categorize tickets/issues.\n  2. Quantify category frequency.\n  3. Identify recurring themes and severe/unusual issues.\n  4. Detect pattern signals (cross-user, time-based, or correlated issues when available).\n  5. Prioritize improvements by frequency, severity/impact, and estimated effort.\n- Keep all claims grounded in provided support-ticket data.\n- Label assumptions if timestamps, severity labels, or effort signals are missing.\n\nFORMAT\nReturn exactly this structure:\n\n<trend_analysis>\n[3-5 major trends with evidence from support tickets, including category frequency and notable severe issues]\n</trend_analysis>\n\n<prioritized_improvements>\nList at least 5 prioritized improvements, ranked from highest to lowest priority. For each improvement:\n1. [Improvement Name]\n   - Description: Brief description of the improvement\n   - Justification: Explain why this improvement is important, citing specific trends or issues from the data\n   - Priority Drivers: Frequency / Severity / Effort rationale\n   - Potential Impact: Describe the expected positive impact on user experience\n</prioritized_improvements>\n\nFAILURE\n- Missing `<trend_analysis>` or `<prioritized_improvements>`.\n- Fewer than 5 prioritized improvements.\n- Prioritization is not supported by frequency/severity/effort reasoning.\n- Claims are generic or not grounded in provided ticket evidence.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Business Analysis/UX edge cases from product briefs.md",
      "title": "UX edge cases from product briefs",
      "category": "Business Analysis",
      "tags": [
        "pm",
        "ux",
        "design",
        "edge-cases",
        "business-analysis"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{PRODUCT_BRIEF}}\n</provided_inputs>\n\nGOAL\nIdentify UX edge cases from `PRODUCT_BRIEF` and define expected behavior for each scenario.\nSuccess metric:\n- Produces a comprehensive scenario set (target 15-20 unique scenarios).\n- Covers diverse user types, contexts, failures, accessibility, and security/privacy considerations.\n- Defines clear, testable expected behavior per scenario.\n- Follows the required output structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip scenario classes:\n  - user-type differences,\n  - context/device variations,\n  - error/misuse flows,\n  - system/network failures,\n  - integrations/dependencies,\n  - performance/load behavior,\n  - security/privacy edge cases,\n  - accessibility interactions.\n- Keep each scenario concrete and distinct (avoid duplicates).\n- Define expected behavior in product terms (clear response, recovery path, and user feedback when relevant).\n- If the brief is missing specifics, state assumptions explicitly.\n\nFORMAT\nReturn exactly this structure:\n\n<analysis>\nBased on the product brief, here are the potential scenarios and their expected behaviors:\n\n| Scenario | Expected Behavior |\n|----------|-------------------|\n| [Scenario 1] | [Expected Behavior 1] |\n| [Scenario 2] | [Expected Behavior 2] |\n| ... | ... |\n| [Scenario n] | [Expected Behavior n] |\n\n</analysis>\n\nFAILURE\n- Required schema is missing or malformed.\n- Fewer than 15 scenarios unless explicitly constrained by provided brief.\n- Scenario coverage is narrow (missing key classes like accessibility, failures, or security/privacy).\n- Expected behaviors are vague, non-testable, or not tied to scenario conditions.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Business Analysis/User stories from initiative requirements.md",
      "title": "User stories from initiative requirements",
      "category": "Business Analysis",
      "tags": [
        "pm",
        "user-stories",
        "requirements",
        "business-analysis"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{USER_STORY_TEMPLATE}}\n- {{INITIATIVE_CONTEXT}}\n- {{FUNCTIONALITY_DESCRIPTION}}\n</provided_inputs>\n\nGOAL\nBreak initiative functionality into clear, implementable user stories using `USER_STORY_TEMPLATE`, `INITIATIVE_CONTEXT`, and `FUNCTIONALITY_DESCRIPTION`.\nSuccess metric:\n- Produces separate stories for distinct functionality/interaction units.\n- Each story is self-contained, value-driven, and has testable acceptance criteria.\n- Story wording follows the provided template structure.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required workflow:\n  1. Read template, context, and functionality description.\n  2. Decompose functionality into distinct user-value units.\n  3. Draft one story per unit.\n  4. Add clear, testable acceptance criteria per story.\n- Follow `USER_STORY_TEMPLATE` exactly for each story.\n- Keep stories implementation-ready, user-value focused, and non-duplicative.\n- Ensure each story is atomic (single primary intent/outcome).\n- Include a brief summary of decomposition logic and key considerations.\n\nFORMAT\nReturn exactly this structure:\n\nHere are the user stories for the described initiative:\n1. <user_story>[User story 1 using the provided template, including clear acceptance criteria]</user_story>\n2. <user_story>[User story 2]</user_story>\n[Continue numbering for all required stories]\n<summary>[Brief summary of decomposition approach and key considerations]</summary>\n\nFAILURE\n- Missing required line header, missing numbered `<user_story>` list, or missing `<summary>`.\n- Stories do not follow the provided template structure.\n- Stories are vague, not testable, or not grounded in provided context/functionality.\n- Stories are duplicative or combine multiple primary intents into one.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Business Analysis/User stories with Gherkin acceptance criteria from requirements.md",
      "title": "User stories with Gherkin acceptance criteria from requirements",
      "category": "Business Analysis",
      "tags": [
        "pm",
        "user-stories",
        "gherkin",
        "requirements",
        "business-analysis"
      ],
      "content": "INPUTS\n<provided_inputs>\n- [No explicit variables declared; use provided context.]\n</provided_inputs>\n\nGOAL\nGenerate INVEST-compliant, atomic user stories with Gherkin acceptance criteria from provided requirements context.\nSuccess metric:\n- Produces one or more atomic user stories aligned to persona goals and constraints.\n- Each story includes deterministic happy-path and edge/negative Gherkin scenarios.\n- Includes traceability from requirements to stories and acceptance criteria.\n- Follows the required markdown output structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required steps:\n  1. Decompose requirements into distinct atomic outcomes.\n  2. Draft one story per outcome.\n  3. Add Gherkin acceptance criteria with one `When` and one `Then` in happy path.\n  4. Add at least one edge/negative scenario per story.\n  5. Complete notes and traceability mapping.\n- Stories must be INVEST-compliant and persona-aligned.\n- If a story would require multiple primary outcomes, split it or mark `SPLIT SUGGESTED`.\n- Keep language testable and implementation-neutral (unless a technical constraint is explicitly required).\n- Use `[TBD]` for critical missing info and surface it under Open Questions.\n\nFORMAT\nReturn exactly this structure:\n\n```md\nBacklog Context\n[Backlog Header Template fields filled]\n\nUser Story [ID-###]:\n[Use Case + Gherkin happy-path scenario + Gherkin edge/negative scenario]\nNotes\n[Non-Functional, Instrumentation, Dependencies, Out of Scope, Open Questions]\n\n[Repeat story blocks for each atomic outcome]\n\nTraceability Table\n[Requirement ID | Requirement Summary | Story ID(s) | AC Coverage Notes]\n\nValidation Checklist\n[All required checklist items]\n```\n\nFAILURE\n- Required markdown structure is missing or malformed.\n- Stories are non-atomic, non-INVEST, or not mapped to clear outcomes.\n- Happy-path scenario contains more than one `When` or more than one `Then` without `SPLIT SUGGESTED`.\n- Edge/negative scenario is missing for any story.\n- Traceability table or validation checklist is missing.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Decision Making/AI product evaluation from Recommendation Canvas framework.md",
      "title": "AI product evaluation from Recommendation Canvas framework",
      "category": "Decision Making",
      "tags": [
        "pm",
        "decision-making",
        "ai-product",
        "recommendation-canvas",
        "strategy"
      ],
      "content": "INPUTS\n<provided_inputs>\n- [No explicit variables declared; use provided context.]\n</provided_inputs>\n\nGOAL\nProduce a complete, executive-ready AI Recommendation Canvas for a specific problem/persona, plus improvement suggestions and a go/no-go decision.\nSuccess metric:\n- Canvas is coherent, measurable, and defensible across business outcome, product outcome, solution hypothesis, and success metrics.\n- Unknowns are explicitly marked; no invented facts.\n- Includes 3-5 concrete improvement suggestions and a clear go/no-go recommendation.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required workflow:\n  1. Gather/normalize available context and identify missing critical inputs.\n  2. Tighten outcomes into SMART form.\n  3. Build the canvas with explicit unknowns and assumptions.\n  4. Add 3-5 improvement suggestions.\n  5. Provide a go/no-go recommendation with rationale.\n- If multiple personas exist, choose one primary persona and note secondary impacts.\n- For regulated data, include compliance and data-minimization constraints.\n- For generative AI use cases, include safety/evaluation/abuse-monitoring considerations.\n- Distinguish risks to investigate (pre-decision) vs risks to monitor (post-decision).\n- Keep language concise, outcome-first, and metric-linked.\n- Do not invent facts; mark unknowns explicitly.\n\nFORMAT\nReturn exactly this structure:\n\n```md\n# AI Recommendation Canvas\n\n## Product Name\n- [Concise, memorable name]\n\n## Business Outcome\n- [Direction][Metric][Outcome][Context][Acceptance Criteria]\n\n## Product Outcome\n- [Direction][Metric][Outcome][Persona context][Acceptance]\n\n## The Problem Statement\n### Problem Statement Narrative\n- [Persona + context + constraints]\n- [2-3 sentence first-person narrative]\n\n## Solution Hypothesis\n### Hypothesis Statement\n- **If we** ...\n- **for** ...\n- **then we will** ...\n\n### Tiny Acts of Discovery (Experiments)\n- Viability: ...\n- Value: ...\n- Feasibility: ...\n- Safety: ...\n\n### Proof-of-Life (Success Criteria)\n- Quantitative: ...\n- Qualitative: ...\n- Operational: ...\n\n## Positioning Statement\n### Value Proposition\n**For** ...  \n**that need** ...  \n**[Product Name]** **is a** ...  \n**that** ...\n\n### Differentiation Statement\n**Unlike** ...  \n**[Product Name]** **provides** ...\n\n## Assumptions & Unknowns\n- ...\n\n## Issues/Risks to Investigate (PESTEL)\n- Political: ...\n- Economic: ...\n- Social: ...\n- Technological: ...\n- Environmental: ...\n- Legal: ...\n\n## Issues/Risks to Monitor (PESTEL)\n- Political: ...\n- Economic: ...\n- Social: ...\n- Technological: ...\n- Environmental: ...\n- Legal: ...\n\n## Value Justification\n### Is this Valuable?\n- [Absolutely yes / Yes with caveats / No with alternatives / Absolutely no]\n\n### Solution Justification (Executive-Ready)\n1. Financial Impact — ...\n2. Strategic Fit — ...\n3. Customer Value — ...\n4. Operational Feasibility — ...\n5. Risk Mitigation — ...\n\n## Success Metrics (SMART)\n1. Efficiency — ...\n2. Quality — ...\n3. Adoption — ...\n4. Financial — ...\n5. Safety — ...\n\n## What’s Next (Strategic Steps)\n1. Data Readiness — ...\n2. Prototype — ...\n3. Pilot — ...\n4. Scale — ...\n5. Governance — ...\n6. Commercialization — ...\n```\n\n<review>\n1. [Improvement suggestion]\n2. [Improvement suggestion]\n3. [Improvement suggestion]\n[Add 3-5 total]\n</review>\n\n<go_no_go_recommendation>\n[Go / No-Go / Go with conditions] - [Brief rationale tied to outcomes, feasibility, and risk]\n</go_no_go_recommendation>\n\nFAILURE\n- Canvas is not rendered as a single Markdown code block.\n- Required canvas sections are missing or materially incomplete.\n- Missing `<review>` section with 3-5 suggestions.\n- Missing `<go_no_go_recommendation>` section.\n- Claims are generic or not grounded in provided inputs.\n- Unknowns/assumptions are present but not explicitly marked."
    },
    {
      "path": "Prompts/Decision Making/Bug prioritization against work in progress.md",
      "title": "\"Bug prioritization against work in progress\"",
      "category": "\"Decision Making\"",
      "tags": [
        "pm",
        "decision-making",
        "prioritization",
        "bugs",
        "triage"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{BUG_DESCRIPTION}}\n- {{CURRENT_WORK}}\n- {{PLANNED_WORK}}\n</provided_inputs>\n\nGOAL\nDetermine whether a reported bug should take priority over current and planned work, then provide a triage decision.\nSuccess metric:\n- Provides clear reasoning and YES/NO decision for both prioritization questions.\n- Final decision is logically consistent with those two answers.\n- Uses only provided bug/current/planned work context.\n- Follows the required output schema exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip either required question:\n  1. Is this bug more important than current work?\n  2. Is this bug more important than planned next work?\n- For each question, include concise reasoning before the YES/NO answer.\n- Apply decision rule strictly:\n  - If both answers are `NO` -> `Do not prioritize fixing this bug now`.\n  - If either answer is `YES` -> `Proceed to further classification`.\n- Keep reasoning grounded in bug impact, user/business risk, and delivery tradeoffs from provided context.\n\nFORMAT\nReturn exactly this structure:\n\n<question1>\nReasoning: [Your reasoning here]\nAnswer: [YES/NO]\n</question1>\n\n<question2>\nReasoning: [Your reasoning here]\nAnswer: [YES/NO]\n</question2>\n\n<decision>\n[Your decision here: either \"Do not prioritize fixing this bug now\" or \"Proceed to further classification\"]\n</decision>\n\nFAILURE\n- Missing `<question1>`, `<question2>`, or `<decision>` section.\n- Missing reasoning or missing YES/NO answer for either question.\n- Final decision contradicts the required decision rule.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Decision Making/Complex problem structuring into actionable recommendations.md",
      "title": "\"Complex problem structuring into actionable recommendations\"",
      "category": "\"Decision Making\"",
      "tags": [
        "decision-making",
        "problem-structuring",
        "analysis",
        "consulting"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{PROBLEM_STATEMENT}}\n</provided_inputs>\n\nGOAL\nStructure a complex problem into a clear analysis and actionable recommendation.\nSuccess metric:\n- Produces a concise problem simplification with key issues/stakeholders.\n- Includes both deductive and inductive analysis streams.\n- Synthesizes insights into a concrete recommendation with rationale.\n- Follows the required output structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required steps:\n  1. Simplify the problem into core components and stakeholders.\n  2. Perform deductive analysis (top-down logic and option tree).\n  3. Perform inductive analysis (specific evidence/patterns/examples).\n  4. Synthesize both analyses (alignment/conflicts and key insight).\n  5. Recommend an actionable course of action.\n- Keep reasoning objective, explicit, and grounded in `PROBLEM_STATEMENT`.\n- Clearly label assumptions if evidence is incomplete.\n\nFORMAT\nReturn exactly this structure:\n\n<analysis>\n<simplified_problem>\n[Provide a concise summary of the simplified problem]\n</simplified_problem>\n\n<deductive_analysis>\n[Present your logical tree of options and ideas, including key considerations and potential outcomes]\n</deductive_analysis>\n\n<inductive_analysis>\n[Discuss specific examples, data points, or patterns you've identified and their implications]\n</inductive_analysis>\n\n<synthesis>\n[Explain how your deductive and inductive analyses complement or contrast with each other, and what overall insights they provide]\n</synthesis>\n\n<recommendation>\n[Clearly state your recommended course of action, explaining why it's the best approach based on your analysis]\n</recommendation>\n</analysis>\n\nFAILURE\n- Required schema is missing or malformed.\n- Any required analysis section is missing or materially incomplete.\n- Deductive and inductive analyses are not clearly distinguished.\n- Recommendation is generic or not supported by prior analysis.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Decision Making/Decision reversibility classification from first principles.md",
      "title": "\"Decision reversibility classification from first principles\"",
      "category": "\"Decision Making\"",
      "tags": [
        "pm",
        "decision-making",
        "reversibility",
        "first-principles",
        "frameworks"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{SITUATION}}\n- {{DECISION}}\n</provided_inputs>\n\nGOAL\nClassify a decision’s reversibility from first principles as `Hat`, `Haircut`, or `Tattoo`, with explicit reasoning.\nSuccess metric:\n- Evaluates immediate and long-term consequences.\n- Assesses reversal cost/time/resources and permanence.\n- Produces a defensible classification with confidence and rationale.\n- Follows the required output structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required dimensions:\n  1. Immediate consequences.\n  2. Long-term effects on stakeholders/environment.\n  3. Reversal effort/time/resource requirements.\n  4. Permanent or hard-to-undo changes.\n- Apply category definitions strictly:\n  - `Hat`: easily reversible; minimal lasting consequences.\n  - `Haircut`: reversible with meaningful but manageable cost/friction.\n  - `Tattoo`: largely irreversible or long-lasting structural impact.\n- Consider multiple plausible outcomes; avoid single-path reasoning.\n- Keep analysis neutral and grounded in `SITUATION` and `DECISION`.\n- Explicitly label assumptions where context is incomplete.\n\nFORMAT\nReturn exactly this structure:\n\n<analysis>\n<immediate_consequences>[Assessment]</immediate_consequences>\n<long_term_effects>[Assessment]</long_term_effects>\n<reversal_cost_and_feasibility>[Assessment of effort/time/resources]</reversal_cost_and_feasibility>\n<permanence_factors>[What becomes hard or impossible to undo]</permanence_factors>\n<synthesis>[How the above dimensions combine into a final judgment]</synthesis>\n</analysis>\n\n<categorization>\n[Hat | Haircut | Tattoo]\n</categorization>\n<confidence>\n[High | Medium | Low] - [Brief reason]\n</confidence>\n<reversal_path>\n[If reversible, concise path to reverse/mitigate; if tattoo, explain why reversal is impractical]\n</reversal_path>\n\nFAILURE\n- Required schema sections are missing or malformed.\n- Classification is provided without first-principles reasoning across required dimensions.\n- Category choice contradicts stated evidence.\n- Analysis is generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Decision Making/Decision-Making using the GUT CHECK protocol.md",
      "title": "Decision-making with the GUT CHECK protocol",
      "category": "Decision Making",
      "tags": [
        "decision-making",
        "self-reflection",
        "frameworks",
        "coaching"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{DECISION}}\n</provided_inputs>\n\nGOAL\nGuide the user through the full GUT CHECK protocol for `DECISION`, then provide a grounded recommendation.\nSuccess metric:\n- Covers all 8 GUT CHECK stages with relevant reflective questions.\n- Separates prompts/questions from interpretation clearly.\n- Provides a summary and final recommendation consistent with the surfaced signals.\n- Follows the required output structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Cover all 8 protocol stages:\n  1. Pause & Feel\n  2. Identify Pressures\n  3. Risk Assessment\n  4. Competency Check\n  5. Values Alignment\n  6. Timing Check\n  7. Red Flags\n  8. Final Gut Check\n- For each stage, provide concise reflection prompts tailored to `DECISION`.\n- Keep tone supportive, neutral, and non-judgmental.\n- If user responses are not available, mark insights as provisional and identify what responses are needed.\n- Include the pressure mantra and key protocol reminders.\n- Final recommendation must align with surfaced signals (not generic advice).\n\nFORMAT\nReturn exactly this structure:\n\n<gut_check_protocol>\n<pause_and_feel>[Stage-specific prompts]</pause_and_feel>\n<identify_pressures>[Stage-specific prompts]</identify_pressures>\n<risk_assessment>[Stage-specific prompts]</risk_assessment>\n<competency_check>[Stage-specific prompts]</competency_check>\n<values_alignment>[Stage-specific prompts]</values_alignment>\n<timing_check>[Stage-specific prompts]</timing_check>\n<red_flags>[Stage-specific prompts and pause rule]</red_flags>\n<final_gut_check>[Stage-specific prompts]</final_gut_check>\n<mantra>\"This is now. Whatever comes, I can handle it. Next step forward.\"</mantra>\n<protocol_reminders>[Key points about gut/hidden costs/alternate paths/well-being]</protocol_reminders>\n</gut_check_protocol>\n\n<summary>\n[Summary of user responses if provided; otherwise a provisional synthesis and missing-response checklist]\n</summary>\n\n<recommendation>\n[Provide a final recommendation based on the user's responses, explaining the reasoning behind it]\n</recommendation>\n\nFAILURE\n- Missing any required stage in `<gut_check_protocol>`, `<summary>`, or `<recommendation>`.\n- Recommendation is generic or not supported by protocol signals.\n- Tone is judgmental, coercive, or dismissive.\n- Missing provisional labeling when user responses are unavailable.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Decision Making/MECE analysis and logical tree from list items.md",
      "title": "\"MECE analysis and logical tree from list items\"",
      "category": "\"Decision Making\"",
      "tags": [
        "pm",
        "decision-making",
        "mece",
        "structured-thinking",
        "frameworks"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{LIST_OF_ITEMS}}\n</provided_inputs>\n\nGOAL\nEvaluate `LIST_OF_ITEMS` for MECE quality and produce a logical tree that resolves overlaps/gaps.\nSuccess metric:\n- Clearly assesses mutual exclusivity and collective exhaustiveness.\n- Identifies concrete overlaps and coverage gaps (if any).\n- Produces a coherent tree structure reflecting corrected grouping logic.\n- Follows the required output schema exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps:\n  1. Test pairwise overlap (mutual exclusivity).\n  2. Test coverage gaps (collective exhaustiveness).\n  3. Propose corrected structure and hierarchy.\n- Keep conclusions grounded in the provided list; avoid unrelated frameworks unless necessary.\n- If ambiguity exists in item definitions, state assumptions explicitly.\n- Provide concise rationale, not hidden/internal chain-of-thought.\n\nFORMAT\nReturn exactly this structure:\n\n<analysis>\n<mutual_exclusivity_assessment>\n[State whether items are mutually exclusive, with specific overlap examples where relevant]\n</mutual_exclusivity_assessment>\n<collective_exhaustiveness_assessment>\n[State whether items are collectively exhaustive, with specific gap examples where relevant]\n</collective_exhaustiveness_assessment>\n<key_issues>\n[Concise list of overlap issues and/or coverage gaps]\n</key_issues>\n</analysis>\n\n<answer>\n<mece_conclusion>[MECE status: Fully MECE | Not MECE | Partially MECE]</mece_conclusion>\n<logical_tree>\n[Hierarchical tree showing corrected structure and item placement]\n</logical_tree>\n</answer>\n\nFAILURE\n- Required schema sections are missing or malformed.\n- Mutual exclusivity or collective exhaustiveness assessment is absent.\n- Logical tree is missing, unclear, or inconsistent with analysis findings.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Decision Making/Root cause and consequence analysis from a question.md",
      "title": "\"Root cause and consequence analysis from a question\"",
      "category": "\"Decision Making\"",
      "tags": [
        "pm",
        "decision-making",
        "analysis",
        "root-causes",
        "reasoning"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{INITIAL_QUESTION}}\n</provided_inputs>\n\nGOAL\nIdentify plausible root causes and downstream consequences of `INITIAL_QUESTION` using recursive why-analysis and first-principles reasoning.\nSuccess metric:\n- Performs a deep why-chain (target depth: at least 5 levels or until a defensible root cause boundary).\n- Explores consequence orders from first through fifth (positive and negative where plausible).\n- Distinguishes assumptions from inferred facts and flags logic gaps.\n- Follows the required output structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis layers:\n  1. Recursive why-analysis.\n  2. Consequence chain (1st to 5th order).\n  3. First-principles reconstruction.\n- For why-analysis, explore parallel branches when multiple plausible causes emerge.\n- For consequence analysis, include both upside and downside outcomes when credible.\n- Keep reasoning neutral and explicit; avoid unsupported certainty.\n- Clearly label assumptions and unknowns.\n\nFORMAT\nReturn exactly this structure:\n\n<analysis>\n<root_causes>\n[List your \"Why?\" questions and answers here, showing the progression to the root cause(s)]\n</root_causes>\n\n<consequences>\n[Describe the potential consequences here, from first-order to fifth-order]\n</consequences>\n\n<first_principles>\n[Present your first principles analysis here, including fundamental truths, questioned assumptions, and any identified gaps]\n</first_principles>\n\n<conclusion>\n[Summarize your key findings and insights]\n</conclusion>\n</analysis>\n\nFAILURE\n- Required schema is missing or malformed.\n- Why-analysis is shallow (no meaningful depth/branching) or lacks root-cause rationale.\n- Consequence analysis does not cover first through fifth order.\n- First-principles section does not separate assumptions from fundamentals.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Decision Making/Solution anti-patterns from customer problem analysis.md",
      "title": "Solution anti-patterns from customer problem analysis",
      "category": "Decision Making",
      "tags": [
        "pm",
        "decision-making",
        "critical-thinking",
        "anti-patterns"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{CUSTOMER_NOTES}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Solution anti-patterns from customer problem analysis.\nSuccess metric:\n- Produces exactly 3 plausible but fundamentally flawed solutions derived from the customer problem context.\n- Each flawed solution is clearly mapped to why it fails (or worsens outcomes) with concrete evidence from inputs.\n- Output follows the required schema exactly.\n\nCONSTRAINTS\n- Use only `{{CUSTOMER_NOTES}}`; if details are missing, state assumptions explicitly.\n- Analyze first, then propose flawed solutions; do not skip analysis steps.\n- Keep flaws subtle and realistic (not absurd/comedic), and tie them to customer context.\n- Ensure each flawed solution is implementable on the surface but strategically wrong.\n- Cover short-term and long-term consequences, stakeholder impacts, and implementation constraints.\n\nFORMAT\nReturn exactly this structure:\n\n<problem_analysis>\n1. Notes breakdown: [Key points, assumptions, implicit needs]\n2. Core problems: [Primary problems to address]\n3. Stakeholders: [Stakeholder -> interests]\n4. Failure-prone areas: [Where solutions can go wrong]\n5. Consequences: [Short-term and long-term consequences to watch]\n6. Constraints: [Resource and implementation constraints]\n7. Flawed-approach brainstorm: [Candidate anti-pattern directions]\n</problem_analysis>\n\n<bad_solutions>\n1. [Brief description of flawed solution 1]\n2. [Brief description of flawed solution 2]\n3. [Brief description of flawed solution 3]\n</bad_solutions>\n\n<explanations>\n1. [Why solution 1 is a poor choice: misread need, hidden downside, likely failure mode, consequence]\n2. [Why solution 2 is a poor choice: misread need, hidden downside, likely failure mode, consequence]\n3. [Why solution 3 is a poor choice: misread need, hidden downside, likely failure mode, consequence]\n</explanations>\n\nFAILURE\n- Any required section in `FORMAT` is missing, malformed, or incomplete.\n- Not exactly 3 flawed solutions.\n- Explanations do not map 1:1 to the listed solutions.\n- Claims are generic or not grounded in provided inputs.\n- Flaws are absurd/comedic instead of plausible and subtle.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Decision Making/Structured decision journals from decisions and context.md",
      "title": "\"Structured decision journals from decisions and context\"",
      "category": "\"Decision Making\"",
      "tags": [
        "pm",
        "decision-making",
        "journaling",
        "forecasting",
        "base-rates"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{DECISION}}\n- {{CONTEXT}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: \"Structured decision journals from decisions and context\".\nSuccess metric:\n- Produces a complete decision journal with all required sections filled from provided context.\n- Probability estimates are coherent and sum to 100%.\n- Quit conditions are measurable and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{DECISION}}` and `{{CONTEXT}}`; if information is missing, state assumptions explicitly.\n- Generate 3-5 expected outcomes spanning best-case to worst-case and covering short-term and long-term effects.\n- Provide one probability for each expected outcome; probabilities must total exactly 100%.\n- Provide 3-5 key assumptions that materially affect outcome validity.\n- Provide relevant base rates/statistics tied to this decision type; if unavailable, provide directional proxies and label as assumptions.\n- Provide 2-3 measurable quit conditions with clear trigger thresholds.\n- Keep `<actual_results>` intentionally blank for future updates.\n\nFORMAT\nReturn exactly this structure:\n\n<decision_journal>\n<expected_outcomes>\n1. [Outcome]\n2. [Outcome]\n3. [Outcome]\n[Optional 4th and 5th outcome]\n</expected_outcomes>\n\n<probability_estimates>\n1. [Outcome 1] - [X%]\n2. [Outcome 2] - [Y%]\n3. [Outcome 3] - [Z%]\n[Optional 4th and 5th probability]\nTotal: 100%\n</probability_estimates>\n\n<key_assumptions>\n1. [Assumption]\n2. [Assumption]\n3. [Assumption]\n[Optional 4th and 5th assumption]\n</key_assumptions>\n\n<base_rates>\n1. [Base rate/statistic + source context or rationale]\n2. [Base rate/statistic + source context or rationale]\n[Optional additional base rates]\n</base_rates>\n\n<quit_conditions>\n1. [Condition + measurable threshold]\n2. [Condition + measurable threshold]\n[Optional 3rd condition]\n</quit_conditions>\n\n<actual_results>\n</actual_results>\n</decision_journal>\n\nFAILURE\n- Any required section in `FORMAT` is missing, malformed, or incomplete.\n- Fewer than 3 or more than 5 expected outcomes.\n- Probability estimates do not map to outcomes or do not total 100%.\n- Fewer than 3 key assumptions or fewer than 2 quit conditions.\n- Quit conditions are not measurable.\n- Claims are generic or not grounded in provided inputs.\n- `<actual_results>` is pre-filled with outcome claims.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Decision Making/Structured product hypotheses from product problems.md",
      "title": "\"Structured product hypotheses from product problems\"",
      "category": "\"Decision Making\"",
      "tags": [
        "pm",
        "decision-making",
        "experimentation",
        "hypotheses",
        "product"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{PRODUCT_PROBLEM}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: \"Structured product hypotheses from product problems\".\nSuccess metric:\n- Produces a clear, testable product hypothesis directly tied to the provided problem.\n- Includes a measurable plan to evaluate success with explicit metrics and thresholds.\n- Covers all required hypothesis-formation steps before finalizing the hypothesis.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{PRODUCT_PROBLEM}}`; if details are missing, state assumptions explicitly.\n- Execute all six steps: experiment goal, draft hypothesis, specificity check, measurement plan, validate/refine, narrative framing.\n- Draft hypothesis must include all five components: Action, Outcome, Direction, Users, Conditions.\n- Keep outcomes measurable; avoid vague terms (for example: \"better\", \"improve\") without quantification.\n- Ensure the final hypothesis and metrics are realistic and testable in product-experiment contexts.\n\nFORMAT\nReturn exactly this structure:\n\n<experiment_goal>\n[User problem and proposed change]\n</experiment_goal>\n\n<hypothesis_draft>\n[Action] will cause [Outcome] to [Direction] for [Users] under [Conditions].\n</hypothesis_draft>\n\n<specificity_check>\n- Action clarity: [Pass/Fail + note]\n- Outcome clarity: [Pass/Fail + note]\n- Direction clarity: [Pass/Fail + note]\n- Users clarity: [Pass/Fail + note]\n- Conditions clarity: [Pass/Fail + note]\n</specificity_check>\n\n<measurement_plan>\n- Primary metric: [Metric + baseline + target change + timeframe]\n- Secondary metrics: [Metric list]\n- Data collection: [How/where measured]\n- Guardrails: [Risk metrics to monitor]\n</measurement_plan>\n\n<validation_and_refinement>\n- Clarity gaps found: [List]\n- Refinements made: [List]\n</validation_and_refinement>\n\n<narrative_framing>\n[Short story-style framing linking problem -> change -> expected outcome -> evidence of success]\n</narrative_framing>\n\n<hypothesis>\nCurrently, [user] is experiencing [problem].\nWe believe that by [change], we'll see [outcome].\nWe'll know we're right when [metric] changes by [amount].\n</hypothesis>\n\n<explanation>\n[Brief explanation of why this hypothesis fits the product problem and framework]\n</explanation>\n\nFAILURE\n- Any required section in `FORMAT` is missing, malformed, or incomplete.\n- Hypothesis draft omits any of the five required components.\n- Measurement plan lacks metric, target change, or timeframe.\n- Final `<hypothesis>` does not follow the required three-line template.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Decision Making/Target opportunity selection from OST.md",
      "title": "\"Target opportunity selection from OST\"",
      "category": "\"Decision Making\"",
      "tags": [
        "pm",
        "decision-making",
        "discovery",
        "opportunity-solution-tree",
        "prioritization"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{BUSINESS_OUTCOME}}\n- {{JOURNEY_NODES_AS_LIST}}\n- {{INTERVIEW_TRANSCRIPTS_OR_STORY_SNIPPETS}}\n- {{CONSTRAINTS_OR_PRINCIPLES}}\n- {{OST_JSON}}\n- Optional: {{WEIGHTS_JSON}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: \"Target opportunity selection from OST\".\nSuccess metric:\n- Recommends exactly one small, distinct, moment-scoped target opportunity from the OST.\n- Uses evidence-grounded scoring across Opportunity, Market, Company, and Customer factors.\n- Produces a shortlist and recommendation that are traceable to OST/interview evidence.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs; if a required field is missing, state assumptions explicitly.\n- Candidate harvesting:\n  - From `{{OST_JSON}}`, include leaf opportunities plus intermediate parents with 2+ specific children or explicit traceability evidence.\n  - Merge duplicates and reframe solution-framed items as opportunity/need statements.\n- Score each candidate 1-5 on:\n  - Opportunity Sizing (OS), Market Factors (MF), Company Factors (CF), Customer Factors (CuF).\n- Compute WPS with default weights unless `{{WEIGHTS_JSON}}` is provided and sums to 1.0:\n  - Default weights: OS 0.35, MF 0.20, CF 0.25, CuF 0.20.\n- If factor data is missing, assign score `3` and flag as low evidence.\n- Shortlist top 3-5 by WPS, then apply tie-breakers in order:\n  - distinctness (thinner slice), evidence quality, time-to-learning, risk diversification across moments.\n- Recommend exactly one target opportunity that is small, distinct, moment-scoped, and independently addressable.\n- Do not include solution effort or engineering feasibility estimates at this stage.\n- Maintain traceability to interview/OST evidence and avoid exposing PII not present in inputs.\n\nFORMAT\nReturn exactly this structure:\n\nPart A - Candidate Inventory (from OST)\n| id | moment | opportunity | level (leaf/parent) | distinct_from | evidence_summary | notes |\n| -- | ------ | ----------- | ------------------- | ------------- | ---------------- | ----- |\n[`evidence_summary` must include: `{frequency_count, confidence, #quotes}` with 1-2 short quote snippets.]\n\nPart B - Scoring Matrix\n| id | OS (weight) | MF (weight) | CF (weight) | CuF (weight) | WPS | factor_rationales |\n| -- | ----------: | ----------: | ----------: | -----------: | --: | ----------------- |\n[Use 1-5 integers for factor scores and show WPS calculation basis.]\n\nPart C - Shortlist (Top 3-5)\n- [id] - [1-2 sentence justification]\n- [id] - [1-2 sentence justification]\n- [id] - [1-2 sentence justification]\n[Optional 4th/5th item]\n\nPart D - Recommendation (One Target Opportunity)\n- Selected id & title: [id] - [opportunity]\n- Why now:\n  - [3-5 evidence-grounded bullets]\n- Scope check:\n  - [Confirm small distinct slice tied to one moment and independent from siblings]\n- Risks/Unknowns:\n  - [Bullets]\n- Immediate next steps:\n  - Generate 3 competing solution ideas for this opportunity.\n  - Draft assumption map (desirability, usability, feasibility, viability, ethical).\n  - Design smallest tests for riskiest assumptions with success criteria.\n\nPart E - Audit (Torres Alignment)\n- No-effort policy honored? [yes/no + explanation]\n- Moment distinctness verified? [yes/no + overlaps if any]\n- Evidence gaps requiring quick follow-up interview or data pull: [Bullets]\n\nFAILURE\n- Any required part/table/list item from `FORMAT` is missing or materially incomplete.\n- Fewer than 3 or more than 5 shortlisted opportunities.\n- Recommendation is not exactly one opportunity.\n- Scoring is missing factor scores, WPS, or weight usage.\n- Tie-break logic is not applied when close/top candidates conflict.\n- Output includes effort/engineering-feasibility prioritization.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Design & Prototyping/App design from project requirements.md",
      "title": "App design from project requirements",
      "category": "Design & Prototyping",
      "tags": [
        "app-design",
        "ux",
        "design-system",
        "wireframing"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{PROJECT_DESCRIPTION}}\n- {{TARGET_AUDIENCE}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: App design from project requirements.\nSuccess metric:\n- Defines one clear core feature aligned to user needs and project goals.\n- Provides a functional grayscale interface sketch focused on essential flow.\n- Produces a minimal, consistent design system within stated constraints.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{PROJECT_DESCRIPTION}}` and `{{TARGET_AUDIENCE}}`; if details are missing, state assumptions explicitly.\n- Identify exactly one core feature (the single highest-value user task).\n- Keep interface sketch grayscale/function-first and limited to essential elements for the core feature.\n- Design system must remain lightweight:\n  - Font sizes: 3-4 sizes total.\n  - Colors: 1 primary + up to 2-3 secondary colors.\n  - Spacing: one consistent scale.\n  - Button styles: 1-2 styles.\n- Keep choices practical, internally consistent, and audience-appropriate.\n\nFORMAT\nReturn exactly this structure:\n\n<kickoff_plan>\n<core_feature>\n[Insert your defined core feature here]\n</core_feature>\n\n<interface_sketch>\n[Describe your grayscale interface sketch here. Be specific about layout and essential elements.]\n</interface_sketch>\n\n<design_system>\n<font_sizes>\n[List your chosen font sizes]\n</font_sizes>\n\n<colors>\n[List your chosen colors]\n</colors>\n\n<spacing_values>\n[Describe your spacing scale]\n</spacing_values>\n\n<button_styles>\n[Describe your button style(s)]\n</button_styles>\n</design_system>\n</kickoff_plan>\n\nFAILURE\n- Any required section/tag in `FORMAT` is missing, malformed, or incomplete.\n- More than one core feature is proposed.\n- `interface_sketch` emphasizes visual styling over functional layout.\n- `font_sizes` has fewer than 3 or more than 4 sizes.\n- `colors` exceeds 1 primary + 2-3 secondary colors.\n- `button_styles` has fewer than 1 or more than 2 styles.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Design & Prototyping/CTAs from copywriting strategies.md",
      "title": "CTAs from copywriting strategies",
      "category": "Design & Prototyping",
      "tags": [
        "pm",
        "marketing",
        "cta"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{PRODUCT}}\n</provided_inputs>\n\nGOAL\nGenerate 12 high-quality CTA options for `PRODUCT`, organized by 4 copywriting strategies.\nSuccess metric:\n- Exactly 12 CTAs are provided (3 per strategy).\n- Every CTA follows length constraints and includes character count.\n- CTA wording is specific to `PRODUCT` and non-duplicative.\n\nCONSTRAINTS\n- Use only `PRODUCT` as input context.\n- Create exactly 12 unique CTAs: 3 for each strategy.\n- Use these strategy groups exactly:\n  - Match the feeling\n  - Actionable next step\n  - Handle the objection\n  - Make it specific\n- Each CTA must be 6-35 characters (including spaces).\n- Target average CTA length around 25 characters across all 12.\n- Keep wording product-specific and action-oriented; avoid generic placeholders.\n- Include character count after every CTA.\n\nFORMAT\nReturn exactly this structure:\n\n<output>\n1. Match the feeling  \n   a. [CTA] (XX characters)  \n   b. [CTA] (XX characters)  \n   c. [CTA] (XX characters)  \n\n2. Actionable next step  \n   a. [CTA] (XX characters)  \n   b. [CTA] (XX characters)  \n   c. [CTA] (XX characters)  \n\n3. Handle the objection  \n   a. [CTA] (XX characters)  \n   b. [CTA] (XX characters)  \n   c. [CTA] (XX characters)  \n\n4. Make it specific  \n   a. [CTA] (XX characters)  \n   b. [CTA] (XX characters)  \n   c. [CTA] (XX characters)  \n</output>\n\nFAILURE\n- Not exactly 12 CTAs, or not exactly 3 per strategy group.\n- Any CTA is outside 6-35 characters, or character counts are missing/incorrect.\n- CTAs are repetitive, generic, or not tailored to `PRODUCT`.\n- Required output schema/order is missing or malformed."
    },
    {
      "path": "Prompts/Design & Prototyping/Ideas for affordances and signifiers based on a design problem.md",
      "title": "Ideas for affordances and signifiers based on a design problem",
      "category": "Design & Prototyping",
      "tags": [
        "ux",
        "interaction-design",
        "affordances",
        "usability"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{DESIGN_CHALLENGE}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Ideas for affordances and signifiers based on a design problem.\nSuccess metric:\n- Identifies key user interactions in the design challenge before proposing ideas.\n- Produces at least 5 concrete ideas each for affordances, perceived affordances, and signifiers.\n- Each idea includes a brief explanation tied to the challenge and UX impact.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{DESIGN_CHALLENGE}}`; if context is incomplete, state assumptions explicitly.\n- Start with a brief interaction analysis identifying main user functions/tasks.\n- Generate at least 5 ideas in each category: affordances, perceived affordances, signifiers.\n- For every idea, include a short explanation linking:\n  - the specific challenge friction/opportunity,\n  - how the idea guides user action or perception,\n  - expected UX improvement.\n- Keep ideas practical, non-generic, and directly relevant to the described product context.\n\nFORMAT\nReturn exactly this structure:\n\n<ideas>\n<interaction_analysis>\n[Main user interactions/functions required by the challenge]\n</interaction_analysis>\n\n<affordances>\n1. [Affordance idea] - [Brief explanation]\n2. [Affordance idea] - [Brief explanation]\n3. [Affordance idea] - [Brief explanation]\n4. [Affordance idea] - [Brief explanation]\n5. [Affordance idea] - [Brief explanation]\n[Optional additional ideas]\n</affordances>\n\n<perceived_affordances>\n1. [Perceived affordance idea] - [Brief explanation]\n2. [Perceived affordance idea] - [Brief explanation]\n3. [Perceived affordance idea] - [Brief explanation]\n4. [Perceived affordance idea] - [Brief explanation]\n5. [Perceived affordance idea] - [Brief explanation]\n[Optional additional ideas]\n</perceived_affordances>\n\n<signifiers>\n1. [Signifier idea] - [Brief explanation]\n2. [Signifier idea] - [Brief explanation]\n3. [Signifier idea] - [Brief explanation]\n4. [Signifier idea] - [Brief explanation]\n5. [Signifier idea] - [Brief explanation]\n[Optional additional ideas]\n</signifiers>\n</ideas>\n\nFAILURE\n- Any required section/tag in `FORMAT` is missing, malformed, or incomplete.\n- Fewer than 5 ideas in any required category.\n- Explanations are missing for one or more ideas.\n- No interaction analysis is provided before idea lists.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Design & Prototyping/Multi-step workflow optimization.md",
      "title": "\"Multi-step workflow optimization\"",
      "category": "\"Design & Prototyping\"",
      "tags": [
        "ux",
        "workflow",
        "friction",
        "funnels",
        "optimization"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{CURRENT_WORKFLOW}}\n- {{USER_ANALYTICS}}\n- {{DROP_OFF_DATA}}\n- {{USER_FEEDBACK}}\n- {{BUSINESS_CONSTRAINTS}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: \"Multi-step workflow optimization\".\nSuccess metric:\n- Produces a full current-state workflow diagnosis with per-step friction and necessity classification.\n- Proposes a lower-friction workflow that improves completion/time while preserving required safeguards.\n- Includes a measurable validation plan (A/B or staged rollout) and post-launch iteration logic.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs; if data is missing, state assumptions explicitly.\n- Analyze the current workflow end-to-end before proposing changes.\n- Provide per-step diagnosis including purpose, required inputs, validation, completion/time, errors, friction type, and necessity.\n- Identify top friction points across redundancy, repetition, validation friction, progress clarity, save/resume, cognitive load, technical friction, and emotional friction.\n- Propose optimizations that reduce steps/time/drop-off while preserving required legal, security, and quality checkpoints.\n- Keep recommendations specific, testable, and measurable against baseline metrics.\n- Include experimentation and rollout plan with success criteria, rollback conditions, and post-launch monitoring.\n- If exact metrics are unavailable, provide directional estimates and clearly mark them as assumptions.\n\nFORMAT\nReturn exactly this structure:\n\n<workflow_optimization>\n<executive_summary>\n**Current State:**\n- Total steps: [X]\n- Average completion rate: [Y%]\n- Average time to complete: [Z minutes]\n- Primary drop-off point: [Step N - why]\n\n**Proposed State:**\n- Total steps: [X - reduced by N]\n- Expected completion rate: [Y + N%]\n- Expected time to complete: [Z - N minutes]\n- Key improvements: [3-5 bullet points]\n\n**Expected Impact:**\n- [Metric]: [Current → Target]\n- [Metric]: [Current → Target]\n- [Business impact]: [e.g., \"10% increase in signups = $X additional revenue/month\"]\n</executive_summary>\n\n<current_workflow_analysis>\n**Overall Metrics:**\n- Steps: [Total count]\n- Completion Rate: [X% - what percent of users who start actually finish]\n- Average Time: [Minutes/seconds]\n- Median Time: [If significantly different from average, indicates confusion for some users]\n- Abandonment Rate: [100 - completion rate]\n\n**Drop-off Analysis:**\n- Step 1: [Name] - [Y% complete this step] - [W% abandon]\n- Step 2: [Name] - [Y% complete] - [W% abandon] ⚠️ [High drop-off? Why?]\n- Step 3: [Name] - [Y% complete] - [W% abandon]\n- [Continue for all steps]\n\n**Top 3 Friction Points:**\n1. [Step/Issue]: [X% abandon] - [Why this is painful]\n2. [Step/Issue]: [Y% abandon] - [Why this is painful]\n3. [Step/Issue]: [Z% abandon] - [Why this is painful]\n\n**Detailed Step Analysis:**\n\nFor each step, provide:\n\n**Step 1: [Name]**\n- **What user does:** [Actions required - e.g., \"Enter name, email, phone number\"]\n- **Why step exists:** [Purpose - e.g., \"Account creation requires contact info\"]\n- **Inputs required:** [List of fields]\n  - [Field]: [Required/Optional] - [Source of data - user memory, lookup, calculation]\n- **Validation:** [What's checked - e.g., \"Email format, phone number format\"]\n- **Completion rate:** [X%] - [Y% drop off at this step]\n- **Average time:** [Z seconds]\n- **Common errors:** [What goes wrong - e.g., \"15% of users enter invalid email format\"]\n- **Friction type:** [Redundant/Complex/Unclear/Tedious/Unnecessary]\n- **Problem statement:** [What makes this step difficult or annoying]\n- **Necessity:** ✅ Required (cannot remove) / ⚠️ Required but could be improved / ❌ Unnecessary (can remove or defer)\n\n**Step 2: [Name]**\n[Same detailed structure]\n\n[Continue for all steps]\n\n</current_workflow_analysis>\n\n<optimization_strategies>\n[Describe which of the strategies above you are applying to this workflow, and how.]\n</optimization_strategies>\n\n<optimized_workflow>\n[Describe the new, optimized workflow step-by-step, including which steps were removed, combined, or deferred, and the expected impact on metrics.]\n</optimized_workflow>\n\n<what_we_keep>\n[List the critical checkpoints, validations, and safeguards you are intentionally preserving, and why they remain necessary.]\n</what_we_keep>\n\n<testing_plan>\n[Outline the A/B test or rollout approach you will use to validate the improved workflow.]\n</testing_plan>\n\n<monitoring_and_iteration>\n[Describe how you will monitor post-launch performance and iterate based on data and feedback.]\n</monitoring_and_iteration>\n</workflow_optimization>\n\nFAILURE\n- Any required section/tag from `FORMAT` is missing, malformed, or materially incomplete.\n- Current workflow analysis lacks per-step necessity or friction classification.\n- Proposed optimizations remove required safeguards without justification.\n- Testing plan lacks control/variant definition or clear decision criteria.\n- Monitoring plan lacks actionable metrics or iteration logic.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Design & Prototyping/Multiple interface descriptions from a single image.md",
      "title": "\"Multiple interface descriptions from a single image\"",
      "category": "\"Design & Prototyping\"",
      "tags": [
        "pm",
        "ux",
        "design",
        "communication",
        "perspectives"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{IMAGE}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: \"Multiple interface descriptions from a single image\".\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Follow these task requirements:\n<task_requirements>\nYou will be given an image of the interface for a complex tool. Your task is to describe this interface in four different ways. Here's how to proceed:\n\nFirst, examine the image carefully:\n<image>\n{{IMAGE}}\n</image>\n\nNow, follow these steps:\n\n1. Write instructions for a novice:  \n   Analyze the image and write clear, step-by-step instructions for a beginner to understand and use the interface. Use simple language and explain each element of the interface. Begin your response with `<novice_instructions>` and end with `</novice_instructions>`.\n\n2. Create a process diagram:  \n   Based on your analysis of the image, create a textual representation of a process diagram. Use symbols like `[ ]` for steps, `( )` for decisions, and `->` for connections. Describe the flow of using the interface in a logical order. Begin your response with `<process_diagram>` and end with `</process_diagram>`.\n\n3. Write like a 5th grader doing a book report:  \n   Imagine you're a 5th grader writing a book report about this interface. Use simple vocabulary, short sentences, and an excited tone. Describe what you see and what you think it does. Begin your response with `<fifth_grader_report>` and end with `</fifth_grader_report>`.\n\n4. Write for someone terminally online:  \n   Rewrite your description for someone who spends all their time on the internet. Use internet slang, memes, and references. Be informal and use exaggerated language. Begin your response with ``.\n\nRemember to base all your descriptions on the image provided. Do not invent features or elements that are not visible in the image. If you're unsure about any aspect of the interface, it's okay to say so in your descriptions.\n</task_requirements>\n\nFORMAT\nReturn exactly this structure:\n\n<online_description>` and end with `</online_description>\n\nFAILURE\n- Output misses required sections, steps, or reasoning required by `<task_requirements>`.\n- Required format/schema is missing, malformed, or incomplete.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Design & Prototyping/Product design analysis from context and screenshots.md",
      "title": "\"Product design analysis from context and screenshots\"",
      "category": "\"Design & Prototyping\"",
      "tags": [
        "pm",
        "ux",
        "design",
        "critique",
        "analysis"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{CONTEXT}}\n- {{SCREENSHOTS}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: \"Product design analysis from context and screenshots\".\nSuccess metric:\n- Identifies concrete design issues from provided context/screenshots.\n- Recommends optimization opportunities tied to stated goals and metrics.\n- Provides viable alternative approaches with clear tradeoffs.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{CONTEXT}}` and `{{SCREENSHOTS}}`; if details are missing, state assumptions explicitly.\n- Ground every issue and recommendation in observable evidence from context/screenshots.\n- Prioritize findings by likely impact on user outcomes and stated product goals/metrics.\n- Keep recommendations actionable, testable, and specific (not generic UX advice).\n- Include balanced tradeoffs when proposing alternatives.\n\nFORMAT\nReturn exactly this structure:\n\n<analysis>\n<issues_and_limitations>\n- [Issue 1] - [Evidence from context/screenshot] - [Why it is a limitation]\n- [Issue 2] - [Evidence from context/screenshot] - [Why it is a limitation]\n[Additional issues as needed]\n</issues_and_limitations>\n\n<optimization_opportunities>\n- [Opportunity 1] - [Target goal/metric] - [Suggested change] - [Expected impact]\n- [Opportunity 2] - [Target goal/metric] - [Suggested change] - [Expected impact]\n[Additional opportunities as needed]\n</optimization_opportunities>\n\n<alternative_approaches>\n- [Alternative 1] - [What changes] - [Pros] - [Cons]\n- [Alternative 2] - [What changes] - [Pros] - [Cons]\n[Additional alternatives as needed]\n</alternative_approaches>\n\n<pros_and_cons>\n- Pros:\n  - [Pro 1]\n  - [Pro 2]\n- Cons:\n  - [Con 1]\n  - [Con 2]\n</pros_and_cons>\n</analysis>\n\nFAILURE\n- Any required section/tag in `FORMAT` is missing, malformed, or incomplete.\n- Issues/recommendations are not traceable to provided context/screenshots.\n- Optimization opportunities are not tied to product goals/metrics.\n- Alternatives are listed without explicit pros/cons tradeoffs.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Design & Prototyping/Prototype from image descriptions and app info.md",
      "title": "Prototype creation from image descriptions and app info",
      "category": "Design & Prototyping",
      "tags": [
        "pm",
        "ux",
        "prototyping",
        "html",
        "interaction-design"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{IMAGE_DESCRIPTION}}\n- {{APP_INFO}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Prototype creation from image descriptions and app info.\nSuccess metric:\n- Produces a coherent clickable screen prototype aligned with provided image/app context.\n- Includes complete HTML, CSS, and JavaScript with responsive layout and interactive behavior.\n- Returns incremental build artifacts plus a final merged prototype file.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{IMAGE_DESCRIPTION}}` and `{{APP_INFO}}`; if details are missing, state assumptions explicitly.\n- Build a realistic screen mental model before coding.\n- Provide incremental artifacts in this order:\n  - `html_structure`\n  - `css_styles`\n  - `js_functionality`\n  - `final_prototype`\n- `html_structure` must include `<!DOCTYPE html>`, `<html>`, `<head>`, `<title>`, and `<body>` scaffolding.\n- `css_styles` must include responsive layout rules and clear interactive states.\n- `js_functionality` must implement click behavior for primary interactive elements.\n- `final_prototype` must combine valid HTML+CSS+JS into one executable file snippet.\n- Keep the prototype suitable for user testing: functional, readable, and context-aligned.\n\nFORMAT\nReturn exactly this structure:\n\n<html_structure>\n[Basic HTML scaffold only]\n</html_structure>\n\n<css_styles>\n[CSS for layout, components, states, and responsiveness]\n</css_styles>\n\n<js_functionality>\n[JavaScript for interactions, click handlers, and lightweight transitions]\n</js_functionality>\n\n<final_prototype>\n[Single complete HTML file containing merged HTML, CSS, and JS]\n</final_prototype>\n\nFAILURE\n- Any required section/tag in `FORMAT` is missing, malformed, out of order, or incomplete.\n- `final_prototype` does not contain a full standalone HTML document.\n- Interactive elements are described but not implemented in JavaScript.\n- Layout is not responsive or lacks interaction feedback states.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Design & Prototyping/Sketch descriptions for wireframes from product ideas.md",
      "title": "Sketch descriptions for wireframes from product ideas",
      "category": "Design & Prototyping",
      "tags": [
        "pm",
        "ux",
        "flows",
        "design",
        "prototyping",
        "wireframes"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{PRODUCT_IDEA}}\n- {{ADDITIONAL_DETAILS}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Sketch descriptions for wireframes from product ideas.\nSuccess metric:\n- Produces 3-5 detailed sketch descriptions covering distinct product flows/aspects.\n- Each sketch includes layout, interaction flow, friction reduction, and design variations.\n- Output is specific enough for a visual designer to create wireframes/mockups directly.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{PRODUCT_IDEA}}` and `{{ADDITIONAL_DETAILS}}`; if details are missing, state assumptions explicitly.\n- Generate 3-5 sketches, each focused on a distinct flow/aspect (not minor variants of the same screen).\n- For each sketch include:\n  - Title/identifier\n  - What the sketch represents\n  - Key UI elements and placement\n  - User flow and interaction points\n  - At least one meaningful variation/alternative\n- Incorporate user-centric design, friction reduction, onboarding considerations, consistency, and scalability.\n- Do not restate input prompts verbatim in the output.\n\nFORMAT\nReturn exactly this structure:\n\n<sketch_descriptions>\n<sketch>\n<title>[Sketch title]</title>\n<description>[What this sketch represents]</description>\n<key_elements_and_layout>[Key elements and placement]</key_elements_and_layout>\n<user_flow_and_interactions>[Start point -> key actions -> completion point]</user_flow_and_interactions>\n<friction_reduction_notes>[How this sketch reduces friction/pain points]</friction_reduction_notes>\n<variations>[Alternative design directions or variants]</variations>\n</sketch>\n[Repeat `<sketch>` for each sketch; total 3-5 sketches]\n</sketch_descriptions>\n\nFAILURE\n- Root tag `<sketch_descriptions>` or child `<sketch>` sections are missing, malformed, or incomplete.\n- Fewer than 3 or more than 5 sketches are provided.\n- Any sketch is missing one or more required fields from `FORMAT`.\n- Sketches are redundant and do not represent distinct flows/aspects.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Design & Prototyping/Solution design for edge cases in product development.md",
      "title": "Solution design for edge cases in product development",
      "category": "Design & Prototyping",
      "tags": [
        "ux",
        "edge-cases",
        "product-design",
        "tradeoffs"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{EDGE_CASE_SCENARIO}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Solution design for edge cases in product development.\nSuccess metric:\n- Clearly explains why the scenario is rare but critical and its user/business impact.\n- Proposes and evaluates at least 3 distinct solution approaches.\n- Recommends a balanced solution that resolves the edge case without overcomplicating the core flow.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{EDGE_CASE_SCENARIO}}`; if details are missing, state assumptions explicitly.\n- Start with scenario diagnosis before solutioning.\n- Generate at least 3 approaches spanning minimal to comprehensive change.\n- Evaluate each approach on:\n  - effectiveness for the edge case,\n  - impact on core users,\n  - implementation complexity,\n  - scalability/risk.\n- Recommend one approach with clear tradeoff rationale.\n- Prioritize minimal added complexity to the primary user journey.\n\nFORMAT\nReturn exactly this structure:\n\n<solution>\n<scenario_analysis>\n- Core issue: [What fails and why]\n- Why rare but critical: [Frequency + severity]\n- Affected users and impact: [Who is impacted and consequence]\n</scenario_analysis>\n\n<solution_options>\n1. [Option name] - [Approach summary]\n2. [Option name] - [Approach summary]\n3. [Option name] - [Approach summary]\n[Optional additional options]\n</solution_options>\n\n<option_evaluation>\n- [Option name]:\n  - Pros: [Bullets]\n  - Cons: [Bullets]\n  - Complexity: [Low/Medium/High + note]\n  - Core experience impact: [Low/Medium/High + note]\n  - Scalability: [Assessment]\n- [Repeat for each option]\n</option_evaluation>\n\n<summary>\nBriefly describe your recommended solution in 2-3 sentences.\n</summary>\n\n<rationale>\nExplain your reasoning for choosing this solution, including:\n- How it addresses the edge case\n- Why it's preferable to other options\n- How it minimizes impact on the core experience\n</rationale>\n\n<implementation>\nProvide a high-level overview of how to implement this solution, including:\n- Any necessary changes to the user interface\n- Backend modifications required\n- Potential challenges in implementation and how to address them\n</implementation>\n\n<user_communication>\nSuggest how to communicate this change to users, if necessary. This may include:\n- Updates to documentation\n- In-app notifications or tooltips\n- Changes to onboarding processes\n</user_communication>\n</solution>\n\nFAILURE\n- Any required section/tag in `FORMAT` is missing, malformed, or incomplete.\n- Fewer than 3 solution options are provided.\n- No explicit evaluation is provided for one or more options.\n- Recommendation is not traceable to the option tradeoff analysis.\n- Recommendation over-engineers the core flow without justification.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Design & Prototyping/Structured JSON descriptions from UI screenshots.md",
      "title": "\"Structured JSON descriptions from UI screenshots\"",
      "category": "\"Design & Prototyping\"",
      "tags": [
        "pm",
        "ux",
        "design",
        "ui",
        "json"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{SCREENSHOT}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: \"Structured JSON descriptions from UI screenshots\".\nSuccess metric:\n- Produces a detailed, structured JSON description of the UI screenshot.\n- Captures layout, visual style, text, UI elements, imagery/icons, and hierarchy with high fidelity.\n- Flags ambiguities explicitly without inventing unsupported details.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{SCREENSHOT}}`; if details are unclear, state uncertainty in `notes`.\n- Do not invent hidden functionality or off-screen content.\n- Capture:\n  - overall layout and structure,\n  - color scheme,\n  - UI elements (interactive and non-interactive),\n  - text content,\n  - images/icons,\n  - hierarchy/positioning.\n- For each `ui_elements` item include `type`, `content`, `position`, and `style`.\n- Keep output as valid JSON only inside `<json_output>` tags (no prose outside JSON).\n\nFORMAT\nReturn exactly this structure:\n\n<json_output>\n{\n  \"overall_layout\": {\n    \"description\": \"\",\n    \"main_sections\": []\n  },\n  \"color_scheme\": {\n    \"primary_colors\": [],\n    \"secondary_colors\": [],\n    \"background_color\": \"\"\n  },\n  \"ui_elements\": [\n    {\n      \"type\": \"\",\n      \"content\": \"\",\n      \"position\": \"\",\n      \"style\": {}\n    }\n  ],\n  \"text_content\": [\n    {\n      \"type\": \"\",\n      \"content\": \"\",\n      \"position\": \"\"\n    }\n  ],\n  \"images_and_icons\": [\n    {\n      \"type\": \"\",\n      \"description\": \"\",\n      \"position\": \"\"\n    }\n  ],\n  \"notes\": []\n}\n</json_output>\n\nFAILURE\n- Output is not wrapped in `<json_output>` tags.\n- JSON is invalid or required top-level keys are missing.\n- `ui_elements` entries are missing `type`, `content`, `position`, or `style`.\n- Observations are generic and not grounded in visible screenshot evidence.\n- Ambiguities exist but `notes` is omitted.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Design & Prototyping/UX terminology improvements in product requirements.md",
      "title": "\"UX terminology improvements in product requirements\"",
      "category": "\"Design & Prototyping\"",
      "tags": [
        "ux",
        "product-requirements",
        "terminology",
        "content-review"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{PRODUCT_MANAGER_REQUIREMENTS}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: \"UX terminology improvements in product requirements\".\nSuccess metric:\n- Identifies incorrect or imprecise UX terminology in the requirements, when present.\n- Provides context-appropriate terminology corrections with clear rationale.\n- Avoids unnecessary edits when wording is already accurate.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{PRODUCT_MANAGER_REQUIREMENTS}}`; if context is missing, state assumptions explicitly.\n- Review terms in context; do not auto-replace words without justification.\n- For each correction, quote the original wording exactly.\n- Provide a correction only when it improves UX precision/clarity.\n- If no corrections are needed, explicitly return the no-change statement in the required schema.\n\nFORMAT\nReturn exactly this structure:\n\n<analysis>\n1. Original term: [Quote the original text]  \n   Correction: [Provide the corrected term or phrase]  \n   Explanation: [Briefly explain why this correction is necessary]\n\n2. Original term: [Quote the original text]  \n   Correction: [Provide the corrected term or phrase]  \n   Explanation: [Briefly explain why this correction is necessary]\n\n[Continue with additional corrections as needed]\n\n[If no corrections are required, return exactly:\n\"No corrections needed. The requirements use appropriate UX terminology.\"]\n</analysis>\n\nFAILURE\n- `<analysis>` section is missing or malformed.\n- Corrections are provided without quoting original text.\n- Explanations do not justify why the correction improves UX terminology precision.\n- Output changes terminology that is already context-appropriate without rationale.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Design & Prototyping/Workshop activity design from problem and participant parameters.md",
      "title": "\"Workshop activity design from problem and participant parameters\"",
      "category": "\"Design & Prototyping\"",
      "tags": [
        "workshops",
        "facilitation",
        "brainstorming",
        "product",
        "ux"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{PROBLEM}}\n- {{PARTICIPANTS}}\n- {{TIME_AVAILABLE}}\n- {{PLATFORM}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: \"Workshop activity design from problem and participant parameters\".\nSuccess metric:\n- Produces 3-5 distinct workshop activity variants tailored to problem, participants, time, and platform.\n- Each variant is facilitator-ready, includes exact timing, and is feasible within `{{TIME_AVAILABLE}}`.\n- Variants include practical tradeoffs, inclusion mechanics, and clear runbooks.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs; if any input is incomplete, state explicit assumptions per variant.\n- Generate 3-5 distinct variants.\n- Do not use XML or JSON anywhere in the response.\n- For each variant, total duration must be `<= {{TIME_AVAILABLE}}`, and timeline minute ranges must sum exactly to the stated total.\n- Adapt mechanics by participant size:\n  - `<=8`: whole-group flow with silent ideation first.\n  - `9-20`: pods of 3-5 with rotating roles/report-outs.\n  - `>20`: swarm + pods (4-6) + gallery walk + synthesis.\n- Adapt logistics by platform:\n  - `remote/hybrid`: breakout choreography and linked board flow.\n  - `in-person`: room setup, physical materials, visible timing controls.\n- Include inclusion and bias-mitigation mechanisms (silent write, timeboxing, anonymous voting, speaker rotation, accessibility notes).\n- Include practical Miro runbook guidance for intermediate users; if in-person-only with no Miro, write `Not applicable`.\n- Across the full set of variants, include at least:\n  - one rapid ideation pattern,\n  - one prioritization pattern,\n  - one synthesis pattern.\n- Keep language facilitator-ready and operational.\n\nFORMAT\nReturn exactly this structure:\n\nHere are multiple workshop activity variants designed to address the given problem(s):\n\n### Variant X: *[Activity Name]*\n**Assumptions**\n- [Assumptions]\n\n**Overview (2-3 sentences)**\n- [Overview]\n\n**Rationale**\n- [Why it fits problem, participants, time, platform]\n\n**Duration**\n- **Total minutes:** [N]\n\n**Timeline (minute-by-minute; sums to total)**\n- 00:00-00:XX — [Step]\n- 00:XX-00:YY — [Step]\n\n**Facilitator Process**\n1. [Concrete facilitator step with timing]\n2. [Concrete facilitator step with timing]\n- **Scaling notes:** [<=8 | 9-20 | >20 adaptations]\n- **If time slips +/-10%:** [What to shorten/extend]\n\n**Participant Process**\n1. [What participants do]\n2. [What participants produce/decide]\n\n**Miro Setup & Runbook (intermediate)**\n- [Board prep, frames, breakouts, timer, voting, mapping, export]\n- [If not applicable: \"Not applicable\"]\n\n**Inputs (bring to the workshop)**\n- [Inputs]\n\n**Outputs (created by the activity)**\n- [Outputs]\n\n**Pros**\n- [Pros]\n\n**Cons (with mitigations)**\n- [Cons + mitigation]\n\n[Repeat full variant structure for 3-5 variants]\n\nFAILURE\n- Opening line is missing or different from required text.\n- Fewer than 3 or more than 5 variants are provided.\n- Any variant exceeds `{{TIME_AVAILABLE}}` or timeline math does not sum to stated total.\n- Output contains XML or JSON.\n- Variant sections are missing required headings/items from `FORMAT`.\n- Participant-size and platform adaptations are not reflected.\n- Miro runbook is missing (or not marked `Not applicable` when appropriate).\n- Required pattern coverage across the set (rapid ideation, prioritization, synthesis) is incomplete.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Ideation & Creativity/Creative solution generation from De Bono's lateral thinking methodsods.md",
      "title": "\"Creative solution generation from De Bono's lateral thinking methods\"",
      "category": "\"Ideation & Creativity\"",
      "tags": [
        "ideation",
        "creativity",
        "lateral-thinking",
        "de-bono",
        "problem-solving",
        "product-management"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{PROBLEM}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: \"Creative solution generation from De Bono's lateral thinking methods\".\nSuccess metric:\n- Produces exactly 20 lateral provocations (`PO`) tied to the problem statement.\n- Each provocation is converted into at least one plausible new option through a named De Bono movement approach.\n- Provocations and options show clear variety (reversal, exaggeration, distortion, random connection).\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{PROBLEM}}`; if context is incomplete, state assumptions explicitly.\n- Generate exactly 20 provocations; each must begin with `PO:`.\n- Ensure coverage across provocation types:\n  - reversal,\n  - exaggeration,\n  - distortion,\n  - random connection.\n- For each provocation, apply at least one movement approach:\n  - Abandon, Ideal case, Reversal, Exaggeration, Fortuity, or Falsification.\n- For each provocation + approach, produce at least one concrete new option tied back to the original problem.\n- Keep options specific enough to be testable/explorable (not generic slogans).\n\nFORMAT\nReturn exactly this structure:\n\n<creative_reframing>\n<provocation_1>\nPO: [Your provocation statement]  \nApproach: [Approach used]  \nNew option: [Resulting idea or solution]\n</provocation_1>\n\n<provocation_2>\nPO: [Your provocation statement]  \nApproach: [Approach used]  \nNew option: [Resulting idea or solution]\n</provocation_2>\n\n[Continue for all 20 provocations]\n</creative_reframing>\n\nFAILURE\n- Root tag `<creative_reframing>` is missing, malformed, or incomplete.\n- Number of provocation blocks is not exactly 20.\n- One or more provocations do not start with `PO:`.\n- Any provocation block is missing `Approach` or `New option`.\n- Provocations lack variety across the required provocation types.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Ideation & Creativity/Creative solution generation from metaphorical thinking.md",
      "title": "\"Creative solution generation from metaphorical thinking\"",
      "category": "\"Ideation & Creativity\"",
      "tags": [
        "ideation",
        "creativity",
        "metaphor",
        "problem-solving",
        "perspective-shifting"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{ISSUE}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: \"Creative solution generation from metaphorical thinking\".\nSuccess metric:\n- Produces at least 3 issue metaphors with clear relevance to the issue.\n- Generates 20 distinct random activities and maps each to at least one meaningful similarity.\n- Selects one best metaphor from the activity list with a compelling rationale.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{ISSUE}}`; if context is incomplete, state assumptions explicitly.\n- Provide at least 3 metaphors directly representing the issue.\n- Generate exactly 20 random activities and avoid these examples: building a house, raising a child, cooking a meal.\n- For each activity, provide at least one explicit similarity to the issue.\n- Choose one best metaphor from the activity list (not from outside the list) and explain insight gained.\n- Keep connections concrete enough to inspire actionable reframing (not generic one-liners).\n\nFORMAT\nReturn exactly this structure:\n\n<output>\n<issue_metaphors>\n1. [Metaphor] - [How it relates to the issue]\n2. [Metaphor] - [How it relates to the issue]\n3. [Metaphor] - [How it relates to the issue]\n[Optional additional metaphors]\n</issue_metaphors>\n\n<random_activities>\n1. [Activity]\n2. [Activity]\n...\n20. [Activity]\n</random_activities>\n\n<activity_similarities>\n1. [Activity 1] - [Similarity to issue]\n2. [Activity 2] - [Similarity to issue]\n...\n20. [Activity 20] - [Similarity to issue]\n</activity_similarities>\n\n<best_metaphor>\n[State the activity you chose as the best metaphor and explain why]\n</best_metaphor>\n</output>\n\nFAILURE\n- Any required section/tag in `FORMAT` is missing, malformed, or incomplete.\n- Fewer than 3 issue metaphors are provided.\n- Random activities count is not exactly 20.\n- Any activity lacks a corresponding similarity mapping.\n- Best metaphor is not selected from the listed random activities.\n- Disallowed example activities are reused.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Ideation & Creativity/Innovative idea generation from project parameters and constraints.md",
      "title": "\"Innovative idea generation from project parameters and constraints\"",
      "category": "\"Ideation & Creativity\"",
      "tags": [
        "creativity",
        "idea-generation",
        "constraints",
        "product-management",
        "osborn-checklist"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{PROJECT_TYPE}}\n- {{GOALS}}\n- {{BUDGET}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: \"Innovative idea generation from project parameters and constraints\".\nSuccess metric:\n- Produces concrete, non-generic ideas that fit project type, goals, and budget.\n- Uses structured creativity analysis (including Osborn checklist) to move beyond obvious solutions.\n- Final ideas are immediately actionable with clear execution steps.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{PROJECT_TYPE}}`, `{{GOALS}}`, and `{{BUDGET}}`; if details are missing, state assumptions explicitly.\n- Provide exactly 5 banal ideas to avoid and explain why each is weak.\n- Define problem context including timeframe, target audience, and situation.\n- Break down problem into objective, constraints, measurable success criteria, challenges, and deeper considerations.\n- Analyze each chunk with explicit link to goals and budget feasibility.\n- Include both creator and consumer perspectives.\n- Apply Osborn checklist categories with project-relevant outputs:\n  - other uses, adaptations, modifications, magnification, minification, substitutions, rearrangements, reversals, combinations.\n- Final ideas must be actionable for an individual, feasible under budget, and include step-by-step instructions plus application context.\n\nFORMAT\nReturn exactly this structure:\n\n<creativity_analysis>\n<banal_ideas>\n1. [Banal idea] - [Why to avoid]\n2. [Banal idea] - [Why to avoid]\n3. [Banal idea] - [Why to avoid]\n4. [Banal idea] - [Why to avoid]\n5. [Banal idea] - [Why to avoid]\n</banal_ideas>\n\n<problem_definition>\n[Clearly define the problem or situation]\n</problem_definition>\n\n<problem_breakdown>\n[Break down the problem into key aspects]\n</problem_breakdown>\n\n<chunk_analysis>\n[Provide in-depth analysis of each problem chunk]\n</chunk_analysis>\n\n<perspectives>\n[Describe creator and consumer perspectives]\n</perspectives>\n\n<osborn_checklist>\n- Other uses: [Ideas]\n- Adaptations: [Ideas]\n- Modifications: [Ideas]\n- Magnification: [Ideas]\n- Minification: [Ideas]\n- Substitutions: [Ideas]\n- Rearrangements: [Ideas]\n- Reversals: [Ideas]\n- Combinations: [Ideas]\n</osborn_checklist>\n\n<final_ideas>\n1. [Idea title]\n   - Specific guidance: [What to do]\n   - Steps: [Step-by-step]\n   - Where/how to apply: [Context/channel/tool]\n   - Budget fit: [How it stays within budget]\n[Repeat for additional ideas]\n</final_ideas>\n</creativity_analysis>\n\nFAILURE\n- Any required section/tag in `FORMAT` is missing, malformed, or incomplete.\n- `banal_ideas` does not contain exactly 5 items.\n- One or more Osborn checklist categories are missing.\n- Final ideas are not actionable step-by-step or are not aligned to budget/goals.\n- Output is generic or repeats cliché ideas without meaningful differentiation.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Ideation & Creativity/Innovative idea generation from structured brainstorming techniques.md",
      "title": "\"Innovative idea generation from structured brainstorming techniques\"",
      "category": "\"Ideation & Creativity\"",
      "tags": [
        "brainstorming",
        "structured-ideation",
        "creativity",
        "product-discovery",
        "problem-solving"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{TOPIC}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: \"Innovative idea generation from structured brainstorming techniques\".\nSuccess metric:\n- Produces a structured ideation session using free association, mind mapping, SCAMPER, and bias checks.\n- Generates non-obvious, high-potential ideas grounded in the topic.\n- Outputs clear top ideas with rationale and a concise synthesis.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{TOPIC}}`; if scope is unclear, state assumptions explicitly.\n- Run a complete structured ideation flow:\n  - free association (4-6 rounds),\n  - mind map (3-4 levels),\n  - SCAMPER exploration (2-3 rounds across shortlisted branches),\n  - bias check,\n  - top-idea selection and rationale.\n- Avoid clichéd or overhyped ideas; prioritize specificity and novelty.\n- Ensure top ideas are distinct from one another and clearly connected to generated branches.\n- Keep outputs practical enough to be explored/prototyped next.\n\nFORMAT\nReturn exactly this structure:\n\n<ideation_session>\n<freeassociation>\n[4-6 rounds of free associations tied to `{{TOPIC}}`]\n</freeassociation>\n\n<mindmap>\n[Mind map with 3-4 branching levels derived from free associations]\n</mindmap>\n\n<shortlisted_branches>\n1. [Branch]\n2. [Branch]\n3. [Branch]\n</shortlisted_branches>\n\n<scamper>\n[2-3 rounds applying SCAMPER prompts to shortlisted branches]\n</scamper>\n\n<biascheck>\n- Anchoring check: [Findings/adjustment]\n- Status quo check: [Findings/adjustment]\n- Groupthink check: [Findings/adjustment]\n</biascheck>\n\n<top_ideas>\n1. [Idea 1]\n2. [Idea 2]\n3. [Idea 3]\n</top_ideas>\n\n<rationale>\n1. [Why idea 1 is powerful and non-obvious]\n2. [Why idea 2 is powerful and non-obvious]\n3. [Why idea 3 is powerful and non-obvious]\n</rationale>\n</ideation_session>\n\n<summary>\n1. [Idea 1]: [Rationale]\n2. [Idea 2]: [Rationale]\n3. [Idea 3]: [Rationale]\n</summary>\n\nFAILURE\n- Any required section/tag in `FORMAT` is missing, malformed, or incomplete.\n- `freeassociation` has fewer than 4 rounds or more than 6 rounds.\n- `mindmap` does not show 3-4 levels of branching.\n- `scamper` does not include at least 2 rounds.\n- `top_ideas` does not contain exactly 3 distinct ideas.\n- Rationales are generic and do not explain non-obvious value.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Ideation & Creativity/Innovative product ideas from structured brainstorming.md",
      "title": "\"Innovative product ideas from structured brainstorming\"",
      "category": "\"Ideation & Creativity\"",
      "tags": [
        "brainstorming",
        "product-ideas",
        "structured-ideation",
        "creativity",
        "product-management"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{TOPIC}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: \"Innovative product ideas from structured brainstorming\".\nSuccess metric:\n- Produces a complete structured brainstorming session from divergence to convergence.\n- Generates non-obvious product ideas grounded in the topic and validated via bias checks.\n- Returns exactly 3 top ideas with clear innovation rationale in abstract terms.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{TOPIC}}`; if scope is unclear, state assumptions explicitly.\n- Run all stages: free association, mind map, SCAMPER expansion, bias check, top-idea selection, summary.\n- Avoid banal, overhyped, or clichéd outputs.\n- Top ideas must be described abstractly; do not use specific tech buzzwords such as `AI`, `blockchain`, or `VR`.\n- Ensure ideas are distinct and traceable to earlier brainstorming artifacts.\n\nFORMAT\nReturn exactly this structure:\n\n<brainstorming_session>\n\n<free_association>\n1. [Word or phrase]\n2. [Word or phrase]\n...\n[Total 8-10 items]\n</free_association>\n\n<mind_map>\n[Topic]\n- [Main branch 1]\n  - [Sub-branch 1a]\n  - [Sub-branch 1b]\n- [Main branch 2]\n  - [Sub-branch 2a]\n  - [Sub-branch 2b]\n- [Main branch 3]\n  - [Sub-branch 3a]\n  - [Sub-branch 3b]\n[At least 3 main branches; each with 2-3 sub-branches]\n</mind_map>\n\n<scamper>\n- Branch: [Name]\n  - Technique 1: [SCAMPER letter + method]\n    - Application: [How applied]\n    - New ideas:\n      - [Idea]\n  - Technique 2: [SCAMPER letter + method]\n    - Application: [How applied]\n    - New ideas:\n      - [Idea]\n[Repeat for 3 branches]\n</scamper>\n\n<bias_check>\n- Bias: [Name]\n  - Evidence in ideas: [How it appears]\n  - Countermeasure: [Concrete action]\n[At least 1 bias]\n</bias_check>\n\n<top_ideas>\n1. [Idea title]\n   - Description (2-3 sentences): [Abstract description]\n   - Why innovative/non-obvious: [Rationale]\n   - Topic fit (abstract): [How it addresses topic]\n2. [Idea title]\n   - Description (2-3 sentences): [Abstract description]\n   - Why innovative/non-obvious: [Rationale]\n   - Topic fit (abstract): [How it addresses topic]\n3. [Idea title]\n   - Description (2-3 sentences): [Abstract description]\n   - Why innovative/non-obvious: [Rationale]\n   - Topic fit (abstract): [How it addresses topic]\n</top_ideas>\n\n<summary>\n[Brief recap of process and why final ideas are stronger after SCAMPER and bias checks]\n</summary>\n\n</brainstorming_session>\n\nFAILURE\n- Root tag `<brainstorming_session>` or any required sub-tag is missing, malformed, or incomplete.\n- `free_association` has fewer than 8 or more than 10 items.\n- `mind_map` has fewer than 3 main branches or insufficient sub-branches.\n- `scamper` does not cover 3 branches with 2 techniques each.\n- `top_ideas` does not contain exactly 3 ideas.\n- Top ideas include banned specific-technology terms (`AI`, `blockchain`, `VR`).\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Ideation & Creativity/Offbeat question generation from any topic.md",
      "title": "\"Offbeat question generation from any topic\"",
      "category": "\"Ideation & Creativity\"",
      "tags": [
        "creativity",
        "brainstorming",
        "questions",
        "perspective-shifting"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{TOPIC}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: \"Offbeat question generation from any topic\".\nSuccess metric:\n- Produces playful, imaginative, and topic-relevant offbeat questions.\n- Includes at least 3 offbeat \"why\" questions and at least 2 offbeat questions in other forms.\n- Questions show variety (comparisons, hypotheticals, absurd twists) rather than minor rewrites.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{TOPIC}}`; if topic scope is ambiguous, state assumptions explicitly.\n- Generate at least 3 offbeat `why` questions tied to the topic.\n- Generate at least 2 additional offbeat questions in non-`why` formats (for example: `what if`, `how come`, or other playful forms).\n- Keep questions imaginative and thought-provoking while staying topic-relevant.\n- Avoid repetitive templates and near-duplicate wording.\n\nFORMAT\nReturn exactly this structure:\n\n<offbeat_questions>\n<why_questions>\n1. [Your first \"why\" question]\n2. [Your second \"why\" question]\n3. [Your third \"why\" question]\n[Add more if you generate more than 3]\n</why_questions>\n\n<other_questions>\n1. [Your first other offbeat question]\n2. [Your second other offbeat question]\n[Add more if you generate more than 2]\n</other_questions>\n</offbeat_questions>\n\nFAILURE\n- Any required section/tag in `FORMAT` is missing, malformed, or incomplete.\n- Fewer than 3 `why` questions are provided.\n- Fewer than 2 `other_questions` are provided.\n- `other_questions` are all `why` questions.\n- Questions are repetitive or generic with no clear offbeat angle.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Presentation & Communication/Crisis communication plan from outage details and company context.md",
      "title": "Crisis communication plan from outage details and company context",
      "category": "Presentation & Communication",
      "tags": [
        "incident-response",
        "communication",
        "reliability",
        "postmortem",
        "stakeholders"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{OUTAGE_DETAILS}}\n- {{COMPANY_CONTEXT}}\n- {{STAKEHOLDERS}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Crisis communication plan from outage details and company context.\nSuccess metric:\n- Produces both a stakeholder communication plan and an internal post-mortem framework.\n- Communication plan is empathetic, transparent, role-specific, and time-sequenced.\n- Post-mortem framework is actionable with root cause analysis, lessons, and owners/deadlines.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{OUTAGE_DETAILS}}`, `{{COMPANY_CONTEXT}}`, and `{{STAKEHOLDERS}}`; if information is missing, state assumptions explicitly.\n- Analyze outage facts, company context, and stakeholder impact before drafting communications.\n- Prioritize stakeholders by outage impact and urgency.\n- For each stakeholder group include:\n  - tailored message (acknowledgment, empathy, immediate actions),\n  - channel(s),\n  - cadence/timeline,\n  - spokesperson and key talking points.\n- Post-mortem framework must include:\n  - incident timeline,\n  - response team,\n  - root cause analysis,\n  - stakeholder/business impact,\n  - lessons learned,\n  - action items with owners and deadlines.\n- Keep tone aligned with company values/style in `{{COMPANY_CONTEXT}}`.\n\nFORMAT\nReturn exactly this structure:\n\n<stakeholder_communication_plan>\n<stakeholder_prioritization>\n[Stakeholder groups ranked by impact/urgency with rationale]\n</stakeholder_prioritization>\n\n<core_message>\n[Shared core message acknowledging outage, empathy, and immediate actions]\n</core_message>\n\n<group_plans>\n- Stakeholder group: [Name]\n  - Concerns: [Primary concerns]\n  - Tailored message: [Message]\n  - Channels: [Email/status page/social/CSM/call/etc.]\n  - Timeline: [Initial notice, update cadence, resolution notice]\n  - Spokesperson: [Role/name]\n  - Talking points: [Bullets]\n[Repeat for each key stakeholder group]\n</group_plans>\n</stakeholder_communication_plan>\n\n<internal_postmortem_framework>\n<timeline_of_events>\n[Chronological sequence before/during/after outage]\n</timeline_of_events>\n\n<response_team>\n[People/roles involved in incident response]\n</response_team>\n\n<root_cause_analysis>\n[Detailed root cause(s), contributing factors, and evidence]\n</root_cause_analysis>\n\n<impact_assessment>\n[Impact by stakeholder group and business operations]\n</impact_assessment>\n\n<lessons_learned>\n[What was learned and what should change]\n</lessons_learned>\n\n<action_items>\n1. [Action] - Owner: [Role/name] - Deadline: [Date/timeframe]\n2. [Action] - Owner: [Role/name] - Deadline: [Date/timeframe]\n[Additional actions]\n</action_items>\n</internal_postmortem_framework>\n\nFAILURE\n- Either top-level required section is missing: `stakeholder_communication_plan` or `internal_postmortem_framework`.\n- Any required subsection in `FORMAT` is missing, malformed, or incomplete.\n- Stakeholder plans are not tailored by group or do not include channels/timeline/spokesperson.\n- Post-mortem is missing root cause analysis, impact assessment, or owned action items with deadlines.\n- Tone is misaligned with provided company context.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Presentation & Communication/Executive decks from Quick Dirty Test analysis.md",
      "title": "Executive decks from Quick Dirty Test analysis",
      "category": "Presentation & Communication",
      "tags": [
        "executive-communication",
        "decision-support",
        "hypothesis-testing",
        "risk-analysis",
        "quick-dirty-test"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{SLIDE_DECK_CONTEXT}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Executive decks from Quick Dirty Test analysis.\nSuccess metric:\n- Identifies critical assumptions and failure modes that executives would scrutinize.\n- Provides risk-dimensioning analyses and decision-driving questions.\n- Includes an executive-ready summary with practical deck-improvement recommendations.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{SLIDE_DECK_CONTEXT}}`; if information is missing, state assumptions explicitly.\n- Apply Quick Dirty Test logic:\n  - What must be true for the hypothesis/investment to succeed?\n  - How could the investment fail or \"blow up\"?\n- Prioritize items that materially affect executive go/no-go decisions.\n- Keep outputs concise, evidence-oriented, and directly usable for deck revisions.\n\nFORMAT\nReturn exactly this structure:\n\n<qdt_analysis>\n<key_assumptions>\n[List the key assumptions here, one per line]\n</key_assumptions>\n\n<potential_risks>\n[List the potential risks or ways the investment could fail, one per line]\n</potential_risks>\n\n<necessary_analyses>\n[List the analyses needed to support or reject the investment, one per line]\n</necessary_analyses>\n\n<key_questions>\n[List the key questions to dimension the risks, one per line]\n</key_questions>\n</qdt_analysis>\n\n<summary>\n[Brief findings summary and recommendations to strengthen the executive deck]\n</summary>\n\nFAILURE\n- `<qdt_analysis>` or `<summary>` is missing, malformed, or incomplete.\n- Any required subsection in `<qdt_analysis>` is missing.\n- Analysis is not executive-decision oriented (missing investment belief/failure logic).\n- Recommendations are generic and not actionable for deck improvement.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Presentation & Communication/Presentation narratives from conversation transcripts.md",
      "title": "Presentation narratives from conversation transcripts",
      "category": "Presentation & Communication",
      "tags": [
        "presentations",
        "storytelling",
        "executive-communication",
        "product-management",
        "research-synthesis"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{CONVERSATION_TRANSCRIPTS}}\n- {{PRESENTATION_TOPIC}}\n- {{TARGET_AUDIENCE}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Presentation narratives from conversation transcripts.\nSuccess metric:\n- Produces a coherent 3-arc presentation narrative grounded in transcript evidence.\n- Tailors narrative language and emphasis to the stated target audience.\n- Concludes with a clear buy-in request in Arc 3.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{CONVERSATION_TRANSCRIPTS}}`, `{{PRESENTATION_TOPIC}}`, and `{{TARGET_AUDIENCE}}`; if key context is missing, state assumptions explicitly.\n- Build exactly three arcs:\n  - Arc 1: Introduction and Problem Statement\n  - Arc 2: Proposed Solution or Approach\n  - Arc 3: Benefits and Implementation\n- Ground each arc in transcript themes, points, examples, or data.\n- Maintain logical transitions across arcs and audience-appropriate tone/detail.\n- Include `[VISUAL]` placeholders where charts, diagrams, or evidence visuals improve clarity.\n- Arc 3 must include a specific buy-in request (what approval/action is needed).\n- Keep narrative scope roughly suitable for a 10-15 slide deck.\n\nFORMAT\nReturn exactly this structure:\n\n<presentation_narrative>\n<arc1>\n[Write the narrative for Arc 1: Introduction and Problem Statement]\n</arc1>\n\n<arc2>\n[Write the narrative for Arc 2: Proposed Solution or Approach]\n</arc2>\n\n<arc3>\n[Write the narrative for Arc 3: Benefits and Implementation, including the buy-in request]\n</arc3>\n</presentation_narrative>\n\nFAILURE\n- Any required section/tag in `FORMAT` is missing, malformed, or incomplete.\n- Arc narratives are not grounded in provided transcripts/topic.\n- No `[VISUAL]` placeholders are included.\n- Arc 3 does not contain a concrete buy-in request.\n- Narrative is not audience-tailored or lacks coherent transitions.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Presentation & Communication/Presentations from 5-step storytelling framework.md",
      "title": "Presentations from 5-step storytelling framework",
      "category": "Presentation & Communication",
      "tags": [
        "presentations",
        "storytelling",
        "product-management",
        "communication"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{PRESENTATION_TOPIC}}\n- {{CURRENT_STEP}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Presentations from 5-step storytelling framework.\nSuccess metric:\n- Provides concrete guidance tailored to the specified current step in the 5-step process.\n- Integrates storytelling principles into step-specific presentation advice.\n- Ends with a clear request for user progress/questions to continue iteration.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{PRESENTATION_TOPIC}}` and `{{CURRENT_STEP}}`; if context is missing, state assumptions explicitly.\n- Tailor guidance to exactly one of these steps:\n  1. Paper outline\n  2. Paper storyboard\n  3. Headlines first\n  4. Fill them in\n  5. Practice\n- Guidance must include concrete next actions for the current step (not generic advice for all steps).\n- Integrate storytelling principles:\n  - hook/call,\n  - trial/tribulations,\n  - transformation/climax,\n  - return/call-to-action,\n  - tradeoffs/challenges.\n- Use practical language and suggest artifacts/checklists relevant to the selected step.\n- End by asking the user to share progress or questions.\n\nFORMAT\nReturn exactly this structure:\n\n<guidance>\n[Step-specific instructions for `{{CURRENT_STEP}}`, tailored to `{{PRESENTATION_TOPIC}}`, including storytelling integration]\n</guidance>\n\n<request>\n[Ask the user to share progress, draft output, or questions for the current step]\n</request>\n\nFAILURE\n- `<guidance>` or `<request>` is missing, malformed, or empty.\n- Guidance is not specific to the declared `{{CURRENT_STEP}}`.\n- Guidance omits storytelling principles or does not relate them to the step.\n- Request does not explicitly ask for user progress/questions.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Presentation & Communication/Presentations from structured content and context.md",
      "title": "Presentations from structured content and context",
      "category": "Presentation & Communication",
      "tags": [
        "presentations",
        "storytelling",
        "product-management",
        "communication"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{PRESENTATION_CONTENT}}\n- {{ADDITIONAL_CONTEXT}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Presentations from structured content and context.\nSuccess metric:\n- Produces a coherent slide narrative from provided content/context with clear logical flow.\n- Uses a \"What, So What, Now What?\" structure (or explains gaps when unavailable).\n- Delivers slide-ready outputs with concrete titles, layouts, and supporting points.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{PRESENTATION_CONTENT}}` and `{{ADDITIONAL_CONTEXT}}`; if information is missing, state assumptions explicitly.\n- Build a clear narrative flow using \"What, So What, Now What?\" as the default organizing model.\n- If one or more structure parts are missing in the source input, explicitly identify the gap and propose how to fill it.\n- Each slide must include:\n  - a descriptive, point-making title,\n  - layout guidance,\n  - main point with supporting points.\n- Add visual/chart suggestions only when supported by provided information; do not invent data.\n- Keep flow logical, audience-friendly, and suitable for direct deck production.\n\nFORMAT\nReturn exactly this structure:\n\n<presentation_plan>\n<introduction>\n[Purpose of the presentation and intended audience/context framing]\n</introduction>\n\n<structure_map>\n- What: [How the deck defines the topic/current state]\n- So What: [Why it matters; implications]\n- Now What: [Recommended actions/next steps]\n</structure_map>\n\n<slides>\nSlide 1: [Title]\nLayout: [Layout description]\nContent:\n- [Main point]\n  - [Supporting point 1]\n  - [Supporting point 2]\nVisual notes: [Chart/visual suggestion only if supported by provided inputs]\n\nSlide 2: [Title]\nLayout: [Layout description]\nContent:\n- [Main point]\n  - [Supporting point 1]\n  - [Supporting point 2]\nVisual notes: [Chart/visual suggestion only if supported by provided inputs]\n\n[Continue for all slides in logical order]\n</slides>\n\n<gaps_and_recommendations>\n[Missing \"What/So What/Now What\" elements and specific suggestions to complete them]\n</gaps_and_recommendations>\n\n<conclusion>\n[Key takeaways and clear next step/call to action]\n</conclusion>\n</presentation_plan>\n\nFAILURE\n- Any required section/tag in `FORMAT` is missing, malformed, or incomplete.\n- Slides are not organized into a coherent \"What, So What, Now What?\" flow.\n- Slide titles do not convey main points.\n- Visual/chart notes include unsupported or invented data.\n- Missing-structure gaps are present in input but not acknowledged with recommendations.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Presentation & Communication/Press releases from product vision (Working Backwards).md",
      "title": "Press releases from product vision (Working Backwards)",
      "category": "Presentation & Communication",
      "tags": [
        "storytelling",
        "press-release",
        "working-backwards",
        "product-strategy",
        "communication",
        "influence"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{PRODUCT_OR_SERVICE}}\n- {{TARGET_PERSONAS}}\n- {{FEATURES_USPS}}\n- {{COMPANY_CONTEXT}}\n- {{PROBLEMS_GOALS}}\n- {{EVIDENCE_METRICS}}\n- {{AUDIENCES_CHANNELS}}\n- Optional: {{LAUNCH_DATE_PRICING_AVAILABILITY}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Press releases from product vision (Working Backwards).\nSuccess metric:\n- Produces a credible Working Backwards-style launch press release that is specific and evidence-backed.\n- Includes exactly two quotes (executive + customer/partner) and at least one concrete proof point.\n- Clearly states availability/pricing/requirements and a direct call to action.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs; if required launch details are missing, use bracketed placeholders like `[CITY]`, `[DATE]`, `[STAT]`.\n- If placeholders are used, append a short `Fill These Gaps` checklist once after the release.\n- Output must be Markdown only (no XML/JSON wrappers).\n- Target length: 350-550 words (plus Media Contact block).\n- Tone: visionary but plain-spoken, AP-style clarity, active voice, short paragraphs.\n- Avoid hype words (for example `revolutionary`, `game-changing`) unless in quotes.\n- Include at least one concrete proof point (metric, benchmark, ROI, independent signal, certification, or analyst note).\n- Include exactly two quotes:\n  - one executive quote (vision/why now),\n  - one customer/partner quote (outcome/benefit).\n- Use the structure labels in `FORMAT` verbatim.\n- Convert each feature into a clear user/business outcome.\n- No unverifiable regulated claims, no competitor bashing, no guaranteed-future promises.\n\nFORMAT\nReturn exactly this structure:\n\n# [Product Name]\nSubhead: [One-line value proposition]\n\nDateline: [CITY], [STATE/PROVINCE], [COUNTRY] — [MONTH DAY, YEAR]\n\n**Lede (Intro, 2-3 sentences):**\n[Announcement summary with who/what/for whom/outcome]\n\n**Body Paragraph (What it does & why it matters):**\n[How it works, why now, and executive quote]\n\n**Feature Highlights:**\n- [Feature 1]: [What it is] -> [Outcome]\n- [Feature 2]: [What it is] -> [Outcome]\n- [Feature 3]: [What it is] -> [Outcome]\n[Optional features 4-6]\n\n**Evidence & Context:**\n[At least one concrete proof point with precise number/signal]\n\n**Customer/Partner Quote:**\n\"[Outcome-focused quote],\" said [Name, Title, Company].\n\n**Availability, Pricing, Requirements:**\n- Availability: [Date/Region/Tiers]\n- Pricing: [Model/Currency/Tiers]\n- Requirements: [Integrations/devices/plans/compliance prerequisites]\n\n**Call to Action:**\n[Learn more/contact/demo links]\n\n**Boilerplate:**\n[Company background, mission, and relevant credibility]\n\n**Media Contact**\n[Name] — [Title]\nPhone: [Number] • Email: [Email]\nPress Kit: [Link]\n\n[Optional: Fill These Gaps\n- [Missing item 1]\n- [Missing item 2]]\n\nFAILURE\n- Required section labels from `FORMAT` are missing, renamed, malformed, or incomplete.\n- Word count is materially outside 350-550 (excluding Media Contact).\n- Not exactly two quotes, or quotes are not executive + customer/partner types.\n- No concrete proof point is included.\n- Feature bullets do not translate to outcomes.\n- Placeholder gaps exist but `Fill These Gaps` is missing.\n- Output contains XML/JSON wrappers.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Presentation & Communication/Pyramid structure optimization from complex text.md",
      "title": "Pyramid structure optimization from complex text",
      "category": "Presentation & Communication",
      "tags": [
        "writing",
        "storytelling",
        "presentations",
        "structured-thinking"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{TEXT_TO_OPTIMIZE}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Pyramid structure optimization from complex text.\nSuccess metric:\n- Produces a clear Minto-style pyramid with one key message and 2-3 supporting arguments.\n- Uses only evidence/details traceable to the source text.\n- Improves clarity and concision while preserving core meaning.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{TEXT_TO_OPTIMIZE}}`; if key context is missing, state assumptions explicitly.\n- Identify exactly one key message.\n- Provide 2-3 supporting arguments (no more than 3).\n- Attach evidence/details for each argument using source-grounded points only.\n- Lead with conclusion first, then grouped support (Minto Pyramid Principle).\n- Keep wording concise and structured; avoid unnecessary prose.\n\nFORMAT\nReturn exactly this structure:\n\n<optimized_text>\nKey Message: [Insert the main conclusion or recommendation]\n\nSupporting Arguments:\n1. [First main argument]\n   - [Evidence or detail]\n   - [Evidence or detail]\n\n2. [Second main argument]\n   - [Evidence or detail]\n   - [Evidence or detail]\n\n3. [Third main argument (if applicable)]\n   - [Evidence or detail]\n   - [Evidence or detail]\n</optimized_text>\n\n<explanation>\n[Brief explanation of what was changed and why communication is clearer]\n</explanation>\n\nFAILURE\n- `<optimized_text>` or `<explanation>` is missing, malformed, or incomplete.\n- More than one key message is provided.\n- Fewer than 2 or more than 3 supporting arguments are provided.\n- Supporting evidence is generic or not traceable to the source text.\n- Structure starts with details instead of the key message.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Presentation & Communication/Skimmable writing transformation.md",
      "title": "Skimmable writing transformation",
      "category": "Presentation & Communication",
      "tags": [
        "writing",
        "editing",
        "clarity",
        "structure"
      ],
      "content": "INPUTS\n<provided_inputs>\n- [No explicit variables declared; use provided context.]\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Skimmable writing transformation.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Follow these task requirements:\n<task_requirements>\nYou are a writing transformer. Rewrite the provided content so it is crystal-clear and easy to skim by using explicit signposting language throughout.\n\n## Inputs\n\n* CONTENT: the raw text to transform  \n* AUDIENCE: who this is for (e.g., execs, peers, customers)  \n* GOAL: what you want the audience to think/do after reading  \n* LENGTH (optional): target word count  \n\n## Output Requirements\n\nProduce a single, self-contained text that:\n\n* Opens with the point and why it matters (Bottom Line Up Front).\n* Uses full sentences (not fragments).\n* Is concise (high information density; cut fluff, keep meaning).\n* Minimizes formatting; prefer words over bolding.\n* Is organized with numbered sections and clear transitions.\n\n## Structure Template (use/adjust as needed)\n\n1. In short, [1-sentence core point + why it matters to AUDIENCE].  \n2. Context: [Because…] [What problem/opportunity this addresses.]  \n3. What we’re proposing: First, … Second, … Third, …  \n4. Evidence & reasoning: Because … For example, … Therefore, …  \n5. Risks & objections (MOO): You might be wondering, … Our approach: …  \n6. As a next step, [specific ask, owner, and timing].  \n7. If you remember one thing, [1-sentence takeaway].  \n\n## Signposting Palette (use liberally to guide the reader)\n\nUse these phrases to make the structure explicit:\n\n* In short, / Bottom line: (thesis)  \n* Context: / Here’s why this matters: (setup)  \n* First, Second, Third, (ordered points)  \n* Because … / Therefore … (logic)  \n* For example, (illustration)  \n* In contrast, / However, (turn)  \n* As a result, (implication)  \n* You might be wondering, / A fair concern is, (anticipate objections)  \n* So what? / What this means is, (meaning)  \n* As a next step, (action)  \n* If you remember one thing, (recap)  \n\n## Editing Pass (do this before finalizing)\n\nBefore you present the final answer:\n\n* Cut 20–40% of words that don’t change meaning.  \n* Replace jargon with plain terms suitable for AUDIENCE.  \n* Promote specifics: dates, owners, numbers.  \n* Turn bullets into sentences where logic needs to be explicit.  \n* Check flow: each paragraph should begin with a signpost that previews its role.  \n* MOO (Most Obvious Objection) check: add one sentence that answers the most obvious objection.\n\n## Edge Cases\n\n* If CONTENT is very short, still add “In short,” and “As a next step,” lines.  \n* If evidence is missing, write “Because …” using first-principles reasoning and add “For example …” with a plausible illustration, clearly labeled as such.  \n* If GOAL is unclear, infer a reasonable one and make it explicit in the opening.\n\n## Style Constraints\n\n* Tone: direct, neutral-to-supportive, no hype.  \n* Sentences: mostly short to medium; one idea per sentence.  \n* Prefer verbs over nouns; use active voice.\n\n---\n\nNow transform:\n\n* AUDIENCE: [insert]  \n* GOAL: [insert]  \n* LENGTH: [optional]  \n* CONTENT:  \n  [insert]\n</task_requirements>\n\nFORMAT\nReturn exactly this structure:\n\n<deliverable>\n[Provide the complete response with clear sections that satisfy all required tasks.]\n</deliverable>\n\nFAILURE\n- Output misses required sections, steps, or reasoning required by `<task_requirements>`.\n- Required format/schema is missing, malformed, or incomplete.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Presentation & Communication/Slide decks from problem statements and context.md",
      "title": "Slide decks from problem statements and context",
      "category": "Presentation & Communication",
      "tags": [
        "presentations",
        "storytelling",
        "communication",
        "decision-making",
        "product-management"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{PROBLEM_STATEMENT}}\n- {{ADDITIONAL_CONTEXT}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Slide decks from problem statements and context.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Follow these task requirements:\n<task_requirements>\nYou are now the world's most convincing, clear, and intelligent management consultant. Your task is to create the most succinct, data-packed, informative, and convincing PowerPoint/slide deck in the world. You will craft guidance for each slide, including layout ideas and specific placement of elements on the canvas.\n\nYou will be given a problem statement and additional context. Use this information to create your slide deck outline.\n\nProblem Statement:\n<problem_statement>\n{{PROBLEM_STATEMENT}}\n</problem_statement>\n\nAdditional Context:\n<additional_context>\n{{ADDITIONAL_CONTEXT}}\n</additional_context>\n\nFollow these guidelines to create your slide deck:\n\n1. **Overall Structure:**\n   - Use the \"What, So What, Now What\" flow of logic.\n   - Comply with the Pyramid Principle by Barbara Minto/McKinsey.\n\n2. **Slide Flow:**\n   - Each slide must answer the question raised by the previous slide.\n   - Ensure a logical flow towards the recommended conclusion.\n\n3. **Individual Slide Creation:**\n   - Every slide should have a title in the form of a question.\n   - The content of the slide should answer that question with supporting details.\n   - Craft specific layout guidance for each slide, stating what element goes where on the canvas.\n\n4. **Content Guidelines:**\n   - Be concise and data-driven.\n   - Ensure each piece of information serves a purpose in building your argument.\n   - Use visuals, charts, and graphs where appropriate to convey information effectively.\n\nNow, create your slide deck outline. For each slide, provide the following:\n\n\n\nBegin your outline with an executive summary slide and end with a conclusion and next steps slide. Aim for 8–12 slides in total, depending on the complexity of the problem statement.\n\nAfter creating your slide deck outline, provide a brief explanation of how your outline adheres to the \"What, So What, Now What\" structure and the Pyramid Principle.\n\nPresent your complete slide deck outline and explanation within `<slide_deck_proposal>` tags.\n</task_requirements>\n\nFORMAT\nReturn exactly this structure:\n\n<slide_outline>\nSlide [Number]: [Question Title]  \nPurpose: [Brief description of the slide's purpose]  \nKey Points:\n- [Point 1]\n- [Point 2]\n- [Point 3]\n\nLayout Guidance:  \n[Describe the layout, including placement of title, key points, and any visual elements]\n</slide_outline>\n\nFAILURE\n- Output misses required sections, steps, or reasoning required by `<task_requirements>`.\n- Required format/schema is missing, malformed, or incomplete.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Presentation & Communication/Strategic presentation planning from topic, audience and time inputs.md",
      "title": "Strategic presentation planning from topic, audience and time inputs",
      "category": "Presentation & Communication",
      "tags": [
        "presentations",
        "storytelling",
        "stakeholder-management",
        "strategy"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{PRESENTATION_TOPIC}}\n- {{TARGET_AUDIENCE}}\n- {{TIME_CONSTRAINT}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Strategic presentation planning from topic, audience and time inputs.\nSuccess metric:\n- Produces a complete presentation framework tailored to topic, audience, and time constraint.\n- Includes a concrete audience matrix, SCQA narrative, and pyramid logic with supporting evidence needs.\n- Provides slide layout guidance and delivery preparation tuned to the audience.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{PRESENTATION_TOPIC}}`, `{{TARGET_AUDIENCE}}`, and `{{TIME_CONSTRAINT}}`; if context is missing, state assumptions explicitly.\n- Build a strategic foundation with a detailed audience matrix and explicit purpose/decision criteria.\n- Use SCQA for narrative framing and pyramid logic for justification structure.\n- Provide slide layout strategy tied to content types and time constraint.\n- Include QA checks and delivery preparation tailored to audience and time.\n\nFORMAT\nReturn exactly this structure:\n\n<framework>\n1. Strategic Foundation\n   [Include your audience analysis and presentation purpose definition]\n\n2. Narrative Architecture\n   [Present your SCQA framework and Pyramid Principle structure]\n\n3. Slide Development\n   [Outline your slide selection strategy and design principles]\n\n4. Quality Assurance\n   [List key points for review]\n\n5. Preparation & Delivery\n   [Provide notes on content mastery and delivery adaptation]\n</framework>\n\nFAILURE\n- Any required numbered section in `FORMAT` is missing, malformed, or incomplete.\n- Audience analysis lacks a matrix across power, expertise, bias, history, style, and politics.\n- SCQA or pyramid logic is missing or not tied to the topic.\n- Slide development guidance does not reflect time constraint or content type.\n- QA checks are missing or superficial.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Presentation & Communication/Structured insight extraction from conversation transcripts.md",
      "title": "Structured insight extraction from conversation transcripts",
      "category": "Presentation & Communication",
      "tags": [
        "conversation-analysis",
        "transcripts",
        "insight-extraction",
        "presentation",
        "communication"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{CONVERSATION_TRANSCRIPT}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Structured insight extraction from conversation transcripts.\nSuccess metric:\n- Produces a faithful, structured reconstruction of the conversation flow and outcomes.\n- Identifies participants, branches, responsibilities, current status, and open items.\n- Keeps all claims grounded in the transcript without adding assumptions.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{CONVERSATION_TRANSCRIPT}}`; do not infer roles or tasks not stated.\n- Identify all participants and their roles (if roles are unclear, note `Unknown`).\n- Summarize conversation flow and any branching points.\n- Capture participant responsibilities and open items explicitly mentioned.\n- Keep output strictly within the required tags; no scratchpad in final output.\n\nFORMAT\nReturn exactly this structure:\n\n<analysis>\n<participants>\n[List of participants and their roles]\n</participants>\n\n<conversation_flow>\n[Summary of the conversation's progression]\n</conversation_flow>\n\n<conversation_branches>\n[List of significant branches or shifts in the conversation]\n</conversation_branches>\n\n<participant_responsibilities>\n[Summary of each participant's tasks or responsibilities]\n</participant_responsibilities>\n\n<current_status>\n[Summary of where the conversation has landed]\n</current_status>\n\n<open_items>\n[List of any open questions or tasks]\n</open_items>\n</analysis>\n\nFAILURE\n- Any required section/tag in `FORMAT` is missing, malformed, or incomplete.\n- Participants or responsibilities are inferred without transcript evidence.\n- Open items are missing or not tied to the transcript.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Product Strategy/Adaptive planning from scenarios to strategic actions.md",
      "title": "Adaptive planning from scenarios to strategic actions",
      "category": "Product Strategy",
      "tags": [
        "strategic-planning",
        "facilitation",
        "product-management",
        "decision-making",
        "frameworks"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{CURRENT_STATE}}\n- {{PROJECTED_MESS}}\n- {{IDEAL_FUTURE}}\n- {{IDEAL_CURRENT_STATE}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Adaptive planning from scenarios to strategic actions.\nSuccess metric:\n- Produces a complete four-quadrant analysis and feedback loop grounded in the provided scenarios.\n- Identifies concrete adjustments and capabilities to avoid the projected mess and enable the ideal future.\n- Ends with a concise, actionable plan with specific next steps.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{CURRENT_STATE}}`, `{{PROJECTED_MESS}}`, `{{IDEAL_FUTURE}}`, and `{{IDEAL_CURRENT_STATE}}`; if missing data is critical, state assumptions explicitly.\n- Address all four quadrants and the feedback loop, grounded in provided inputs.\n- Keep analysis specific and actionable; avoid generic leadership or capability lists.\n- Action plan must include concrete steps that bridge current to ideal while mitigating projected mess.\n\nFORMAT\nReturn exactly this structure:\n\n<adaptive_planning_analysis>\n<quadrant_1_analysis>\n[Your analysis of the Current State]\n</quadrant_1_analysis>\n\n<quadrant_2_analysis>\n[Your analysis of the Projected Mess]\n</quadrant_2_analysis>\n\n<quadrant_3_analysis>\n[Your analysis of the Ideal Future]\n</quadrant_3_analysis>\n\n<quadrant_4_analysis>\n[Your analysis of the Ideal Current State]\n</quadrant_4_analysis>\n\n<feedback_loop_analysis>\n<current_state_adjustments>\n[Your recommendations for current state adjustments]\n</current_state_adjustments>\n\n<avoiding_projected_mess>\n[Your recommendations for avoiding the projected mess]\n</avoiding_projected_mess>\n\n<enabling_ideal_future>\n[Your recommendations for enabling the ideal future]\n</enabling_ideal_future>\n</feedback_loop_analysis>\n\n<summary_and_action_plan>\n[Your concise summary and specific, actionable steps]\n</summary_and_action_plan>\n</adaptive_planning_analysis>\n\nFAILURE\n- Any required section/tag in `FORMAT` is missing, malformed, or incomplete.\n- Feedback loop omits one of the three adjustment categories.\n- Action plan lacks concrete, actionable steps linked to the quadrants.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Product Strategy/Business flywheel from company successes and failures.md",
      "title": "Business flywheel from company successes and failures",
      "category": "Product Strategy",
      "tags": [
        "strategy",
        "flywheel",
        "hedgehog-concept",
        "retrospectives",
        "business-model"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{COMPANY_INFO}}\n- {{SUCCESSES}}\n- {{DISAPPOINTMENTS}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Business flywheel from company successes and failures.\nSuccess metric:\n- Produces a 4–6 component flywheel grounded in successes and disappointments.\n- Explains the causal loop and how it reinforces outcomes.\n- Connects the flywheel to Hedgehog Concept alignment.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{COMPANY_INFO}}`, `{{SUCCESSES}}`, and `{{DISAPPOINTMENTS}}`; if information is missing, state assumptions explicitly.\n- Identify 4–6 flywheel components only; consolidate if more.\n- Describe the causal loop explicitly (component -> component).\n- Validate the flywheel against successes and disappointments (explain fit and gaps).\n- Map the flywheel to the Hedgehog Concept circles.\n- Keep outputs specific and evidence-grounded; avoid generic platitudes.\n\nFORMAT\nReturn exactly this structure:\n\n<flywheel_analysis>\n<components>\nList the 4–6 key components you've identified.\n</components>\n\n<flywheel_sketch>\nDescribe the flywheel, explaining how each component leads to the next in a self-reinforcing loop.\n</flywheel_sketch>\n\n<success_alignment>\nExplain how the flywheel aligns with and explains the company's successes.\n</success_alignment>\n\n<disappointment_insights>\nDescribe how the flywheel provides insights into the company's disappointments or failures.\n</disappointment_insights>\n\n<hedgehog_alignment>\nDiscuss how the flywheel aligns with the three circles of the Hedgehog Concept.\n</hedgehog_alignment>\n</flywheel_analysis>\n\nFAILURE\n- Any required section/tag in `FORMAT` is missing, malformed, or incomplete.\n- Number of flywheel components is outside 4–6.\n- Flywheel sketch does not show a clear causal loop.\n- Alignment sections are generic or not tied to provided inputs.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Product Strategy/Business strategy creation from expert strategic thinking.md",
      "title": "Business strategy creation from expert strategic thinking",
      "category": "Product Strategy",
      "tags": [
        "strategy",
        "decision-making",
        "business",
        "leadership"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{USER_INPUT}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Business strategy creation from expert strategic thinking.\nSuccess metric:\n- Provides crisp, actionable strategic guidance tailored to the user's input.\n- Either asks targeted clarifying questions or delivers a structured strategy response.\n- Keeps advice grounded in SWOT and coherent strategic logic.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{USER_INPUT}}`; if context is insufficient, ask targeted questions first.\n- Keep responses concise, direct, and free of hype or AI references.\n- Ground guidance in strengths, weaknesses, opportunities, and threats.\n- Provide coherent strategy logic with concrete next steps and priorities.\n- If providing a plan, include short-term and long-term goals plus momentum flywheels.\n\nFORMAT\nReturn exactly this structure:\n\n<strategy_consultant>Your message here</strategy_consultant>\n\nFAILURE\n- `<strategy_consultant>` wrapper is missing or malformed.\n- Response is overly verbose, abstract, or generic.\n- Guidance ignores SWOT or lacks concrete priorities/actions.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Product Strategy/Competitive Advantage Diagnostics and Moat Strategy.md",
      "title": "Competitive Advantage Diagnostics and Moat Strategy",
      "category": "Product Strategy",
      "tags": [
        "strategy",
        "competitive-advantage",
        "moats",
        "7-powers"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{BUSINESS_NAME}}\n- {{ONE_LINER}}\n- {{STAGE}}\n- {{BUSINESS_MODEL}}\n- {{UNIT_ECONOMICS}}\n- {{SCALE}}\n- {{PRODUCT_USAGE}}\n- {{DATA_IP_RESOURCES}}\n- {{GTM}}\n- {{COMPETITION}}\n- {{CONSTRAINTS}}\n- {{TIME_HORIZON}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Competitive Advantage Diagnostics and Moat Strategy.\nSuccess metric:\n- Diagnoses which of the 7 Powers are present, emerging, or absent with evidence-linked benefits and barriers.\n- Provides acquisition playbooks for missing powers with concrete steps and KPIs.\n- Produces a prioritized 30/60/90 plan and red-team risks with validation tests.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs; if key inputs are missing, state assumptions explicitly (do not ask questions in the output).\n- For every claimed advantage, pair benefit + barrier; no barrier means no Power.\n- Diagnose each of the 7 Powers as Present/Emerging/Absent with evidence and confidence.\n- Provide acquisition playbooks for each Absent/Emerging power with concrete actions and KPIs.\n- Include 30/60/90 actions and a red-team section with falsification tests.\n- Keep claims specific, measurable, and grounded in inputs.\n\nFORMAT\nReturn exactly this structure:\n\n### A) Summary Table\n\n| Power | Status (Present/Emerging/Absent) | Benefit | Barrier | Evidence & Metrics | Confidence | Trend (↑/→/↓) | Stage Fit |\n| ----- | -------------------------------- | ------- | ------- | ------------------ | ---------: | :-----------: | --------- |\n\n### B) Verdict (<=120 words)\n\n[Plain-English call on sustainability of advantage.]\n\n### C) Acquisition Playbooks (for each Absent/Emerging power)\n\n**[Power Name]**\n- Prerequisites: [List]\n- Plays (3-5): [Concrete steps]\n- 12-24 mo roadmap: [Milestones]\n- KPIs & leading indicators: [Metrics + targets]\n- Risks & countermeasures: [Bullets]\n- Stop/kill criteria: [Bullets]\n\n### D) 30/60/90\n\n- 30 days: [Top 3 actions with owner, resources, success metric]\n- 60 days: [Top 3 actions with owner, resources, success metric]\n- 90 days: [Top 3 actions with owner, resources, success metric]\n\n### E) Red Team\n\n1. [Why this could be wrong] - [How to test]\n2. [Why this could be wrong] - [How to test]\n3. [Why this could be wrong] - [How to test]\n\nFAILURE\n- Any required section/table from `FORMAT` is missing, malformed, or incomplete.\n- Any power marked Present/Emerging lacks a clear benefit+barrier pairing.\n- Acquisition playbooks are missing for any Absent/Emerging power.\n- 30/60/90 actions lack owners, resources, or success metrics.\n- Red-team section lacks falsification tests.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Product Strategy/Competitive analysis to winning positioning strategy.md",
      "title": "Competitive analysis to winning positioning strategy",
      "category": "Product Strategy",
      "tags": [
        "positioning",
        "competition",
        "product-marketing",
        "differentiation"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{COMPETITIVE_ANALYSIS}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Competitive analysis to winning positioning strategy.\nSuccess metric:\n- Produces a data-backed positioning strategy grounded in competitive analysis.\n- Identifies 3–5 clear differentiators with customer-relevant rationale.\n- Outputs a concise, compelling value proposition and the reasoning behind it.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{COMPETITIVE_ANALYSIS}}`; if data is missing, state assumptions explicitly.\n- Identify 3–5 differentiators grounded in the competitive analysis.\n- For each differentiator, explain customer value and competitive significance.\n- Define a clear target audience and market position based on evidence.\n- Value proposition must answer “why choose us” without introducing unsupported claims.\n\nFORMAT\nReturn exactly this structure:\n\n<differentiators>\n1. [Differentiator] - [Why it matters to customers] - [Evidence from analysis]\n2. [Differentiator] - [Why it matters to customers] - [Evidence from analysis]\n3. [Differentiator] - [Why it matters to customers] - [Evidence from analysis]\n[Optional 4th/5th differentiator]\n</differentiators>\n\n<positioning_strategy>\n[Target audience, market position, and how differentiators map to customer needs and gaps]\n</positioning_strategy>\n\n<unique_value_proposition>\n[Concise statement answering why choose us]\n</unique_value_proposition>\n\n<rationale>\n[Explain reasoning with explicit references to competitive analysis]\n</rationale>\n\nFAILURE\n- Any required section/tag in `FORMAT` is missing, malformed, or incomplete.\n- Fewer than 3 or more than 5 differentiators are provided.\n- Positioning or value proposition is not grounded in provided analysis.\n- Rationale lacks evidence references.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Product Strategy/Competitive parity and strategic differentiation.md",
      "title": "\"Competitive parity and strategic differentiation\"",
      "category": "\"Product Strategy\"",
      "tags": [
        "competitive-analysis",
        "differentiation",
        "product-strategy",
        "decision-making"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{COMPETITIVE_FEATURE}}\n- {{COMPETITOR_CONTEXT}}\n- {{OUR_PRODUCT_STRATEGY}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: \"Competitive parity and strategic differentiation\".\nSuccess metric:\n- Produces a clear parity-vs-differentiation decision grounded in competitive context and product strategy.\n- Distinguishes table-stakes matching from strategic differentiation, leapfrogging, or deliberate skipping.\n- Provides actionable implementation guidance and monitoring signals tied to the recommendation.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{COMPETITIVE_FEATURE}}`, `{{COMPETITOR_CONTEXT}}`, and `{{OUR_PRODUCT_STRATEGY}}`; if information is missing, state assumptions explicitly.\n- Analyze competitor capability, UX, target users/use cases, and positioning before recommending action.\n- Classify strategic importance as one of: Table Stakes, Valuable Differentiator, Non-Essential, Strategic Distraction.\n- Evaluate four paths: do better, do differently, leapfrog, skip.\n- Frame decisions as strategy-led (serving our users and positioning), not reactive feature copying.\n- Include user/market implications, recommendation rationale, implementation guidance, and ongoing monitoring metrics/signals.\n- Keep claims specific and evidence-oriented; avoid generic statements.\n\nFORMAT\nReturn exactly this structure:\n\n<competitive_strategy_analysis>\n<competitive_feature_analysis>\n**What Competitor Built:**  \n[Describe capabilities and UX approach]\n\n**Why They Built It:**  \n[Infer strategic intent: what user need, what market position, what business goal]\n\n**Who It Serves:**  \n[Target users and use cases]\n\n**How They Positioned It:**  \n[Marketing/messaging angle]\n\n**Market Reception:**  \n[If known: user feedback, adoption, impact]\n</competitive_feature_analysis>\n\n<strategic_importance_assessment>\n**Classification:**  \n[Select one: Table Stakes / Valuable Differentiator / Non-Essential / Strategic Distraction]\n\n**Rationale:**  \n[Explain the classification]\n\n**Evidence:**\n- User feedback: [What users say about this]  \n- Market trends: [Industry direction]  \n- Win/loss data: [If relevant to deals]  \n- Strategic alignment: [How it fits our positioning]  \n\n**Risk of Not Having:**\n- Deal losses: [High/Medium/Low]  \n- User churn: [High/Medium/Low]  \n- Perception damage: [High/Medium/Low]  \n\n**Opportunity Cost:**  \n[What else could we build with the same investment]\n</strategic_importance_assessment>\n\n<differentiation_opportunities>\n<opportunity_1_better>\n**Do It Better:**  \n[How we could execute this more effectively than competitor]\n\n**Our Advantages:**  \n[What unique capabilities or context we have]\n\n**User Value:**  \n[How users benefit from our better approach]\n\n**Effort:**  \n[High/Medium/Low to achieve superior execution]\n</opportunity_1_better>\n\n<opportunity_2_different>\n**Do It Differently:**  \n[Alternative approach that serves our users better]\n\n**Why This Works for Us:**  \n[How it aligns with our strategy and user base]\n\n**User Value:**  \n[Why users would prefer this approach]\n\n**Risks:**  \n[What could go wrong with being different]\n</opportunity_2_different>\n\n<opportunity_3_leapfrog>\n**Leapfrog:**  \n[More advanced approach that makes competitor's solution look dated]\n\n**Innovation:**  \n[What's novel about this approach]\n\n**User Value:**  \n[Why this is significantly better]\n\n**Feasibility:**  \n[Can we actually pull this off? What's required?]\n\n**Risk:**  \n[Execution risk and market risk]\n</opportunity_3_leapfrog>\n\n<opportunity_4_skip>\n**Skip Entirely:**  \n[Case for not building this at all]\n\n**Alternative:**  \n[What we do instead that serves users differently]\n\n**Rationale:**  \n[Why skipping aligns with our strategy]\n\n**Communication:**  \n[How to position our absence of this feature]\n</opportunity_4_skip>\n</differentiation_opportunities>\n\n<user_market_implications>\n**User Expectations:**  \n[What users now expect based on competitor precedent]\n\n**Expectation Flexibility:**  \n[Where users are open to alternatives vs. locked into patterns]\n\n**Innovation Readiness:**  \n[Would users welcome innovation here or is familiarity valued?]\n\n**Education Required:**  \n[If we differentiate, what teaching is needed?]\n\n**Competitive Messaging:**  \n[How to position our approach vs. competitor]\n</user_market_implications>\n\n<recommended_strategy>\n**Recommendation:** [Match / Differentiate / Leapfrog / Skip]\n\n**Specific Approach:**  \n[Detailed description of what to build and how]\n\n**Rationale:**  \n[Why this approach is strategically right]\n\n**Success Criteria:**  \n[How we'll know this was the right decision]\n\n**Timeline:**  \n[When to execute]\n\n**Resources Required:**  \n[Team, time, budget]\n</recommended_strategy>\n\n<implementation_guidance>\n**If Match:**\n- Core capabilities to replicate: [List]  \n- Where we can simplify: [Opportunities]  \n- Where we must differentiate UX: [To fit our product]  \n\n**If Differentiate:**\n- Key differences: [What's different]  \n- User communication: [How to explain our approach]  \n- Risk mitigation: [How to validate innovation]  \n\n**If Leapfrog:**\n- Technical requirements: [What's needed]  \n- User research: [Validation needed]  \n- Phasing: [How to de-risk]  \n\n**If Skip:**\n- Alternative solution: [What we do instead]  \n- Communication strategy: [How to position absence]  \n- Monitoring: [What signals would change this decision]\n</implementation_guidance>\n\n<ongoing_monitoring>\n[What to track to validate the decision:  \n- Competitive intelligence: [Watch for X]  \n- User feedback: [Listen for Y]  \n- Market trends: [Monitor Z]  \n- Performance metrics: [Track A, B, C]]\n</ongoing_monitoring>\n</competitive_strategy_analysis>\n\nFAILURE\n- Any required section/tag in `FORMAT` is missing, malformed, or materially incomplete.\n- `Classification` is missing or not one of the allowed categories.\n- Recommendation is missing or not aligned with prior analysis/evidence.\n- User and market implications are omitted or disconnected from the recommended strategy.\n- Implementation guidance does not map to the selected recommendation path.\n- Monitoring signals/metrics are missing or non-actionable.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Product Strategy/Disruptive strategy generation from what-if questions.md",
      "title": "Disruptive strategy generation from what-if questions",
      "category": "Product Strategy",
      "tags": [
        "strategy",
        "counter-positioning",
        "brainstorming",
        "disruption",
        "competitive-analysis"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{COMPANY_OR_PRODUCT}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Disruptive strategy generation from what-if questions.\nSuccess metric:\n- Produces a grounded analysis of the incumbent and a diverse set of counter-positioning \"what if\" questions.\n- Generates 20–30 specific, actionable questions across multiple disruption dimensions.\n- Keeps outputs tied to the company's business model and customer assumptions.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{COMPANY_OR_PRODUCT}}`; if critical details are missing, state assumptions explicitly.\n- Start with a brief, grounded analysis of how the incumbent makes money, core product elements, and strategic posture.\n- Generate 20–30 \"what if\" questions that are specific and actionable.\n- Ensure diversity across at least these dimensions:\n  - technology,\n  - business model,\n  - customer experience,\n  - market expansion,\n  - sustainability,\n  - regulatory changes.\n- Questions must challenge core assumptions and suggest plausible counter-positioning angles.\n\nFORMAT\nReturn exactly this structure:\n\n<reasoning>\n[Analysis of the company/product and what makes it successful]\n</reasoning>\n\n<what_if_questions>\n1. [Your first \"what if\" question]\n2. [Your second \"what if\" question]\n...\n[Continue until you have 20–30 questions]\n</what_if_questions>\n\nFAILURE\n- Any required section/tag in `FORMAT` is missing, malformed, or incomplete.\n- Fewer than 20 or more than 30 questions are provided.\n- Questions are generic, repetitive, or not tied to the company/product context.\n- Diversity across the required dimensions is missing.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Product Strategy/Framework application to product challenges from user input.md",
      "title": "Framework application to product challenges from user input",
      "category": "Product Strategy",
      "tags": [
        "product-strategy",
        "frameworks",
        "decision-making",
        "coaching"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{FRAMEWORK}}\n- {{USER_INPUT}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Framework application to product challenges from user input.\nSuccess metric:\n- Asks targeted questions when key context is missing.\n- Applies the provided framework precisely to the user’s situation.\n- Produces actionable advice and a clear recommendation when sufficient context exists.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{FRAMEWORK}}` and `{{USER_INPUT}}`; if key context is missing, ask targeted questions first.\n- Do not summarize the framework back to the user.\n- When asking for more information, use `<question>` tags only.\n- When providing guidance, use `<advice>` tags only.\n- When providing a final recommendation, use `<recommendation>` tags only.\n- Keep advice specific and grounded in the user’s context; avoid generic PM guidance.\n\nFORMAT\nReturn exactly this structure:\n\n<question>\n[Targeted questions needed to apply the framework]\n</question>\n\n<advice>\n[Framework-applied guidance once sufficient context exists]\n</advice>\n\n<recommendation>\n[Final recommendation when enough context exists]\n</recommendation>\n\nFAILURE\n- Required tags are missing or malformed.\n- Output includes framework summary instead of application.\n- Advice is generic or not tied to the user input.\n- Recommendation is provided without sufficient context.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Product Strategy/Future product opportunities from market inflection points.md",
      "title": "Future product opportunities from market inflection points",
      "category": "Product Strategy",
      "tags": [
        "strategy",
        "foresight",
        "market-analysis",
        "product-discovery",
        "trends",
        "product-vision",
        "product-strategy"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{CURRENT_YEAR}}\n- {{RESEARCH_TIMEFRAME}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Future product opportunities from market inflection points.\nSuccess metric:\n- Identifies concrete regulatory, technological, and belief inflection points within the stated timeframe.\n- Connects converging trends to 3–5 plausible future opportunities.\n- Provides actionable challenges and timelines for each opportunity.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{CURRENT_YEAR}}` and `{{RESEARCH_TIMEFRAME}}`; if context is missing, state assumptions explicitly.\n- List 3–5 items per inflection category (regulatory, technological, belief).\n- Provide 3–5 converging trend sets that explicitly combine at least two categories.\n- Provide 3–5 future opportunities with concept, enabling trends, challenges, and timeline.\n- Keep opportunities plausible within the specified research timeframe.\n\nFORMAT\nReturn exactly this structure:\n\n<analysis>\n1. Inflection Points:\n   a. Regulatory:\n      - [List 3–5 significant regulatory changes]\n   b. Technological:\n      - [List 3–5 important technological advancements]\n   c. Belief:\n      - [List 3–5 notable shifts in societal attitudes or behaviors]\n\n2. Converging Trends:\n   - [Describe 3–5 sets of converging trends, explaining how they intersect]\n\n3. Future Opportunities:\n   [For each opportunity (aim for 3–5), include:]\n   a. Concept: [Brief description]\n   b. Enabling Trends: [List the key inflection points or converging trends]\n   c. Challenges: [Potential barriers or difficulties]\n   d. Timeline: [Estimated timeframe for realization]\n\n4. Conclusion:\n   [Summarize the most promising areas for innovation based on your analysis]\n</analysis>\n\nFAILURE\n- Any required section/tag in `FORMAT` is missing, malformed, or incomplete.\n- Any inflection category has fewer than 3 or more than 5 items.\n- Converging trends do not combine multiple categories.\n- Opportunities are missing required fields or outside the specified timeframe.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Product Strategy/Growth project generation with Pioneer-Migrator-Settler framework.md",
      "title": "Growth project generation with Pioneer-Migrator-Settler framework",
      "category": "Product Strategy",
      "tags": [
        "strategy",
        "growth",
        "blue-ocean",
        "innovation",
        "portfolio"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{COMPANY}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Growth project generation with Pioneer-Migrator-Settler framework.\nSuccess metric:\n- Produces 12 distinct growth projects categorized into Pioneer/Migrator/Settler.\n- Ensures balanced portfolio logic and a brief plan to drive growth.\n- Keeps ideas concrete, differentiated, and aligned to the company context.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{COMPANY}}`; if details are missing, state assumptions explicitly.\n- Generate exactly 12 distinct growth projects:\n  - 3 creative,\n  - 3 weird,\n  - 3 compelling,\n  - 3 novel and unexpected.\n- Each idea must be tagged as one of: Pioneer, Migrator, Settler.\n- Keep ideas concrete and specific to the company’s context.\n- Provide a brief analysis of portfolio balance and strategic impact.\n- Provide a short growth plan for how to build new market space and profitable growth.\n\nFORMAT\nReturn exactly this structure:\n\n<growth_projects>\n<creative_ideas>\n1. [Idea 1] - [Category]\n2. [Idea 2] - [Category]\n3. [Idea 3] - [Category]\n</creative_ideas>\n\n<weird_ideas>\n1. [Idea 1] - [Category]\n2. [Idea 2] - [Category]\n3. [Idea 3] - [Category]\n</weird_ideas>\n\n<compelling_ideas>\n1. [Idea 1] - [Category]\n2. [Idea 2] - [Category]\n3. [Idea 3] - [Category]\n</compelling_ideas>\n\n<novel_ideas>\n1. [Idea 1] - [Category]\n2. [Idea 2] - [Category]\n3. [Idea 3] - [Category]\n</novel_ideas>\n</growth_projects>\n\n<analysis>\n[Brief analysis of mix and impact, with portfolio balance insights]\n</analysis>\n\n<growth_plan>\n[Brief plan for creating new market space and profitable growth]\n</growth_plan>\n\nFAILURE\n- Any required section/tag in `FORMAT` is missing, malformed, or incomplete.\n- Fewer or more than 12 ideas are provided.\n- Any idea is missing a Pioneer/Migrator/Settler category.\n- Ideas are generic or not grounded in the company context.\n- Analysis or growth plan is missing or superficial.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Product Strategy/Growth strategy synthesis from user inputs.md",
      "title": "Growth strategy synthesis from user inputs",
      "category": "Product Strategy",
      "tags": [
        "growth",
        "strategy",
        "experimentation",
        "metrics",
        "distribution"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{USER_INPUTS}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Growth strategy synthesis from user inputs.\nSuccess metric:\n- Produces a complete growth strategy across model, constraints, horizon, method, principle, and catalyst.\n- Grounds all recommendations in the provided user inputs.\n- Outputs actionable, testable recommendations and a concise summary.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{USER_INPUTS}}`; if critical data is missing, state assumptions explicitly.\n- Address each required section: model, constraint, horizon, method, principle, catalyst, summary.\n- Keep recommendations actionable and testable; avoid generic advice.\n- If quantitative data is present, reference it; if not, use qualitative reasoning and label assumptions.\n\nFORMAT\nReturn exactly this structure:\n\n<growth_strategy>\n<growth_model>\n[Provide a detailed description of the growth model]\n</growth_model>\n\n<growth_constraint>\n[Identify and explain the main growth constraints]\n</growth_constraint>\n\n<growth_horizon>\n[Analyze the growth horizon and potential limitations]\n</growth_horizon>\n\n<growth_method>\n[Propose specific methods to address constraints and extend the growth horizon]\n</growth_method>\n\n<growth_principle>\n[Develop a guiding principle for aligning the organization]\n</growth_principle>\n\n<growth_catalyst>\n[Identify and explain any growth catalysts]\n</growth_catalyst>\n\n<summary>\n[Provide a brief summary of the overall growth strategy]\n</summary>\n</growth_strategy>\n\nFAILURE\n- Any required section/tag in `FORMAT` is missing, malformed, or incomplete.\n- Recommendations are not tied to the provided inputs.\n- Growth method lacks actionable steps.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Product Strategy/Industry trend strategy.md",
      "title": "Industry trend strategy",
      "category": "Product Strategy",
      "tags": [
        "strategy",
        "competitive-analysis",
        "positioning",
        "decision-making"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{INDUSTRY}}\n- {{TREND}}\n- {{COMPANY}}\n- {{GOAL}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Industry trend strategy.\nSuccess metric:\n- Produces a grounded industry + trend analysis tied to company strengths and goal.\n- Proposes at least three distinct strategies with actionable steps.\n- Summarizes how strategies leverage strengths to achieve the goal.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{INDUSTRY}}`, `{{TREND}}`, `{{COMPANY}}`, and `{{GOAL}}`; if critical data is missing, state assumptions explicitly.\n- Provide a concise industry + trend analysis and a focused company strengths assessment.\n- Propose at least 3 distinct strategies aligned to strengths and goal.\n- Each strategy must include name, description, alignment, contribution to goal, challenges, and action steps.\n- Keep recommendations specific and actionable, not generic.\n\nFORMAT\nReturn exactly this structure:\n\n<analysis>\n[Industry + trend analysis and company strength assessment]\n</analysis>\n\n<strategies>\n1. [Strategy name]\n   - Description: [What it is]\n   - Alignment: [Company strengths leveraged]\n   - Contribution to goal: [How it advances the goal]\n   - Challenges: [Risks/obstacles]\n   - Action steps: [Concrete steps]\n2. [Strategy name]\n   - Description: ...\n   - Alignment: ...\n   - Contribution to goal: ...\n   - Challenges: ...\n   - Action steps: ...\n3. [Strategy name]\n   - Description: ...\n   - Alignment: ...\n   - Contribution to goal: ...\n   - Challenges: ...\n   - Action steps: ...\n[Optional additional strategies]\n</strategies>\n\n<conclusion>\n[Summary emphasizing how strategies leverage strengths to capitalize on the trend and achieve the goal]\n</conclusion>\n\nFAILURE\n- Any required section/tag in `FORMAT` is missing, malformed, or incomplete.\n- Fewer than 3 strategies are provided.\n- Strategies lack alignment to company strengths or contribution to goal.\n- Action steps are missing or not actionable.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Product Strategy/Limit-based product strategy from problem to execution plan.md",
      "title": "Limit-based product strategy from problem to execution plan",
      "category": "Product Strategy",
      "tags": [
        "product-strategy",
        "roadmapping",
        "long-term-thinking",
        "structured-thinking"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{PROBLEM_STATEMENT}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Limit-based product strategy from problem to execution plan.\nSuccess metric:\n- Applies the full Limit-Based Product Thinking framework end-to-end.\n- Produces concrete milestones, levers, assumptions, and a phased execution plan.\n- Keeps outputs grounded in the provided problem statement.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{PROBLEM_STATEMENT}}`; if critical details are missing, state assumptions explicitly.\n- Follow all 7 framework steps in order.\n- Provide quantified convergence milestones at 10%, 25%, 50%, 75%, 90% with dates or triggers.\n- Identify levers to accelerate convergence and explicitly name the top 1–2 highest impact moves.\n- List critical assumptions with validation methods.\n- Provide a 3-phase plan (Foundation, Acceleration, Optimization) with timelines and resource guidance.\n\nFORMAT\nReturn exactly this structure:\n\n<limit_based_analysis>\n1. Growth Variable: [Your identified variable]\n\n2. Limit State Description:\n   [Your vivid description of the fully mature state]\n\n3. Core Properties of the Limit:\n   [List of key features and interactions]\n\n4. Convergence Estimate:\n   [Growth curve and milestones]\n\n5. Acceleration Strategies:\n   [Prioritized list of levers to steepen the curve]\n\n6. Critical Assumptions:\n   [List of assumptions with validation methods]\n\n7. Product Vision and Execution:\n   Vision Statement: [One-sentence summary]  \n   Roadmap: [Major milestones and timelines]  \n   3-Phase Plan: [Brief outline of each phase]  \n   Resource Allocation: [Key recommendations]\n\n</limit_based_analysis>\n\nFAILURE\n- Any required section/tag in `FORMAT` is missing, malformed, or incomplete.\n- Convergence milestones are missing required percentages or triggers/dates.\n- Acceleration strategies lack prioritized top 1–2 levers.\n- Assumptions lack validation methods.\n- 3-phase plan is missing or not sequenced.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Product Strategy/Low-Frequency-to-Power-User Transition Strategy.md",
      "title": "Low-Frequency-to-Power-User Transition Strategy",
      "category": "Product Strategy",
      "tags": [
        "product-strategy",
        "engagement",
        "activation",
        "retention"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{PRODUCT_DESCRIPTION}}\n- {{CURRENT_USE_CASE}}\n- {{TARGET_USE_CASE}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Low-Frequency-to-Power-User Transition Strategy.\nSuccess metric:\n- Produces a concrete transition plan from low-frequency to high-frequency usage.\n- Aligns strategy to current and target use cases with explicit behavioral gaps.\n- Includes metrics, timeline, and rollout/education plans grounded in the inputs.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{PRODUCT_DESCRIPTION}}`, `{{CURRENT_USE_CASE}}`, and `{{TARGET_USE_CASE}}`; if information is missing, state assumptions explicitly.\n- Identify the behavioral gap between current and target usage.\n- Provide step-by-step transition plan, education/onboarding, and communication strategy.\n- Include rollout plan, key metrics, and timeline for measurement.\n- Keep recommendations specific and grounded in the provided context.\n\nFORMAT\nReturn exactly this structure:\n\n<transition_strategy>\n1. Current Use Case Analysis:\n   [Provide a brief analysis of the current low-frequency use case]\n\n2. Target Use Case Analysis:\n   [Provide a brief analysis of the target high-frequency use case]\n\n3. User Behavior and Needs:\n   [Summarize key insights about user behavior and needs]\n\n4. Transition Strategy:\n   a. Feature Introduction Plan:\n      [Outline the step-by-step plan for introducing new features]\n   b. User Education and Onboarding:\n      [Describe the approach for educating users about the new use case]\n   c. Communication Strategy:\n      [Outline the key messages and channels for communicating the benefits]\n   d. Gradual Rollout Plan:\n      [Describe the approach for gradually introducing new functionality]\n\n5. Implementation and Measurement:\n   a. Key Metrics:\n      [List the primary metrics to track for measuring success]\n   b. Timeline:\n      [Provide a high-level timeline for implementation and evaluation]\n   c. Feedback and Iteration:\n      [Describe the plan for collecting user feedback and making improvements]\n\n6. Potential Challenges and Mitigation Strategies:\n   [Identify potential obstacles and propose solutions]\n\n7. Conclusion:\n   [Summarize the key points of the transition strategy and its potential impact]\n</transition_strategy>\n\nFAILURE\n- Any required section/tag in `FORMAT` is missing, malformed, or incomplete.\n- Behavioral gap or barriers are not explicitly identified.\n- Metrics or timeline are missing.\n- Strategies are generic or not tied to the given use cases.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Product Strategy/Market opportunities from Jobs-to-be-Done market canvas.md",
      "title": "Market opportunities from Jobs-to-be-Done market canvas",
      "category": "Product Strategy",
      "tags": [
        "jobs-to-be-done",
        "market-definition",
        "customer-insight",
        "product-strategy"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{PRODUCT_OR_SERVICE}}\n- {{USER_INPUT}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Market opportunities from Jobs-to-be-Done market canvas.\nSuccess metric:\n- Guides the user through all 8 JTBD canvas steps with clear prompts.\n- Keeps responses tied to provided `{{USER_INPUT}}` and the product context.\n- Ends with a concise summary prompt that reflects the completed canvas.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{PRODUCT_OR_SERVICE}}` and `{{USER_INPUT}}`; if context is missing, state assumptions explicitly.\n- Ask for user input at each of the 8 JTBD canvas steps.\n- Provide a brief explanation before each step’s prompt.\n- Require the user to answer within the specified `<stepN>` tags.\n- End by requesting a `<summary>` that synthesizes the full canvas.\n- Remind the user to use `{{USER_INPUT}}` when answering.\n\nFORMAT\nReturn exactly this structure:\n\n<step1>\n[Prompt + explanation for Traditional Market Definition]\n</step1>\n\n<step2>\n[Prompt + explanation for Job Executor Determination]\n</step2>\n\n<step3>\n[Prompt + explanation for Abstracted Job Executor]\n</step3>\n\n<step4>\n[Prompt + explanation for Job Executor Documentation]\n</step4>\n\n<step5>\n[Prompt + explanation for Product Function Analysis]\n</step5>\n\n<step6>\n[Prompt + explanation for Complementary Product Analysis]\n</step6>\n\n<step7>\n[Prompt + explanation for Job Statement Abstraction]\n</step7>\n\n<step8>\n[Prompt + explanation for Final Job Documentation]\n</step8>\n\n<summary>\n[Prompt asking the user to summarize the completed canvas]\n</summary>\n\nFAILURE\n- Any required step tag in `FORMAT` is missing, malformed, or incomplete.\n- Prompts do not request user responses within the correct `<stepN>` tags.\n- User is not reminded to use `{{USER_INPUT}}` for responses.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Product Strategy/Market requirements from strategic market inputs.md",
      "title": "Market requirements from strategic market inputs",
      "category": "Product Strategy",
      "tags": [
        "product-management",
        "market-research",
        "strategy",
        "MRD"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{MARKET_INDUSTRY}}\n- {{PROBLEM_UNMET_NEED}}\n- {{TARGET_USER_BUYER}}\n- {{CURRENT_ALTERNATIVES}}\n- {{COMPANY_ROLE_VISION_ADVANTAGE}}\n- {{EXTERNAL_FACTORS}}\n- {{OUTPUT_REQUEST}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Market requirements from strategic market inputs.\nSuccess metric:\n- Gathers required MRD inputs via a structured question flow.\n- Produces decision-ready MRD sections only after the user confirms “Ready to draft.”\n- Keeps analysis concise, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs; ask one question at a time until the user says **“Ready to draft.”**\n- Do not draft any MRD section before the user explicitly says **“Ready to draft.”**\n- After the user selects the output (A–D), produce that section only and pause for feedback.\n- Use links for citations; state assumptions explicitly.\n- No emojis. No JSON output.\n\nFORMAT\nReturn exactly this structure:\n\n<kickoff>\nLet’s co-create a Market Requirements Document. I’ll ask a few questions to gather context and then generate a draft. First up: What market or industry are you exploring?\n</kickoff>\n\n<question>\n[Your single next question based on the most recent answer]\n</question>\n\n[When user says “Ready to draft,” respond with exactly one of the requested MRD sections using the MRD Output Format headings.]\n\nFAILURE\n- Output drafts MRD sections before user says “Ready to draft.”\n- More than one question is asked at a time.\n- Output does not follow the selected section from A–D.\n- Missing citations/assumptions where needed.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Product Strategy/NETMBA competitor analysis.md",
      "title": "NETMBA competitor analysis",
      "category": "Product Strategy",
      "tags": [
        "strategy",
        "competition",
        "porter",
        "competitor-analysis"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{OUR_COMPANY_BUSINESS_UNIT}}\n- {{FOCAL_COMPETITORS}}\n- {{GEOGRAPHY_SEGMENT}}\n- {{TIME_HORIZON}}\n- {{PROVIDED_DATA_AND_CONSTRAINTS}}\n- {{DESIRED_DEPTH}}  # Brief | Standard | Deep\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: NETMBA competitor analysis.\nSuccess metric:\n- Produces a rigorous competitor analysis using Objectives, Current Strategy, Assumptions, and Capabilities.\n- Converts analysis into ranked likely moves and actionable counter-moves.\n- Keeps key claims auditable with explicit source tags and confidence levels.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs; if key fields are missing, state assumptions explicitly.\n- Use Porter/NETMBA competitor model components explicitly:\n  - Objectives, Current Strategy, Assumptions, Capabilities.\n- Separate facts from inferences; mark inferred claims with `(Inference)` and source tags `[S#]` when indirectly supported.\n- Quantify where possible; use ranges if exact values are unavailable.\n- Add confidence level (`High/Med/Low`) with one-line justification in major sections.\n- Keep all key claims auditable via `Evidence Pack` source tags.\n- Use exact section headers from `FORMAT`; do not add extra sections.\n- Depth handling:\n  - `Brief`: cap around 600 words total.\n  - `Standard`: normal detail.\n  - `Deep`: expanded sub-bullets and richer tables.\n- Include required tables:\n  - Capabilities Heatmap,\n  - Likely Moves Matrix,\n  - Counter-Moves Plan.\n\nFORMAT\nReturn exactly this structure:\n\n1. Executive Snapshot (<=120 words)\n\n2. Objectives (Future Goals)\n\n3. Current Strategy\n\n4. Assumptions\n\n5. Capabilities (Resources & Weaknesses)\n\nCapabilities Heatmap\n| Capability | Rating (High/Medium/Low) | Evidence/Notes |\n| --- | --- | --- |\n| R&D |  |  |\n| Cost position |  |  |\n| Brand |  |  |\n| Data assets |  |  |\n| Channel strength |  |  |\n| Supply chain |  |  |\n| Regulatory savvy |  |  |\n| Hiring velocity |  |  |\n\n6. Likely Moves & Response Profile\n\nLikely Moves Matrix\n| Move | Likelihood (1-5) | Impact (1-5) | Earliest timing | Leading indicators |\n| --- | --- | --- | --- | --- |\n|  |  |  |  |  |\n\n7. Implications for Us\n\nCounter-Moves Plan\n| Our move | Objective | Dependency | Owner | T-minus signals |\n| --- | --- | --- | --- | --- |\n|  |  |  |  |  |\n\n8. Evidence Pack\n- [S1] [Source title] ([Date])\n- [S2] [Source title] ([Date])\n\n9. Unknowns & Validation Plan\n\n10. Appendix\n- KPI table: [price levels, feature parity, share estimates, CAC/LTV clues if available]\n- Timeline of notable moves (last 12-24 months)\n\nFAILURE\n- Any required section header/table from `FORMAT` is missing, malformed, or materially incomplete.\n- One or more core model components (Objectives/Current Strategy/Assumptions/Capabilities) lacks concrete, testable claims.\n- Likely moves are not logically connected to the four core model components.\n- Key claims lack `[S#]` references to `Evidence Pack`.\n- Confidence levels are missing in major sections.\n- `DESIRED_DEPTH=Brief` output is materially overlong.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Product Strategy/Now-Next-Later vision roadmap from interview synthesis.md",
      "title": "Now-Next-Later vision / roadmap from interview synthesis",
      "category": "Product Strategy",
      "tags": [
        "interviews",
        "research-synthesis",
        "product-strategy",
        "roadmapping",
        "vision"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{TRANSCRIPT}}\n- Optional: {{CONTEXT}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Now-Next-Later vision / roadmap from interview synthesis.\nSuccess metric:\n- Produces a Now/Next/Later roadmap grounded in transcript evidence.\n- Distinguishes needs, symptoms, solutions, and underlying drivers with citations.\n- Limits items to what is supported by the transcript.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{TRANSCRIPT}}` (and optional `{{CONTEXT}}`); if evidence is missing, do not infer.\n- Output exactly three sections: **Now**, **Next**, **Later**.\n- Each section contains 2–4 items (or fewer if evidence is insufficient).\n- Each item must include: Need, Symptom, Proposed solution (if mentioned), Underlying driver, Evidence (quote/paraphrase).\n- Use direct quotes <= 20 words or precise paraphrases with speaker/timestamp if available.\n- If a need spans horizons, place it where it becomes critical and note cross-horizon relevance.\n\nFORMAT\nReturn exactly this structure:\n\n**Now**\n1. Need: [What]\n   - Symptom: [Signal]\n   - Proposed solution: [How, if mentioned]\n   - Underlying driver: [Why]\n   - Evidence: \"[Quote <=20 words]\" (Speaker, timestamp) or [Paraphrase + attribution]\n[2–4 items or fewer if evidence is insufficient]\n\n**Next**\n1. Need: [What]\n   - Symptom: [Signal]\n   - Proposed solution: [How, if mentioned]\n   - Underlying driver: [Why]\n   - Evidence: \"[Quote <=20 words]\" (Speaker, timestamp) or [Paraphrase + attribution]\n[2–4 items or fewer if evidence is insufficient]\n\n**Later**\n1. Need: [What]\n   - Symptom: [Signal]\n   - Proposed solution: [How, if mentioned]\n   - Underlying driver: [Why]\n   - Evidence: \"[Quote <=20 words]\" (Speaker, timestamp) or [Paraphrase + attribution]\n[2–4 items or fewer if evidence is insufficient]\n\nFAILURE\n- Any required section in `FORMAT` is missing or malformed.\n- Items are missing required fields (Need, Symptom, Proposed solution, Underlying driver, Evidence).\n- Evidence is missing or exceeds the 20-word quote limit.\n- Items are inferred without transcript evidence."
    },
    {
      "path": "Prompts/Product Strategy/OKR planning from vision statements.md",
      "title": "OKR planning from vision statements",
      "category": "Product Strategy",
      "tags": [
        "okrs",
        "strategy",
        "goal-setting",
        "product-management",
        "execution",
        "prioritization"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{VISION_STATEMENT}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: OKR planning from vision statements.\nSuccess metric:\n- Converts the vision into 3–5 key areas with quarterly objectives and measurable key results.\n- Ensures key results are quantitative and tied to product milestones.\n- Includes a clear explanation of alignment back to the vision.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{VISION_STATEMENT}}`; if context is missing, state assumptions explicitly.\n- Create 3–5 key areas; each has 1–2 objectives.\n- Each objective must have 2–4 quantitative key results tied to product milestones.\n- Keep OKRs specific to the vision and industry; avoid generic templates.\n- Include an explanation mapping each key area to the vision.\n\nFORMAT\nReturn exactly this structure:\n\n<okrs>\nKey Area 1:\nObjective 1:\n- Key Result 1\n- Key Result 2\n- Key Result 3\n\nKey Area 2:\nObjective 1:\n- Key Result 1\n- Key Result 2\n- Key Result 3\n\nObjective 2:\n- Key Result 1\n- Key Result 2\n- Key Result 3\n\n(Continue for all key areas, objectives, and key results)\n</okrs>\n\n<explanation>\n[Explain how each key area and its OKRs map back to the vision statement]\n</explanation>\n\nFAILURE\n- `<okrs>` or `<explanation>` is missing, malformed, or incomplete.\n- Fewer than 3 or more than 5 key areas are provided.\n- Objectives or key results are missing or not within required counts.\n- Key results are not quantitative or not tied to product milestones.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Product Strategy/Positioning statements from competitive analysis and value proposition.md",
      "title": "Positioning statements from competitive analysis and value proposition",
      "category": "Product Strategy",
      "tags": [
        "marketing",
        "positioning",
        "messaging",
        "competitive-analysis",
        "copywriting"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{TARGET_CUSTOMER}}\n- {{UNMET_NEEDS}}\n- {{PRODUCT_NAME}}\n- {{PRODUCT_CATEGORY}}\n- {{BENEFITS}}\n- {{COMPETITIVE_LANDSCAPE}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Positioning statements from competitive analysis and value proposition.\nSuccess metric:\n- Produces a canonical positioning statement plus two variants with clear differentiation.\n- Uses outcomes over features, avoids buzzwords, and stays within length limits.\n- Includes evidence hook and footnote for assumptions/prioritization when needed.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only the provided inputs; if any are missing or vague, infer minimally and wrap inferred text in [brackets].\n- Output must be a single Markdown code block and nothing else.\n- Include exactly one canonical statement and two variants (Executive-readout, Sales enablement).\n- Enforce length limits: canonical <= 60 words; variants <= 35 words each.\n- Avoid hype/buzzwords (for example: revolutionary, cutting-edge).\n- Include an evidence hook in Differentiation without fabricating data.\n- If multiple segments/competitors are provided, choose one and note in a footnote.\n\nFORMAT\nReturn exactly this structure:\n\n```markdown\n## Positioning Statement\n\n**For** [TARGET_CUSTOMER]  \n**who** [UNMET_NEEDS in one tight clause],  \n**[PRODUCT NAME]** **is a** [PRODUCT_CATEGORY]  \n**that** [BENEFITS as results the user achieves].\n\n### Differentiation\n**Unlike** [PRIMARY COMPETITOR / STATUS QUO], **[PRODUCT NAME]** **delivers** [outcome-focused differentiation + proof hook].\n\n---\n\n## Executive-Readout Variant\nFor [TARGET_CUSTOMER], **[PRODUCT NAME]** is a [PRODUCT_CATEGORY] that [top outcome]. Unlike [competitor/status quo], it [sharp differentiator].\n\n## Sales Enablement Variant\nWhen [TARGET_CUSTOMER] struggles with [UNMET_NEEDS], **[PRODUCT NAME]** helps them [BENEFITS]. Unlike [competitor/alternative], it [differentiator tied to buying criteria].\n\n[Optional Footnote: one sentence noting assumptions or prioritization choices]\n```\n\nFAILURE\n- Output is not a single Markdown code block.\n- Canonical or variant statements exceed length limits.\n- Differentiation lacks an evidence hook.\n- Missing or incorrect sections/labels from the required format.\n- Footnote is missing when assumptions or prioritization are made.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Product Strategy/Product strategy review from draft documents.md",
      "title": "\"Product strategy review from draft documents\"",
      "category": "\"Product Strategy\"",
      "tags": [
        "product-management",
        "strategy",
        "stakeholder-management",
        "communication"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{DRAFT_DOCUMENT}}\n- {{CONTEXT}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: \"Product strategy review from draft documents\".\nSuccess metric:\n- Produces a high-signal review of strengths, gaps, and review risks in the draft.\n- Provides concrete copy/structure improvements that can be directly used in the draft.\n- Surfaces the top 3 discussion points likely to drive executive review decisions.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{DRAFT_DOCUMENT}}` and `{{CONTEXT}}`; if data is missing, state assumptions explicitly.\n- Analyze strengths and gaps against:\n  - punchline clarity,\n  - front-loading of controversial elements,\n  - memorable insight/stat,\n  - customer pain articulation,\n  - solution-to-pain alignment,\n  - assumptions/trade-offs,\n  - executive question readiness.\n- In `<analysis>`, use a numbered list; each item is 2-3 sentences, with the first short sentence in bold.\n- In `<improvements>`, provide up to 10 concrete copy/structure edits in the same style as the draft.\n- Do not fabricate data or claims; explicitly call out missing data when needed.\n- Output only the required tags and nothing outside them.\n\nFORMAT\nReturn exactly this structure:\n\n<analysis>\n[Numbered list of strengths and gaps; first short sentence bold in each item]\n</analysis>\n\n<improvements>\n[Numbered list (up to 10) of specific copy and structure improvements]\n</improvements>\n\n<discussion_points>\n[Your list of top 3 discussion points]\n</discussion_points>\n\nFAILURE\n- Any required section/tag in `FORMAT` is missing, malformed, or incomplete.\n- `<analysis>` items do not follow the required format (numbered, 2-3 sentences, bold first short sentence).\n- `<improvements>` has more than 10 items or lacks concrete rewrites.\n- `discussion_points` does not contain exactly 3 points.\n- Output includes fabricated data not present in inputs.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Product Strategy/Research into durable competitive moats.md",
      "title": "Research into durable competitive moats",
      "category": "Product Strategy",
      "tags": [
        "moats",
        "product-strategy",
        "competitive-advantage",
        "research-synthesis"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{APP_CONTEXT}}\n- {{RESEARCH_BUNDLE}}\n- Optional: {{K_STRATEGIES}}  # default 10\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Research into durable competitive moats.\nSuccess metric:\n- Produces research-grounded moat insights and converts them into implementation-ready strategies.\n- Delivers a diversified moat portfolio with explicit probabilities, defensibility, and kill criteria.\n- Keeps recommendations constrained by feasibility, compounding potential, and non-copyability.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{APP_CONTEXT}}` and `{{RESEARCH_BUNDLE}}`; if critical info is missing, add explicit assumptions in a top-level `assumptions` array.\n- Extract 8-15 research-backed insights; each insight must include:\n  - `id` (e.g., `I1`),\n  - `insight` (one sentence),\n  - `evidence` (quote/paraphrase + source cue),\n  - `implication` (competitive implication).\n- Generate `k` moat strategies (`k={{K_STRATEGIES}}` if provided; otherwise 10).\n- Allowed `moat_type` values:\n  - `data moat`, `network effects`, `switching costs`, `distribution moat`, `brand`, `scale economies`, `ecosystem/platform`, `regulatory/permissions`, `IP/know-how`, `community`.\n- Each strategy must include:\n  - `title`,\n  - `moat_type`,\n  - `contrarian` (boolean),\n  - `mechanism`,\n  - `research_link` (insight IDs),\n  - `implementation_plan` (`now_30d`, `next_90d`, `next_12m`, each 3-6 steps),\n  - `prerequisites`,\n  - `metrics` (3-6 leading indicators with targets),\n  - `risks_and_mitigations` (3-6),\n  - `time_to_moat` (`<3 months`, `3-6 months`, `6-12 months`, `12-24 months`, `24+ months`),\n  - `estimated_cost` (`low`, `medium`, `high`),\n  - `defensibility_score` (1-10) and `defensibility_justification`,\n  - `probability` (decimal 0.0-1.0).\n- Diversity constraints:\n  - every strategy probability `< 0.15`,\n  - at least 3 strategies with probability `< 0.07`,\n  - no `moat_type` used more than twice,\n  - at least 2 strategies with `contrarian=true`.\n- Portfolio section must include:\n  - `recommended_portfolio` (exactly 3 strategies with rationale),\n  - `kill_criteria` (2-3 falsifiable stop criteria per recommended strategy),\n  - `sequencing` (month-by-month plan for 6 months with dependencies).\n- Output must be valid JSON only, concise and implementation-ready.\n\nFORMAT\nReturn exactly this structure:\n\n{\n  \"assumptions\": [\"[Only if needed]\"],\n  \"insights\": [\n    {\n      \"id\": \"I1\",\n      \"insight\": \"\",\n      \"evidence\": \"\",\n      \"implication\": \"\"\n    }\n  ],\n  \"moat_strategies\": [\n    {\n      \"title\": \"\",\n      \"moat_type\": \"\",\n      \"contrarian\": false,\n      \"mechanism\": \"\",\n      \"research_link\": [\"I1\"],\n      \"implementation_plan\": {\n        \"now_30d\": [\"\", \"\", \"\"],\n        \"next_90d\": [\"\", \"\", \"\"],\n        \"next_12m\": [\"\", \"\", \"\"]\n      },\n      \"prerequisites\": [\"\"],\n      \"metrics\": [\n        {\n          \"name\": \"\",\n          \"target\": \"\"\n        }\n      ],\n      \"risks_and_mitigations\": [\n        {\n          \"risk\": \"\",\n          \"mitigation\": \"\"\n        }\n      ],\n      \"time_to_moat\": \"\",\n      \"estimated_cost\": \"\",\n      \"defensibility_score\": 1,\n      \"defensibility_justification\": \"\",\n      \"probability\": 0.01\n    }\n  ],\n  \"recommended_portfolio\": [\n    {\n      \"strategy_title\": \"\",\n      \"rationale\": \"\"\n    }\n  ],\n  \"kill_criteria\": [\n    {\n      \"strategy_title\": \"\",\n      \"criteria\": [\"\", \"\"]\n    }\n  ],\n  \"sequencing\": [\n    {\n      \"month\": \"M1\",\n      \"focus\": \"\",\n      \"dependencies\": [\"\"]\n    }\n  ]\n}\n\nFAILURE\n- Output is not valid JSON.\n- Required top-level keys are missing or malformed.\n- Insight count is outside 8-15.\n- Strategy count does not equal `k` (default 10).\n- Any strategy misses required fields or contains invalid enum values.\n- Distribution constraints are violated (probability caps, low-probability count, moat-type repetition, contrarian minimum).\n- `recommended_portfolio` does not contain exactly 3 strategies.\n- Kill criteria are not falsifiable or have fewer than 2 criteria per recommended strategy.\n- Sequencing is not month-by-month for 6 months.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Product Strategy/Strategic crux diagnosis and strategy design.md",
      "title": "Strategic crux diagnosis and strategy design",
      "category": "Product Strategy",
      "tags": [
        "strategy",
        "decision-making",
        "prioritization",
        "product",
        "leadership"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{CONTEXT_SCOPE}}\n- {{CURRENT_STATE}}\n- {{DESIRED_FUTURE}}\n- {{TIME_HORIZON}}\n- {{CUSTOMERS_JTBD}}\n- {{UVP_TODAY}}\n- {{COMPETITIVE_LANDSCAPE}}\n- {{KEY_CONSTRAINTS}}\n- {{ASSETS_STRENGTHS}}\n- {{RISKS_NON_NEGOTIABLES}}\n- {{USER_INSIGHTS}}\n- {{UNIT_ECONOMICS}}\n- {{STAKEHOLDERS_DECISION_RIGHTS}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Strategic crux diagnosis and strategy design.\nSuccess metric:\n- Identifies the strategic crux with evidence-backed rationale.\n- Proposes a leveraged strategy with explicit trade-offs and testable milestones.\n- Provides a concrete execution plan with experiments, metrics, and risks.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs; if critical items are missing, ask up to 6 concise clarification questions first.\n- Separate facts, assumptions, and inferences; label disconfirming evidence and uncertainties.\n- Identify the crux and choose a leveraged strategy with explicit trade-offs.\n- Provide options table, chosen strategy, 12–18 week moves, experiments, metrics, risks, and resources.\n- If constraints make the goal infeasible, propose renegotiations with quantified trade-offs.\n\nFORMAT\nReturn exactly this structure:\n\n1) Executive Summary (<=200 words)\n\n2) Strategic Narrative\n\n3) Evidence Pack\n\n4) Crux Definition\n\n5) Options & Trade-offs\n| Option | Core Bet | Expected Impact (with math) | Cost (money/teams) | Time-to-First-Signal | Risks | Reversibility | Why It Might Fail |\n\n6) Chosen Strategy (Leverage Thesis)\n\n7) Strategic Moves (12–18 weeks)\n| Move | Owner | Start | End | Dependencies | Weekly Leading Indicator | Target | Risk & Mitigation |\n\n8) Experiments to Prove/Disprove\n\n9) Metrics & Monitoring\n\n10) Risks, Preconditions, and Constraint Renegotiations\n\n11) Resource Plan\n\n12) Decision Log & Next Checkpoint\n\nAppendices (tables)\n1. Assumptions -> Tests Map: | Assumption | Test/Experiment | When | Owner | Decision Rule |\n2. Roadmap (Quarter): | Week | Move | Deliverable | Confidence |\n3. Stakeholder Map: | Stakeholder | Interest/Influence | What They Need to See |\n\nFAILURE\n- Any required section/table in `FORMAT` is missing, malformed, or incomplete.\n- Crux is not explicitly defined or not tied to evidence.\n- Options table is missing or lacks required columns.\n- Moves lack owners, timeline, or leading indicators.\n- Experiments lack hypothesis/metrics or stop/scale rules.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Product Strategy/Strategic moves from SWOT pairings.md",
      "title": "Strategic moves from SWOT pairings",
      "category": "Product Strategy",
      "tags": [
        "strategy",
        "swot",
        "decision-making",
        "structured-thinking"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{SWOT_CONTEXT}}\n- {{SWOT_STRENGTHS}}\n- {{SWOT_WEAKNESSES}}\n- {{SWOT_OPPORTUNITIES}}\n- {{SWOT_THREATS}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Strategic moves from SWOT pairings.\nSuccess metric:\n- Produces strategic move patterns for all 6 SWOT pairings.\n- Includes a combination matrix and 3–7 unifying strategic themes.\n- Keeps patterns general (not hyper-specific tactics) unless explicitly requested.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided SWOT inputs; if context is missing, ask a short set of clarification questions first.\n- Generate patterns for all 6 SWOT pairings.\n- Provide 5–10 patterns per pairing, each with an optional trigger and a risk/assumption note.\n- Include a combination matrix and 3–7 strategic themes.\n- Keep output general unless the user explicitly requests company-specific tactics.\n\nFORMAT\nReturn exactly this structure:\n\n<clarifying_questions>\n[If needed: ask up to 6 concise questions to obtain missing context and SWOT lists]\n</clarifying_questions>\n\n<swot_pairings>\n<so_growth_leverage>\n1. [Pattern] - Trigger: [If/then] - Risk/Assumption: [Note]\n...\n</so_growth_leverage>\n\n<st_defensive_advantage>\n1. [Pattern] - Trigger: [If/then] - Risk/Assumption: [Note]\n...\n</st_defensive_advantage>\n\n<wo_capability_building>\n1. [Pattern] - Trigger: [If/then] - Risk/Assumption: [Note]\n...\n</wo_capability_building>\n\n<wt_protective_actions>\n1. [Pattern] - Trigger: [If/then] - Risk/Assumption: [Note]\n...\n</wt_protective_actions>\n\n<sw_focus_tradeoffs>\n1. [Pattern] - Trigger: [If/then] - Risk/Assumption: [Note]\n...\n</sw_focus_tradeoffs>\n\n<ot_market_shaping>\n1. [Pattern] - Trigger: [If/then] - Risk/Assumption: [Note]\n...\n</ot_market_shaping>\n</swot_pairings>\n\n<combination_matrix>\n[Lightweight matching rules across SWOT items]\n</combination_matrix>\n\n<strategic_themes>\n1. [Theme]\n2. [Theme]\n3. [Theme]\n[Up to 7 themes]\n</strategic_themes>\n\nFAILURE\n- Any required section/tag in `FORMAT` is missing, malformed, or incomplete.\n- Any SWOT pairing has fewer than 5 or more than 10 patterns.\n- Combination matrix or strategic themes are missing.\n- Patterns are overly tactic-specific without request.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Product Strategy/Strategy Kernel extraction from context.md",
      "title": "Strategy Kernel extraction from context",
      "category": "Product Strategy",
      "tags": [
        "strategy",
        "product-management",
        "diagnosis",
        "context"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{PRODUCT_MANAGER_INPUT}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Strategy Kernel extraction from context.\nSuccess metric:\n- Extracts explicit, implied, and missing strategic context with clear gaps and next steps.\n- Flags risks/anti-patterns and prioritizes follow-up questions.\n- Produces a structured assessment aligned to the Strategy Kernel Canvas sections.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{PRODUCT_MANAGER_INPUT}}`; if key context is missing, state assumptions explicitly.\n- Extract explicit, implied, and missing information across History, Diagnosis, and Guiding Policy.\n- Flag anti-patterns when supported by the input.\n- Provide 3–5 prioritized clarification questions if critical gaps remain.\n- Keep output structured and decision-ready; no fluff.\n\nFORMAT\nReturn exactly this structure:\n\ncontext_assessment:\n  completeness_score: [0-100]\n  confidence_level: [high/medium/low]\n\n  explicit_information:\n    - [Clearly stated items]\n\n  implied_information:\n    - [Reasonable inferences]\n\n  critical_gaps:\n    - gap: [description]\n      why_critical: [explanation]\n      how_to_obtain: [suggested action]\n\n  red_flags:\n    - [Potential derailers]\n\n  recommended_focus_areas:\n    - [Where to focus effort]\n\n  stakeholder_map:\n    - name/role: [name or role]\n      influence: [high/medium/low]\n      alignment: [aligned/neutral/opposed/unknown]\n\n  next_steps:\n    immediate:\n      - [Next 24 hours]\n    week_one:\n      - [First week actions]\n\nclarifying_questions:\n  - \"[CRITICAL] [Question] - Why this matters: [explanation]\"\n  - \"[IMPORTANT] [Question] - Why this matters: [explanation]\"\n  - \"[USEFUL] [Question] - Why this matters: [explanation]\"\n\nFAILURE\n- Output is missing `context_assessment` or `clarifying_questions`.\n- Completeness score or confidence level is missing.\n- Critical gaps are missing when evidence is insufficient.\n- Clarifying questions are not prioritized or fewer than 3 when needed.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Product Strategy/Strategy-to-execution bridge for UX decisions.md",
      "title": "\"Strategy-to-execution bridge for UX decisions\"",
      "category": "\"Product Strategy\"",
      "tags": [
        "ux",
        "product-strategy",
        "execution",
        "roadmapping"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{VISION_STRATEGY}}\n- {{CURRENT_QUARTER_OBJECTIVES}}\n- {{DESIGN_TEAM_CAPACITY}}\n- {{EXISTING_DESIGN_SYSTEM}}\n- {{TECHNICAL_CONSTRAINTS}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: \"Strategy-to-execution bridge for UX decisions\".\nSuccess metric:\n- Translates vision and objectives into concrete UX principles, patterns, and execution plans.\n- Produces a quarter-by-quarter roadmap with dependencies, risks, and success criteria.\n- Provides decision frameworks that connect daily design choices to strategy.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs; if information is missing, state assumptions explicitly.\n- Extract 3–5 strategic themes and map them to UX goals, patterns, and decision principles.\n- Build a quarterly execution plan with dependencies, success criteria, and capacity fit.\n- Identify gaps, blockers, and research needs that prevent execution.\n- Provide a multi-phase roadmap, validation plan, and feedback loops.\n\nFORMAT\nReturn exactly this structure:\n\n<strategy_to_execution_bridge>\n<vision_analysis>\n## Strategic Themes\n\n[List 3–5 core strategic themes extracted from vision, with brief explanation of each]\n\n**Theme 1: [Name]**\n- Description: [What this theme means strategically]\n- UX implications: [How this affects user experience]\n- Key phrases from vision: \"[Quote relevant language]\"\n\n**Theme 2: [Name]**\n[Same structure]\n\n## User Experience Goals\n\n[Specific UX outcomes mentioned or strongly implied by vision]\n\n1. **[Goal name]:** [Description and rationale]\n   - Success looks like: [Observable outcome]\n   - Measurement: [How to track progress]\n\n2. **[Goal name]:** [Description]  \n   [Continue for each goal]\n\n## Market Positioning\n\n**Target positioning:** [Premium/accessible, technical/intuitive, comprehensive/focused, etc.]  \n**Competitive differentiation:** [How vision positions against competitors]  \n**Customer segment priority:** [Which personas or segments are prioritized]  \n**Brand personality:** [Tone, voice, aesthetic implied]\n\n## Vision Gaps and Ambiguities\n\n[Areas where vision is too vague for execution]\n\n- **Ambiguity:** \"[Vague term or conflicting signal]\"\n  - **Why this matters:** [Impact on design decisions]\n  - **Question to resolve:** [Specific question stakeholders must answer]\n  - **Temporary assumption:** [What to assume if answer isn't available]\n\n[Continue for each ambiguity]\n\n</vision_analysis>\n\n<ux_translation>\n## Design Principles\n\n[4–6 principles that operationalize the vision – avoid generic platitudes]\n\n**Principle 1: [Specific, actionable principle]**\n- **What it means:** [Operational definition]\n- **How to apply:** [Decision heuristic or guideline]\n- **Example:** [Concrete example of principle in action]\n- **Anti-pattern:** [What to avoid that violates this principle]\n\n**Principle 2: [Name]**  \n[Same structure]\n\n## Required UX Patterns\n\n[Specific interaction patterns needed to realize strategic themes]\n\n**Strategic Theme:** [Theme name]\n\n**Required Patterns:**\n1. **[Pattern name]** – [Brief description]\n   - Use cases: [Where this pattern appears]\n   - Component needs: [Design system elements required]\n   - Examples: [Reference products or specific instances]\n\n2. **[Pattern name]** – [Description]  \n   [Continue]\n\n[Repeat for each strategic theme]\n\n## Information Architecture Implications\n\n[How vision affects IA and content structure]\n\n**Navigation strategy:** [Top-level navigation approach implied by vision – task-based, feature-based, role-based, etc.]  \n**Content hierarchy:** [What information is primary vs. secondary]  \n**Discoverability approach:** [How users find features – guided onboarding, search-first, exploration, etc.]  \n**Conceptual model:** [How vision wants users to think about the product]\n\n**IA changes needed:**\n- [Specific IA shifts required to align with vision]\n- [Continue]\n\n## Visual and Interaction Design Direction\n\n**Aesthetic:** [Visual style implied – minimal, expressive, data-dense, spacious, etc.]  \n**Interaction patterns:** [Gestural, form-based, conversational, drag-and-drop, etc.]  \n**Motion and animation:** [Role of animation – functional only, delightful, prominent, minimal]  \n**Density and spacing:** [Information density – compact, generous, adaptive]  \n**Color strategy:** [Use of color – vibrant, muted, semantic only, brand-forward]\n\n## Component and Pattern Inventory\n\n[Comprehensive list of design system components needed for vision]\n\n**Existing components sufficient for vision:**\n- [Component name] – [How it supports vision]\n- [Continue]\n\n**Existing components needing enhancement:**\n- [Component name] – [What enhancement is needed and why]\n- [Continue]\n\n**New components required:**\n- [Component name] – [Purpose and rationale]\n  - Priority: [Critical / High / Medium / Low]\n  - Dependencies: [What must exist first]\n  - Effort estimate: [Design days / complexity]\n- [Continue]\n\n</ux_translation>\n\n<quarterly_execution_plan>\n## Q1 Scope: Actionable This Quarter\n\n[Vision elements that can be designed and delivered this quarter]\n\n### Initiative 1: [Name]\n\n**Strategic theme:** [Which theme this advances]  \n**Design deliverables:**\n- [Specific deliverable] – [Completion date]\n- [Continue]\n\n**Design effort:** [X days research, Y days design, Z iteration cycles]  \n**Dependencies:**\n- Design: [Dependencies within design team]\n- Research: [User research needs]\n- Engineering: [Technical dependencies]\n- Product: [Product decisions needed]\n- External: [Third-party or other team dependencies]\n\n**Success criteria:**\n- Design quality: [Standards to meet]\n- User outcomes: [Behavioral or satisfaction metrics]\n- Business metrics: [Adoption, conversion, revenue, etc.]\n- Learning goals: [Assumptions validated or de-risked]\n\n**Risks and mitigations:**\n- **Risk:** [Potential issue]\n  - **Likelihood:** [High/Medium/Low]\n  - **Impact:** [High/Medium/Low]\n  - **Mitigation:** [How to reduce risk]\n\n[Continue for each Q1 initiative]\n\n## Foundational Work Required\n\n[Prerequisite work needed before vision elements can be executed]\n\n### Foundation 1: [Name]\n\n**What it enables:** [Which vision elements depend on this]  \n**Why it's foundational:** [Explanation of dependency]  \n**Deliverables:**\n- [Specific output]\n- [Continue]\n\n**Timeline:** [When this must be complete and why]  \n**Effort:** [Resource estimate]\n\n[Continue for each foundational item]\n\n## Deferred to Q2+\n\n[Vision elements not actionable this quarter]\n\n### Deferred Initiative: [Name]\n\n**Strategic theme:** [Which theme this advances]  \n**Why deferred:** [Blocker – capacity, dependencies, uncertainty, etc.]  \n**What's needed to activate:**\n- [Prerequisite] – [Who/what/when]\n- [Continue]\n\n**Tentative timeline:** [When this could begin]\n\n[Continue for each deferred item]\n\n## Capacity Analysis\n\n**Total design capacity:** [X designer-days available this quarter]  \n**Allocated capacity:**\n- Q1 initiatives: [Y designer-days] ([Z]% of capacity)\n- Foundational work: [Y designer-days] ([Z]%)\n- Maintenance and support: [Y designer-days] ([Z]%)\n- Buffer for unknowns: [Y designer-days] ([Z]%)\n\n**Capacity status:** [Over-committed / Fully allocated / Under-utilized]\n\n**Recommendations:**\n- [If over-committed: what to descope or defer]\n- [If under-utilized: what to pull forward or invest in]\n- [Prioritization rationale]\n\n</quarterly_execution_plan>\n\n<decision_frameworks>\n## Daily Design Decision Criteria\n\n[Questions to ask when making design choices to ensure vision alignment]\n\n### When Choosing Between Design Alternatives\n\n1. **Vision alignment check:** Which option better advances strategic themes [list themes]?\n   - Option A: [How it aligns or conflicts]\n   - Option B: [How it aligns or conflicts]\n   - Winner: [Which to choose and why]\n\n2. **Scalability evaluation:** Which option extends to future use cases implied by vision?\n   - Consider: [Upcoming features or use cases]\n   - Test: [Can this pattern handle those scenarios?]\n\n3. **Consistency assessment:** Which option reinforces established patterns vs. introducing divergence?\n   - If new pattern is needed: [Justify with strategic rationale]\n   - If consistency conflicts with vision: [Escalate or document tradeoff]\n\n4. **User value prioritization:** Which option prioritizes user needs over internal convenience?\n   - Red flag: [Designs optimized for engineering simplicity or business politics over UX]\n\n5. **Technical feasibility reality check:** Is this implementable within constraints?\n   - If not: [Adjust design or advocate for constraint removal]\n   - If workaround needed: [Ensure workaround doesn't degrade UX]\n\n### When Vision and Immediate Needs Conflict\n\n**Favor vision if:**\n- Immediate need is temporary or can be solved another way\n- Vision direction is high-confidence and well-validated\n- Technical debt from immediate solution is significant\n\n**Favor immediate need if:**\n- Blocker for users or business (not just internal inconvenience)\n- Vision direction is uncertain or likely to change\n- Can be implemented without major technical debt\n\n**Seek creative middle ground:**\n- Phased rollout (simple now, vision-aligned later)\n- Feature flags (ship both, test and learn)\n- Modular design (immediate solution doesn't preclude vision path)\n\n**Escalate when:**\n- Tradeoff has significant strategic implications\n- Decision affects multiple teams or long-term architecture\n- Stakeholder alignment is needed\n\n### Pattern Establishment vs. Deferral\n\n**Standardize now if:**\n- Pattern will be used in 3+ places imminently\n- Consistency is critical for usability (e.g., error handling, form validation)\n- Foundation for other patterns (e.g., base components)\n\n**Defer standardization if:**\n- Single-use or rare use case\n- Vision direction unclear and pattern may change\n- Pattern is experimental and needs validation first\n\n**Create flexible pattern if:**\n- Vision direction uncertain but action needed now\n- Multiple future variations likely\n- Learning required before locking in specific implementation\n\n### Scope Management\n\n**When new requests arise outside quarterly plan:**\n\n1. **Does this directly advance a Q1 vision element?**\n   - Yes → Evaluate against current priorities\n   - No → Default to defer unless exception criteria met\n\n2. **Exception criteria:**\n   - Critical user blocker (cannot accomplish core tasks)\n   - Regulatory or legal requirement\n   - Foundational for Q2+ work (pull forward)\n   - Opportunistic (very low effort, high strategic value)\n\n3. **If considering inclusion, ask: What would we deprioritize?**\n   - Evaluate tradeoff explicitly\n   - Ensure swapped item is truly lower priority\n   - Get stakeholder alignment on change\n\n4. **Can this be achieved with existing patterns?**\n   - Yes → Lower cost, more likely to include\n   - No → Higher bar for inclusion\n\n</decision_frameworks>\n\n<gaps_and_dependencies>\n## Strategic Gaps Requiring Clarification\n\n[Where strategy needs more definition before design can proceed confidently]\n\n**Gap 1: [Topic]**\n- **Ambiguity:** [What's unclear]\n- **Design impact:** [Why this blocks or confuses design work]\n- **Question for stakeholders:** [Specific question]\n- **Decision owner:** [Who should answer]\n- **Urgency:** [When answer is needed – this week, this month, this quarter]\n- **Temporary path forward:** [What to assume if answer delayed]\n\n[Continue for each strategic gap]\n\n## Technical Dependencies and Blockers\n\n[Required technical capabilities that don't exist yet]\n\n**Dependency 1: [Capability name]**\n- **What it enables:** [Design work or vision elements blocked without this]\n- **Current status:** [Not started / In progress / Blocked]\n- **Owner:** [Team or person responsible]\n- **Timeline:** [When this will be available]\n- **Design impact if delayed:** [Consequences for design roadmap]\n- **Workaround if unavailable:** [Alternative approach or descoped experience]\n\n[Continue for each technical dependency]\n\n## Research Needs and Unknowns\n\n[Questions that must be answered through user research]\n\n**Research Need 1: [Topic]**\n- **Question:** [Specific research question]\n- **Why this matters:** [Design decisions that depend on answer]\n- **Hypotheses:** [Current assumptions to validate or invalidate]\n- **Research method:** [Interviews, usability testing, survey, analytics analysis, etc.]\n- **Participants:** [Who to include – personas, segments, sample size]\n- **Timeline:** [When research must complete to inform design]\n- **Owner:** [Researcher or designer responsible]\n- **Design path if answer is X:** [Decision tree based on findings]\n- **Design path if answer is Y:** [Alternative direction]\n\n[Continue for each research need]\n\n## Design System Gaps\n\n[Missing design system components or patterns needed for vision]\n\n**Gap 1: [Component or pattern name]**\n- **Vision element requiring this:** [Strategic theme or initiative this supports]\n- **Why existing components insufficient:** [What's missing or inadequate]\n- **Scope of new component:**\n  - States: [Default, hover, focus, disabled, error, loading, etc.]\n  - Variants: [Size, style, or functional variations needed]\n  - Responsive behavior: [Mobile, tablet, desktop considerations]\n  - Accessibility requirements: [Keyboard nav, screen reader, WCAG compliance]\n- **Effort estimate:** [Design days, complexity level]\n- **Dependencies:** [Other components or patterns this builds on]\n- **Priority:** [Critical / High / Medium / Low]\n- **Timeline need:** [When this must be ready]\n\n[Continue for each design system gap]\n\n## Cross-Functional Dependencies\n\n[What other teams must deliver for design to proceed or ship]\n\n**Dependency on [Team Name]:**\n- **What's needed:** [Specific deliverable or decision]\n- **Why design needs this:** [Blocker explanation]\n- **Owner:** [Name or role]\n- **Requested by:** [Date]\n- **Committed date:** [When they'll deliver, if known]\n- **Status:** [On track / At risk / Blocked / Unknown]\n- **Design contingency:** [What design does if this is delayed]\n\n[Continue for each cross-functional dependency]\n\n</gaps_and_dependencies>\n\n<implementation_roadmap>\n## Phase 1: Current Quarter (Q1) – Foundation and Momentum\n\n**Timeline:** [Dates]  \n**Goal:** [High-level objective for this phase]\n\n### Foundational Work\n[Work that enables future phases – design system, research, core patterns]\n\n**Foundation:** [Name]\n- **Deliverables:** [Specific outputs]\n- **Effort:** [Resource estimate]\n- **Completion:** [Target date]\n- **Unlocks:** [What becomes possible after this]\n\n[Continue for each foundation]\n\n### Quick Wins\n[High-impact, low-effort improvements demonstrating vision progress]\n\n**Quick Win:** [Name]\n- **Impact:** [User or business value]\n- **Effort:** [Low effort explanation]\n- **Delivery:** [Target date]\n- **Strategic signal:** [Which vision theme this demonstrates]\n\n[Continue for each quick win]\n\n### Critical Path Items\n[Blockers for Q2+ work that must complete this quarter]\n\n**Critical Item:** [Name]\n- **Why critical:** [Explanation of dependency]\n- **Risk if delayed:** [Downstream impact]\n- **Deliverables:** [Specific outputs]\n- **Date:** [Must complete by]\n\n[Continue for each critical item]\n\n### Learning Experiments\n[Small tests to validate assumptions before major investment]\n\n**Experiment:** [Name]\n- **Hypothesis:** [What we're testing]\n- **Method:** [How we'll test – prototype, survey, A/B test, etc.]\n- **Success criteria:** [What results validate hypothesis]\n- **Failure criteria:** [What results invalidate hypothesis]\n- **Decision:** [What we'll do based on results]\n- **Timeline:** [Duration of experiment]\n\n[Continue for each experiment]\n\n### Q1 Success Criteria\n\n**Design outputs:**\n- [ ] [Specific deliverable or milestone]\n- [ ] [Continue]\n\n**User outcomes:**\n- [ ] [Metric or qualitative signal]\n- [ ] [Continue]\n\n**Business results:**\n- [ ] [KPI or goal]\n- [ ] [Continue]\n\n**Strategic progress:**\n- [ ] [Vision element advanced or de-risked]\n- [ ] [Continue]\n\n## Phase 2: Next Two Quarters (Q2–Q3) – Building Toward Vision\n\n**Timeline:** [Dates]  \n**Goal:** [High-level objective for this phase]\n\n### Major Initiatives\n[Large design efforts advancing core strategic themes]\n\n**Initiative:** [Name]\n- **Strategic theme:** [Which theme this advances]\n- **Scope:** [High-level description]\n- **Dependencies:** [What from Phase 1 must be complete]\n- **Milestones:**\n  - [Milestone 1] – [Date]\n  - [Milestone 2] – [Date]\n- **Success criteria:** [How to measure success]\n\n[Continue for each major initiative]\n\n### Integration and Coherence Work\n[Connecting Phase 1 foundations into cohesive experiences]\n\n**Integration Work:** [Name]\n- **What's being integrated:** [Components, patterns, or features]\n- **Why integration matters:** [User benefit or strategic value]\n- **Timeline:** [When this happens]\n\n[Continue for each integration]\n\n### Iteration and Refinement\n[Improving based on Phase 1 learnings]\n\n**Area for refinement:** [Name]\n- **Phase 1 learning:** [What we learned]\n- **Refinement needed:** [How to improve]\n- **Timeline:** [When this happens]\n\n[Continue for each refinement area]\n\n### Decision Checkpoints\n[Points where direction may adjust based on data]\n\n**Checkpoint:** [When – e.g., \"End of Q2\"]\n- **Decision:** [What will be decided]\n- **Data inputs:** [Metrics, research, or signals informing decision]\n- **Options:** [Possible directions based on data]\n- **Decision owner:** [Who decides]\n\n[Continue for each checkpoint]\n\n## Phase 3: Future Quarters (Q4+) – Vision Realization\n\n**Timeline:** [Dates or \"Q4 and beyond\"]  \n**Goal:** [High-level objective for this phase]\n\n### Vision Completion\n[Fully realized strategic themes]\n\n**Strategic Theme:** [Name]\n- **Vision state:** [Description of fully realized theme]\n- **What's needed to complete:**\n  - [Work item]\n  - [Continue]\n- **Success criteria:** [How to know theme is fully realized]\n\n[Continue for each strategic theme]\n\n### Polish and Elevation\n[Raising experience quality to match vision]\n\n**Polish area:** [Name]\n- **Current state:** [Where quality falls short]\n- **Vision state:** [Target quality level]\n- **Work required:** [What it takes to close gap]\n\n[Continue for each polish area]\n\n### Scale and Robustness\n[Handling edge cases, localization, advanced use cases]\n\n**Scaling dimension:** [Name – e.g., \"Localization,\" \"Edge case handling\"]\n- **Scope:** [What must scale]\n- **Complexity:** [Challenges involved]\n- **Timeline:** [When this is addressed]\n\n[Continue for each scaling dimension]\n\n### Measurement and Validation\n[Confirming strategic goals achieved]\n\n**Strategic goal:** [Goal from vision]\n- **Measurement approach:** [How to validate achievement]\n- **Target metric:** [Specific number or threshold]\n- **Review cadence:** [When to check progress]\n\n[Continue for each strategic goal]\n\n## Ongoing Across All Phases\n\n### Maintenance and Debt Reduction\n**Allocation:** [% of capacity per quarter]  \n**Focus areas:**\n- [Area needing maintenance – e.g., \"accessibility improvements,\" \"mobile optimization\"]\n- [Continue]\n\n### Flexibility Buffer\n**Allocation:** [% of capacity held for emerging priorities]  \n**Use for:** [Unplanned work, urgent requests, pivots]\n\n### Research and Discovery\n**Allocation:** [% of capacity for ongoing learning]  \n**Focus:** [Continuous research to inform future phases]\n\n## Roadmap Visualization\n\n[If helpful, provide a timeline visual or table showing initiatives across phases]\n\n**Q1:** [List key initiatives]  \n**Q2:** [List key initiatives]  \n**Q3:** [List key initiatives]  \n**Q4+:** [List key initiatives]\n\n</implementation_roadmap>\n\n<assumptions_and_validation>\n## Vision Assumptions to Validate\n\n[Beliefs embedded in strategy that should be tested]\n\n**Assumption 1: [Statement]**\n- **Type:** [Market / User behavior / Competitive / Business model]\n- **Source:** [Where this assumption comes from in vision]\n- **Confidence level:** [High / Medium / Low]\n- **Validation method:** [How to test this]\n- **Timeline:** [When to validate]\n- **Impact if wrong:** [Consequence of false assumption]\n- **Pivot options:** [Alternative directions if invalidated]\n\n[Continue for each assumption]\n\n## Design Hypotheses\n\n[Testable beliefs about UX approaches]\n\n**Hypothesis 1: [Statement]**\n- **Rationale:** [Why we believe this]\n- **Test method:** [How to validate – prototype testing, A/B test, analytics, etc.]\n- **Success criteria:** [Evidence that confirms hypothesis]\n- **Failure criteria:** [Evidence that refutes hypothesis]\n- **Timeline:** [When to test]\n- **Decision tree:**\n  - If validated: [Design direction to pursue]\n  - If invalidated: [Alternative approach]\n  - If inconclusive: [Further research or conservative path]\n\n[Continue for each hypothesis]\n\n## Success Indicators and Monitoring\n\n### Leading Indicators\n[Early signals that validate or invalidate direction]\n\n**Indicator:** [Metric or signal]\n- **What it measures:** [What this tells us]\n- **Target:** [Threshold or trend]\n- **Measurement method:** [How to track]\n- **Frequency:** [How often to check]\n- **Green flag:** [Signal we're on track]\n- **Yellow flag:** [Signal to investigate]\n- **Red flag:** [Signal to pivot]\n\n[Continue for each indicator]\n\n### Lagging Indicators\n[Longer-term outcomes confirming strategic success]\n\n**Indicator:** [Metric or signal]\n- **What it measures:** [What this tells us]\n- **Target:** [Threshold or goal]\n- **Timeline:** [When to expect result]\n- **Measurement method:** [How to track]\n\n[Continue for each indicator]\n\n## Review Cadence and Feedback Loops\n\n### Weekly Design Reviews\n**Attendees:** [Roles]  \n**Agenda:**\n- Work in progress review\n- **Strategy alignment check:** [Quick assessment of whether work advances vision]\n- Blockers and dependencies\n- Upcoming decisions\n\n### Mid-Quarter Checkpoint\n**Timing:** [Week 6 of 13-week quarter]  \n**Purpose:** Assess if on track to hit Q1 success criteria  \n**Review:**\n- Progress vs. plan\n- Capacity actuals vs. estimates\n- Dependency status\n- Emerging risks\n- Adjustment needs\n\n### End-of-Quarter Retrospective\n**Timing:** [Final week of quarter]  \n**Purpose:** Learn and inform next quarter planning  \n**Review:**\n- Q1 success criteria achievement\n- Assumption validation results\n- What worked well / What didn't\n- Roadmap adjustments needed\n- Phase 2 planning input\n\n### Strategy Review with Leadership\n**Cadence:** [Quarterly or semi-annually]  \n**Purpose:** Ensure design work aligns with evolving business strategy  \n**Topics:**\n- Vision progress report\n- Key learnings and pivots\n- Roadmap alignment with business priorities\n- Resource needs for upcoming phases\n\n## Escalation Triggers\n\n[When to pause and reconsider direction]\n\n**Trigger 1: User research contradicts core assumptions**\n- **Action:** [Immediate review of affected design work, stakeholder alignment meeting]\n- **Decision owner:** [Role]\n- **Timeline:** [How quickly to respond]\n\n**Trigger 2: Technical feasibility proves impossible or dramatically more expensive**\n- **Action:** [Evaluate alternative approaches, possibly descope or rearchitect]\n- **Decision owner:** [Role]\n- **Timeline:** [How quickly to respond]\n\n**Trigger 3: Business priorities shift**\n- **Action:** [Reassess roadmap, reprioritize quarterly plan]\n- **Decision owner:** [Role]\n- **Timeline:** [How quickly to respond]\n\n**Trigger 4: Competitive landscape changes significantly**\n- **Action:** [Competitive analysis update, strategy review meeting]\n- **Decision owner:** [Role]\n- **Timeline:** [How quickly to respond]\n\n**Trigger 5: Success metrics trending negatively**\n- **Action:** [Root cause analysis, corrective action plan]\n- **Decision owner:** [Role]\n- **Timeline:** [How quickly to respond]\n\n</assumptions_and_validation>\n</strategy_to_execution_bridge>\n\nFAILURE\n- Any required section/tag in `FORMAT` is missing, malformed, or incomplete.\n- Strategic themes or UX goals are missing or not tied to the vision.\n- Execution plan lacks dependencies, success criteria, or capacity analysis.\n- Validation and feedback loops are missing or superficial.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Product Strategy/Structured product strategy from product context.md",
      "title": "Structured product strategy from product context",
      "category": "Product Strategy",
      "tags": [
        "product-strategy",
        "roadmapping",
        "product-management",
        "structured-thinking",
        "product-vision"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{PRODUCT_CONTEXT}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Structured product strategy from product context.\nSuccess metric:\n- Produces a complete strategy across objective, users, superpowers, vision, pillars, impact, and roadmap.\n- Keeps each section grounded in the provided product context.\n- Provides concrete, coherent outputs that build on each other.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{PRODUCT_CONTEXT}}`; if context is missing, state assumptions explicitly.\n- Provide all 7 sections in the required format.\n- Objective: 1–2 sentences, ambitious but achievable.\n- Users: 1–2 groups; each with 3–4 needs.\n- Superpowers: 3–4 unique advantages.\n- Vision: 2–3 paragraphs.\n- Pillars: 2–4 themes with brief descriptions.\n- Impact: causal mechanism or back-of-envelope logic.\n- Roadmap: 3–10 items per pillar (no prioritization).\n\nFORMAT\nReturn exactly this structure:\n\n<product_strategy>\n\n<objective>\n\n[Your objective here]\n\n</objective>\n\n<users>\n\n[User group descriptions and bullet points here]\n\n</users>\n\n<superpowers>\n\n[List of superpowers here]\n\n</superpowers>\n\n<vision>\n\n[Your vision paragraphs here]\n\n</vision>\n\n<pillars>\n\n[List of pillars with titles and descriptions here]\n\n</pillars>\n\n<impact>\n\n[Impact description here]\n\n</impact>\n\n<roadmap>\n\n[Roadmap items for each pillar here]\n\n</roadmap>\n\n</product_strategy>\n\nFAILURE\n- Any required section/tag in `FORMAT` is missing, malformed, or incomplete.\n- Counts are outside required ranges (users, superpowers, pillars, roadmap items).\n- Impact does not explain mechanism or is generic.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Product Strategy/Task-specific product strategy design.md",
      "title": "\"Task-specific product strategy design\"",
      "category": "\"Product Strategy\"",
      "tags": [
        "product-management",
        "strategy",
        "prd",
        "leadership",
        "execution"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{TASK_TYPE}}\n- {{PRD_CONTENT}}\n- {{PM_QUESTION}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: \"Task-specific product strategy design\".\nSuccess metric:\n- Detects the task type and produces the correct response structure.\n- Grounds outputs in provided inputs and avoids generic advice.\n- Delivers actionable, CPO-level guidance or PRD/analysis as requested.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs; if required content is missing for the chosen task type, state assumptions explicitly.\n- If `{{TASK_TYPE}}` is unknown, ask a clarifying question within `<response>`.\n- Task-specific outputs:\n  - Draft PRD: include all required PRD sections in markdown.\n  - Analyze PRD: provide structured feedback across the listed aspects.\n  - General PM Advice: provide direct, experience-based guidance tied to user input.\n- Avoid generic frameworks or platitudes.\n\nFORMAT\nReturn exactly this structure:\n\n<response>\n[Your detailed answer, following the task-specific instructions and communication style guidelines]\n</response>\n\nFAILURE\n- `<response>` wrapper is missing or malformed.\n- Response does not match the requested task type.\n- Draft PRD output omits required sections.\n- Analysis feedback omits required review aspects.\n- Advice is generic or not tied to `{{PM_QUESTION}}`.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Product Strategy/Value chain mapping from end-user needs to core value generators.md",
      "title": "Value chain mapping from end-user needs to core value generators",
      "category": "Product Strategy",
      "tags": [
        "strategy",
        "value-chain",
        "business-model",
        "structured-thinking"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{PRODUCT}}\n- {{INDUSTRY}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Value chain mapping from end-user needs to core value generators.\nSuccess metric:\n- Maps end-user needs to a full value chain and identifies core value generators.\n- Highlights vulnerabilities where the chain could be disrupted.\n- Grounds analysis in the provided product and industry context.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{PRODUCT}}` and `{{INDUSTRY}}`; if information is missing, state assumptions explicitly.\n- Map value creation from end-user needs back to foundational inputs.\n- Identify core value generators and explain why they are defensible.\n- Highlight vulnerabilities and potential disruption points.\n- Keep analysis specific to the product/industry context.\n\nFORMAT\nReturn exactly this structure:\n\n<value_chain_analysis>\n1. End-user needs:  \n   [List the primary needs the product/service fulfills]\n\n2. Value chain breakdown:  \n   [Provide a hierarchical breakdown of the value chain, from end-user needs to basic inputs]\n\n3. Core value generators:  \n   [List and explain the identified core value generators]\n\n4. Potential vulnerabilities:  \n   [Discuss any aspects of the value chain that could be vulnerable to disruption]\n</value_chain_analysis>\n\nFAILURE\n- Any required section/tag in `FORMAT` is missing, malformed, or incomplete.\n- Value chain breakdown does not reach foundational inputs.\n- Core value generators lack defensible rationale.\n- Vulnerabilities are missing or generic.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Project Management/Conversation summaries from meeting transcripts.md",
      "title": "Conversation summaries from meeting transcripts",
      "category": "Project Management",
      "tags": [
        "meetings",
        "summarization",
        "note-taking",
        "communication"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{CONVERSATION}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Conversation summaries from meeting transcripts.\nSuccess metric:\n- Produces a structured summary of major topics with correct hierarchy.\n- Extracts explicit actions with owners and ADHD-friendly step breakdowns.\n- Keeps summary faithful to the transcript without fabrication.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only `{{CONVERSATION}}`; if information is missing, state assumptions explicitly.\n- Summarize with nested bullets reflecting topic hierarchy and relationships.\n- Identify explicit actions with:\n  - `**Action:**` statement,\n  - `**Who:**` owner,\n  - concise numbered ADHD-friendly steps.\n- Keep language clear and concise; avoid invented facts or inferred decisions not in transcript.\n- Output must be inside `<summary>` tags only.\n\nFORMAT\nReturn exactly this structure:\n\n<summary>\n• Main topic 1\n  ◦ Subtopic 1.1\n    ▪ Detail 1.1.1\n    ▪ Detail 1.1.2\n  ◦ Subtopic 1.2\n    ▪ Detail 1.2.1\n      - Sub-detail 1.2.1.1\n\n• Main topic 2\n  ◦ Subtopic 2.1\n    ▪ **Action: [Description of the action]**\n    ▪ **Who: [Person responsible]**\n    ▪ Steps for ADHD individuals:\n      1. First step\n      2. Second step\n      3. Third step\n\n  ◦ Subtopic 2.2\n    ▪ Detail 2.2.1\n</summary>\n\nFAILURE\n- `<summary>` wrapper is missing, malformed, or incomplete.\n- Nested structure does not reflect major topics and supporting details.\n- Actions are missing `**Action:**`, `**Who:**`, or ADHD step breakdown.\n- Content includes fabricated points not present in transcript.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Project Management/Detailed project plans from project briefs.md",
      "title": "\"Detailed project plans from project briefs\"",
      "category": "\"Project Management\"",
      "tags": [
        "planning",
        "scheduling",
        "risk-management",
        "execution"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{PROJECT_BRIEF}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: \"Detailed project plans from project briefs\".\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Build a detailed, realistic project plan from `{{PROJECT_BRIEF}}`, including:\n- Project objectives, deliverables, constraints, and deadlines from the brief.\n- Task/subtask breakdown with duration and resource estimates.\n- Day-by-day plan, then weekly milestones, then monthly goals.\n- Critical path analysis and schedule impact of delays.\n- Risk assessment with likelihood, impact, and mitigation.\n- Ambiguity review covering: what is unclear, why it matters, and how to resolve it.\n- Final summary of timeline, milestones, critical path, and top risks.\n\nFORMAT\nReturn exactly this structure:\n\n<project_plan>\n<summary>\n[Include your project summary here]\n</summary>\n\n<daily_plan>\n[Include your day-by-day breakdown here]\n</daily_plan>\n\n<weekly_plan>\n[Include your week-by-week plan here]\n</weekly_plan>\n\n<monthly_plan>\n[Include your month-by-month plan here]\n</monthly_plan>\n\n<critical_path>\n[Include your critical path analysis here]\n</critical_path>\n\n<risk_management>\n[Include your risk assessment and mitigation strategies here]\n</risk_management>\n</project_plan>\n\n<ambiguities>\n[Include your analysis of ambiguous areas and proposed solutions here]\n</ambiguities>\n\nFAILURE\n- Any required section (`<summary>`, `<daily_plan>`, `<weekly_plan>`, `<monthly_plan>`, `<critical_path>`, `<risk_management>`, `<ambiguities>`) is missing or materially incomplete.\n- Timeline logic is inconsistent across daily/weekly/monthly levels.\n- Critical path, risks, or ambiguity handling is missing, shallow, or not actionable.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Project Management/Meeting agendas from meeting descriptions.md",
      "title": "\"Meeting agendas from meeting descriptions\"",
      "category": "\"Project Management\"",
      "tags": [
        "meetings",
        "facilitation",
        "planning",
        "productivity"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{MEETING_DESCRIPTION}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: \"Meeting agendas from meeting descriptions\".\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Build a meeting preparation output from `{{MEETING_DESCRIPTION}}` that includes:\n- A clear purpose statement for the meeting.\n- A structured agenda with allocated time per topic and key questions per topic.\n- A practical process/flow for running the meeting to achieve the stated purpose.\n- Internally reason from meeting goals, stakeholders, and constraints; return only the required final sections.\n\nFORMAT\nReturn exactly this structure:\n\n<purpose>\n[Clear and concise purpose statement]\n</purpose>\n\n<agenda>\n1. [Agenda Topic 1] - [Allocated Time]\nKey Questions:\n- [Question 1]\n- [Question 2]\n...\n2. [Agenda Topic 2] - [Allocated Time]\nKey Questions:\n- [Question 1]\n- [Question 2]\n...\n[Additional agenda topics]\n</agenda>\n\n<process>\n[Suggested process and flow for the meeting]\n</process>\n\nFAILURE\n- Any required section (`<purpose>`, `<agenda>`, `<process>`) is missing or materially incomplete.\n- Agenda items do not include both time allocation and key questions.\n- Meeting flow/process is generic and not tied to the stated purpose.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Project Management/Meeting summaries from meeting transcript (IDEAS framework).md",
      "title": "Meeting summaries from meeting transcript (IDEAS framework)",
      "category": "Communication & Influence",
      "tags": [
        "meetings",
        "summarization",
        "frameworks",
        "note-taking"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{MEETING_TRANSCRIPT}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Meeting summaries from meeting transcript (IDEAS framework).\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Follow these task requirements:\n<task_requirements>\nYou are tasked with summarizing a meeting using the IDEAS framework. This framework helps organize the key points of a meeting into five categories: Insights, Decisions, Engagements, Actions, and Summary. Here's the meeting transcript you need to analyze:\n\n<meeting_transcript>\n{{MEETING_TRANSCRIPT}}\n</meeting_transcript>\n\nPlease carefully read and analyze the meeting transcript. Then, summarize the meeting using the IDEAS framework as follows:\n\n1. Insights: Identify and list the main insights or important realizations that emerged during the meeting.\n2. Decisions: Note any decisions that were made during the meeting.\n3. Engagements: List any tasks or responsibilities that were assigned to specific individuals or teams.\n4. Actions: Highlight any immediate actions that need to be taken as a result of the meeting.\n5. Summary: Provide a brief overall summary of the meeting's impact and significance.\n\nWhen writing your summary, please be concise and focused. Aim to capture the most important points rather than trying to include every detail. Use bullet points for each category to make the summary easy to read and understand.\n\nPresent your summary using the following format, enclosed in XML tags:\n\n\n\nRemember to focus on the most significant and relevant information for each category. Your goal is to provide a clear, organized, and useful summary of the meeting using the IDEAS framework.\n</task_requirements>\n\nFORMAT\nReturn exactly this structure:\n\n<IDEAS_Summary>\n<Insights>\n• [List insights here]\n</Insights>\n\n<Decisions>\n• [List decisions here]\n</Decisions>\n\n<Engagements>\n• [List engagements here]\n</Engagements>\n\n<Actions>\n• [List actions here]\n</Actions>\n\n<Summary>\n[Write a brief overall summary here]\n</Summary>\n</IDEAS_Summary>\n\nFAILURE\n- Output misses required sections, steps, or reasoning required by `<task_requirements>`.\n- Required format/schema is missing, malformed, or incomplete.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Project Management/Product refinement session planning.md",
      "title": "Product refinement session planning",
      "category": "Project Management",
      "tags": [
        "product-management",
        "refinement",
        "meetings",
        "facilitation"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{TOPIC}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Product refinement session planning.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Use the refinement guide to plan a session for `{{TOPIC}}`.\n- Produce:\n- A timeboxed agenda aligned to the guide’s phases.\n- 3-5 guide-derived key points relevant to this topic.\n- 3-5 topic-specific discussion questions focused on problem exploration.\n- A 2-3 sentence closing statement emphasizing refinement value and next steps.\n\nFORMAT\nReturn exactly this structure:\n\n<refinement_guide>\n# Product Refinement Session Guide\n## Purpose\nA refinement session is NOT about estimating solutions, but rather:\n- Understanding problems deeply\n- Determining solution requirements\n- Building shared team understanding\n- Defining clear success criteria\n## Pre-Session Preparation\n### For Product Manager/Owner\n1. Identify key items for refinement\n   - Select items that align with current priorities\n   - Focus on problems that need immediate attention\n2. Share materials in advance\n   - Distribute selected items to team 24 hours before session\n   - Give team time to review and reflect\n   - Include any relevant context or background information\n### For Team Members\n1. Review shared materials\n2. Note initial questions and concerns\n3. Consider potential problem areas that need clarification\n## During the Session\n### 1. Context Setting (15-20 minutes)\n- PM/PO clearly articulates:\n  - Current business priorities\n  - Strategic context\n  - Why these items matter now\n  - How they align with broader goals\n### 2. Problem Space Exploration (40-45 minutes)\n- Discuss each refinement item:\n  - Define the core problem\n  - Identify affected stakeholders\n  - Map out dependencies\n  - Document constraints\n  - Clarify assumptions\n### 3. Success Criteria Definition (20-25 minutes)\n- Define clear outcomes:\n  - What does success look like?\n  - How will we measure it?\n  - What are the acceptance criteria?\n  - What are the non-negotiables?\n### 4. Discussion Management\n- Timeboxed conversations\n- Park tangential discussions\n- Document open questions\n- Capture action items\n### 5. Session Retrospective (10-15 minutes)\n- Gather feedback on:\n  - Session effectiveness\n  - Discussion quality\n  - Time management\n  - Areas for improvement\n  - What worked well\n## Post-Session Actions\n### 1. Documentation\n- Update refinement items with new insights\n- Document decisions and rationale\n- Share session notes\n### 2. Follow-up\n- Address parked items\n- Schedule any needed deep-dives\n- Assign action items\n### 3. Preparation for Next Session\n- Apply retrospective feedback\n- Begin identifying next batch of items\n- Update session format based on team input\n## Success Indicators\n- Team has clear understanding of problems\n- Success criteria are well-defined\n- Next steps are clearly documented\n- Team is aligned on priorities\n- Everyone understands their role in solution development\n## Common Pitfalls to Avoid\n- Jumping to solutions too quickly\n- Not timeboxing discussions\n- Lack of preparation\n- Missing key stakeholders\n- Focusing on estimation instead of understanding\n</refinement_guide>\n\n<agenda>\n[Timeboxed agenda aligned to the guide’s phases]\n</agenda>\n\n<key_points>\n[3-5 guide-derived points relevant to the session topic]\n</key_points>\n\n<discussion_questions>\n[3-5 topic-specific questions for problem space exploration]\n</discussion_questions>\n\n<closing_statement>\n[2-3 sentence closing statement]\n</closing_statement>\n\nFAILURE\n- Any required section (`<refinement_guide>`, `<agenda>`, `<key_points>`, `<discussion_questions>`, `<closing_statement>`) is missing or materially incomplete.\n- Agenda is not timeboxed or does not align to the guide’s phases.\n- Questions are generic or not tied to `{{TOPIC}}`.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Project Management/Reinforcing sequence from unstructured items.md",
      "title": "Reinforcing sequence from unstructured items",
      "category": "Project Management",
      "tags": [
        "systems-thinking",
        "prioritization",
        "root-cause-analysis",
        "workflows"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{ITEMS}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Reinforcing sequence from unstructured items.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Analyze `{{ITEMS}}` to build an interrelationship sequence where each step reinforces or enables the next.\n- Identify cause-effect links, dependencies, and likely root-driver items.\n- Choose a strong starting item and produce one coherent sequence (domino logic).\n- Use interrelationship-diagram thinking (drivers vs outcomes, direction of influence, dependency strength) to justify order.\n- Include concise reasoning in `<reasoning>` and final ordered list in `<best>`.\n\nFORMAT\nReturn exactly this structure:\n\n<reasoning>\n[Concise explanation of key dependencies, reinforcing relationships, starting-point choice, and ordering logic]\n</reasoning>\n\n<best>\n[Numbered list of all items from `{{ITEMS}}` in the recommended reinforcing order; one item per line]\n</best>\n\nFAILURE\n- `<reasoning>` or `<best>` is missing, malformed, or materially incomplete.\n- Final sequence does not include all input items exactly once.\n- Ordering is not justified by dependency/reinforcement logic.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Project Management/Requirements prioritization with P0-P1-P2 framework.md",
      "title": "Requirements prioritization with P0-P1-P2 framework",
      "category": "Project Management",
      "tags": [
        "prioritization",
        "product-management",
        "planning",
        "scope"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{REQUIREMENTS_LIST}}\n- {{PRODUCT_CONTEXT}}\n- {{CONSTRAINTS}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Requirements prioritization with P0-P1-P2 framework.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Prioritize `{{REQUIREMENTS_LIST}}` using the P0/P1/P2 framework in the context of `{{PRODUCT_CONTEXT}}` and `{{CONSTRAINTS}}`.\n- Apply explicit prioritization tests for each tier (P0/P1/P2) and challenge “must-have” claims.\n- Use effort vs. value to support decisions and identify descoping options if capacity is exceeded.\n- Provide rationale, evidence, and acceptance criteria for each requirement.\n- Produce a capacity analysis and a stakeholder communication plan.\n\nFORMAT\nReturn exactly this structure:\n\n<requirements_prioritization>\n<prioritization_framework>\n**P0 Definition (Launch Blocker):**\n[Your specific definition for this project:\n- Without this, users cannot [core task]\n- Without this, product fails [critical requirement]\n- Must-have criteria: [specific tests]]\n\n**P1 Definition (High Value):**\n[Your specific definition for this project:\n- Significantly improves [key experience]\n- Enables [important use case]\n- Should-have criteria: [specific tests]]\n\n**P2 Definition (Nice-to-Have):**\n[Your specific definition for this project:\n- Enhances [aspect of experience]\n- Valuable but users can accomplish goals without it\n- Nice-to-have criteria: [specific tests]]\n\n**Prioritization Principles:**\n[3-5 principles guiding decisions for this project:\n- \"Core user task enablement trumps convenience features\"\n- \"Baseline quality must be met (P0) before adding polish (P2)\"]\n</prioritization_framework>\n\n<prioritized_requirements>\n<p0_requirements>\n[For each P0 requirement:\n\n**Requirement:** [Clear description]\n\n**Why P0:**\n[Specific justification using P0 criteria]\n\n**Impact if Missing:**\n[Concrete description of what breaks without this]\n\n**User Tasks Blocked:**\n[Which core user tasks become impossible]\n\n**Evidence:**\n[Data/research supporting this priority]\n\n**Effort Estimate:**\n[Time/complexity]\n\n**Dependencies:**\n[What else must exist for this to work]\n\n**Acceptance Criteria:**\n[Minimum bar for \"done\" on this requirement]]\n</p0_requirements>\n\n<p1_requirements>\n[For each P1 requirement:\n\n**Requirement:** [Clear description]\n\n**Why P1:**\n[Specific justification using P1 criteria]\n\n**Value if Included:**\n[Concrete benefits of including this]\n\n**Impact if Missing:**\n[What degrades without this, but doesn't break]\n\n**User Tasks Affected:**\n[Which tasks become harder but still possible]\n\n**Evidence:**\n[Data/research supporting value]\n\n**Effort Estimate:**\n[Time/complexity]\n\n**Could Descope to:**\n[Simpler version that captures core value]\n\n**Acceptance Criteria:**\n[Minimum bar for \"done\"]]\n</p1_requirements>\n\n<p2_requirements>\n[For each P2 requirement:\n\n**Requirement:** [Clear description]\n\n**Why P2:**\n[Why it's nice-to-have but not critical]\n\n**Value:**\n[What it adds]\n\n**Defer Rationale:**\n[Why it's okay to wait]\n\n**Effort Estimate:**\n[Time/complexity]\n\n**Post-Launch Timeline:**\n[When to revisit]\n\n**Acceptance Criteria:**\n[If we did build it, what's the bar]]\n</p2_requirements>\n</prioritized_requirements>\n\n<challenged_priorities>\n[For items originally claimed as \"must-have\" but deprioritized:\n\n**Requirement:** [Description]\n\n**Originally Claimed As:** [P0/P1]\n\n**Actually:** [P1/P2]\n\n**Why Deprioritized:**\n[Reason it's not as critical as claimed]\n\n**Supporting Evidence:**\n[Why this priority is more accurate]\n\n**Alternative:**\n[How users can accomplish goal without this, or simpler version]]\n</challenged_priorities>\n\n<effort_value_matrix>\n[Create a 2x2 showing:\n**High Value / Low Effort (Do First):**\n- [List requirements]\n\n**High Value / High Effort (Evaluate):**\n- [List requirements]\n- [For each: Is value worth effort? Can we simplify?]\n\n**Low Value / Low Effort (Nice-to-have):**\n- [List requirements]\n- [Consider: Worth including or better to focus elsewhere?]\n\n**Low Value / High Effort (Descope):**\n- [List requirements]\n- [Rationale for cutting]]\n</effort_value_matrix>\n\n<capacity_analysis>\n**Total Requirements:**\n- P0: [count] items = [estimated effort]\n- P1: [count] items = [estimated effort]\n- P2: [count] items = [estimated effort]\n- Total: [total effort]\n\n**Available Capacity:**\n[Team capacity for this release]\n\n**Gap Analysis:**\n- P0 fit: [Yes/No - if no, how much over?]\n- P0 + P1 fit: [Yes/No - if no, which P1 to defer?]\n- P0 + P1 + P2 fit: [Almost certainly no]\n\n**Conclusion:**\n[What's realistic to complete]\n</capacity_analysis>\n\n<descoping_options>\n[If capacity is exceeded, propose descoping approaches:\n\n**Option 1: Defer All P2**\n- What's cut: [List P2 items]\n- What's preserved: [All P0/P1]\n- Impact: [Minimal - nice-to-haves wait]\n\n**Option 2: Defer Low-Effort P1 + All P2**\n- What's cut: [Specific P1 items]\n- What's preserved: [High-value P0/P1]\n- Rationale: [Why these P1 items can wait]\n- Impact: [Description]\n\n**Option 3: Simplify High-Effort P1**\n- What's simplified: [Specific items]\n- Simplified version: [Description]\n- Value preserved: [What's kept]\n- Impact: [Tradeoffs]\n\n**Recommended Approach:**\n[Which option, with rationale]]\n</descoping_options>\n\n<decision_documentation>\n**Prioritization Decision Log:**\n[Template for documenting:\n- Requirement\n- Priority assignment (P0/P1/P2)\n- Rationale\n- Decision maker\n- Date\n- Conditions that would change priority]\n</decision_documentation>\n\n<communication_plan>\n**How to Present Prioritization:**\n[Guidance for sharing with stakeholders:\n- Lead with framework and principles\n- Show evidence for priorities\n- Be explicit about tradeoffs\n- Invite challenge on specific items\n- Document decisions]\n\n**Handling \"Everything is P0\" Stakeholders:**\n[Tactics for managing pushback:\n- Apply prioritization tests consistently\n- Show capacity constraints\n- Offer descoping choices\n- Escalate if needed]\n</communication_plan>\n</requirements_prioritization>\n\nFAILURE\n- Any required section in `<requirements_prioritization>` is missing or materially incomplete.\n- Requirements lack evidence-based rationale or acceptance criteria.\n- Capacity analysis or descoping options are missing when P0+P1 exceed capacity.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Project Management/Scope defense using time-cost tradeoff analysis.md",
      "title": "Scope defense using time-cost tradeoff analysis",
      "category": "Project Management",
      "tags": [
        "scope-management",
        "prioritization",
        "product-design",
        "stakeholder-management"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{CURRENT_SCOPE}}\n- {{NEW_REQUEST}}\n- {{PROJECT_CONSTRAINTS}}\n- {{TEAM_CAPACITY}}\n- {{EXISTING_PRIORITIES}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Scope defense using time-cost tradeoff analysis.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Use `{{CURRENT_SCOPE}}`, `{{NEW_REQUEST}}`, `{{PROJECT_CONSTRAINTS}}`, `{{TEAM_CAPACITY}}`, and `{{EXISTING_PRIORITIES}}` to quantify tradeoffs.\n- Provide a full effort breakdown (design/engineering/QA/documentation) plus indirect costs.\n- Assess timeline, scope, quality, team health, and stakeholder impacts.\n- Evaluate user, business, technical, and strategic value with explicit scoring.\n- Present at least the five decision options (add/extend, swap, defer, MVP, reject) and recommend one.\n- Provide decision criteria, escalation triggers, assumptions, and next steps.\n\nFORMAT\nReturn exactly this structure:\n\n<scope_tradeoff_analysis>\n<request_summary>\n## New Request Overview\n\n**Requested by:** [Person/team/stakeholder]\n**Request date:** [When request was made]\n**Context:** [Why this is being requested - user feedback, competitive pressure, stakeholder priority, etc.]\n\n**Description:**\n[Clear, concise description of what's being requested]\n\n**Stated rationale:**\n[Why requester believes this is important]\n\n</request_summary>\n\n<comprehensive_cost_analysis>\n## Effort Breakdown\n\n### Design Effort\n\n**Research and Discovery:** [X hours]\n- [Specific task 1]\n- [Specific task 2]\n- [Continue...]\n\n**Concept and Ideation:** [X hours]\n- [Specific task]\n- [Continue...]\n\n**Detailed Design:** [X hours]\n- [Specific task]\n- [Continue...]\n\n**Iteration and Refinement:** [X hours]\n- [Specific task - design reviews, stakeholder feedback, usability testing]\n- [Continue...]\n\n**Design System Work:** [X hours]\n- [Specific task - new components, variants, documentation]\n- [Continue...]\n\n**Handoff and Specification:** [X hours]\n- [Specific task - redlines, developer collaboration, design QA]\n- [Continue...]\n\n**Total Design Effort:** [X hours] = [Y days]\n\n### Engineering Effort\n\n**Technical Discovery:** [X hours]\n- [Specific task - architecture decisions, feasibility assessment, spike work]\n- [Continue...]\n\n**Frontend Implementation:** [X hours]\n- [Specific task - UI components, styling, interactions, responsive behavior]\n- [Continue...]\n\n**Backend Implementation:** [X hours] (if applicable)\n- [Specific task - API changes, database schema, business logic]\n- [Continue...]\n\n**Integration Work:** [X hours]\n- [Specific task - connecting frontend to backend, third-party services, etc.]\n- [Continue...]\n\n**Testing and Quality:** [X hours]\n- [Specific task - unit tests, integration tests, cross-browser testing]\n- [Continue...]\n\n**Performance Optimization:** [X hours]\n- [Specific task]\n- [Continue...]\n\n**Code Review and Refactoring:** [X hours]\n- [Specific task]\n- [Continue...]\n\n**Total Engineering Effort:** [X hours] = [Y days]\n\n### QA and Validation Effort\n\n**Test Planning:** [X hours]\n- [Specific task]\n- [Continue...]\n\n**Manual Testing:** [X hours]\n- [Specific task - functional, cross-browser, responsive, device testing]\n- [Continue...]\n\n**Automated Testing:** [X hours] (if applicable)\n- [Specific task]\n- [Continue...]\n\n**Regression Testing:** [X hours]\n- [Specific task - ensuring no breakage in existing functionality]\n- [Continue...]\n\n**Accessibility Testing:** [X hours]\n- [Specific task - keyboard navigation, screen reader, WCAG compliance]\n- [Continue...]\n\n**Edge Case Testing:** [X hours]\n- [Specific task]\n- [Continue...]\n\n**Bug Fixing Cycles:** [X hours]\n- [Expected iteration time based on complexity]\n\n**Total QA Effort:** [X hours] = [Y days]\n\n### Documentation and Communication\n\n**User Documentation:** [X hours]\n- [Help articles, tooltips, onboarding content]\n\n**Technical Documentation:** [X hours]\n- [Technical specs, API docs, architecture decisions]\n\n**Stakeholder Communication:** [X hours]\n- [Updates, demos, alignment meetings]\n\n**Team Onboarding:** [X hours]\n- [Training team members on new feature]\n\n**Total Documentation:** [X hours]\n\n### Total Direct Effort\n\n**Total Hours:** [Sum of all above] hours\n**Total Days:** [Accounting for parallel work] days\n**Confidence Level:** [High / Medium / Low]\n- [Explanation of confidence - e.g., \"Medium confidence - design is straightforward but engineering unknowns exist\"]\n\n## Hidden and Indirect Costs\n\n**Technical Debt:**\n- [Description of shortcuts or compromises this introduces]\n- [Future cost to address this debt: X days]\n- [Impact on codebase maintainability or complexity]\n\n**Future Maintenance Burden:**\n- [Ongoing cost to support, enhance, and troubleshoot this feature]\n- [Estimated: X hours per quarter]\n\n**Complexity Tax:**\n- [How this increases overall product or codebase complexity]\n- [Impact on future development speed or onboarding]\n\n**Opportunity Cost:**\n- [What else could be accomplished with this time?]\n- [Specific alternatives: e.g., \"Could complete [other feature] or [technical improvement]\"]\n\n**Context Switching Cost:**\n- [Cost of interrupting current work to accommodate this]\n- [Estimated productivity loss: X hours]\n\n**Risk Additions:**\n- [New failure modes introduced: e.g., \"Additional error states to handle\"]\n- [Increased testing surface area]\n- [Potential user confusion: e.g., \"Adds complexity to already complex flow\"]\n\n**Total Indirect Cost:** [Estimated in hours or qualitative assessment]\n\n</comprehensive_cost_analysis>\n\n<impact_assessment>\n## Impact on Timeline\n\n**Current Committed Deadline:** [Date]\n**Revised Deadline (if adding this):** [New date] (+X days/weeks)\n\n**Milestone Slippage:**\n- [Milestone 1]: [Original date] → [New date]\n- [Milestone 2]: [Original date] → [New date]\n- [Continue...]\n\n**Dependencies Affected:**\n- [Team/project depending on original timeline] - [Impact]\n- [Continue...]\n\n**Market/Business Timing Concerns:**\n- [Product launch window, competitive deadline, seasonal timing, customer commitments, etc.]\n\n## Impact on Scope (If Timeline Holds)\n\n**What must be deprioritized or cut to fit this in:**\n\n**Item 1:** [Feature or work item]\n- **Description:** [What this is]\n- **Current status:** [In progress, planned, etc.]\n- **Value lost:** [User and business impact of cutting this]\n- **Effort saved:** [X days]\n\n**Item 2:** [Feature or work item]\n[Same structure]\n\n[Continue for all items that would need to be cut]\n\n**Total scope reduction:** [X days saved] (offsetting [Y days] required for new request)\n\n## Impact on Quality and Risk\n\n**Testing Coverage:**\n- [Impact on test coverage if timeline is constrained]\n- [Higher bug risk in: specific areas]\n\n**Design Quality:**\n- [Areas where design would be rushed or less polished]\n- [UX debt created: e.g., \"Inconsistency with design system,\" \"Less iteration on interaction model\"]\n\n**Technical Quality:**\n- [Code shortcuts required to meet deadline]\n- [Long-term maintenance issues created]\n\n**Accessibility:**\n- [Risk of cutting accessibility work if time is tight]\n- [Compliance and usability impact]\n\n**User Experience Consistency:**\n- [Risk of poor integration with existing features]\n- [Design system alignment compromised]\n\n## Impact on Team Health\n\n**Morale:**\n- [Effect of constant scope changes on team confidence and trust]\n\n**Burnout Risk:**\n- [If timeline doesn't adjust, team must absorb increased work]\n- [Current team utilization: X% - adding this increases to Y%]\n\n**Context Switching:**\n- [Cost of disrupting current focused work]\n- [Productivity impact]\n\n**Trust and Commitments:**\n- [Impact on team's trust if commitments repeatedly change]\n\n## Stakeholder and Communication Impact\n\n**Who needs to be informed:**\n- [Leadership, marketing, sales, customers, partners, etc.]\n\n**External commitments affected:**\n- [Press releases, customer promises, partnerships, events, etc.]\n\n**Credibility impact:**\n- [Effect on credibility of missing committed dates]\n- [Relationship impact with stakeholders]\n\n</impact_assessment>\n\n<value_evaluation>\n## User Impact Assessment\n\n**Affected Users:**\n- **Percentage/Number:** [e.g., \"30% of active users\" or \"All new users during onboarding\"]\n- **Personas:** [Which specific user types benefit]\n\n**Use Case Frequency:**\n- [How often users encounter this scenario]\n- Daily / Weekly / Monthly / Rare edge case\n\n**Severity of Need:**\n- [ ] **Blocker:** Users cannot accomplish core task without this\n- [ ] **Major friction:** Users can accomplish task but with significant difficulty/inefficiency\n- [ ] **Minor improvement:** Nice-to-have that slightly improves experience\n- [ ] **Delight feature:** Pure enhancement with no functional necessity\n\n**User Workarounds:**\n- [How users currently achieve this goal (if possible)]\n- [Cost/pain of workaround: time, frustration, error rate]\n\n**User Impact Score:** [X/10]\n- **Calculation:** [# users] × [frequency] × [severity]\n- **Rationale:** [Explanation of score]\n\n## Business Impact Assessment\n\n**Revenue Impact:**\n- [Does this directly affect revenue?]\n- **Quantified:** [e.g., \"Expected to increase conversion by 5%, worth $200K annually\"]\n- **Qualitative:** [e.g., \"Required for enterprise sales\" or \"Reduces churn risk\"]\n\n**Cost Savings:**\n- [Does this reduce operational costs, support burden, technical debt?]\n- [Quantified if possible]\n\n**Strategic Alignment:**\n- [ ] **High:** Core to strategic direction, unlocks future initiatives\n- [ ] **Medium:** Supports strategy but not critical path\n- [ ] **Low:** Tangential or unrelated to strategic priorities\n- **Explanation:** [How this fits or doesn't fit strategy]\n\n**Competitive Necessity:**\n- [ ] **Must-have:** Competitors all have this, we're behind without it\n- [ ] **Nice-to-have:** Would match competitors but not falling behind without it\n- [ ] **Differentiator:** Opportunity to exceed competitors and stand out\n- **Explanation:** [Competitive landscape context]\n\n**Market Timing:**\n- [Does this need to launch with initial release?]\n- [Reason: competitive window, customer commitment, seasonal timing, etc.]\n\n**Business Impact Score:** [X/10]\n- **Rationale:** [Explanation based on revenue + strategy + competitive factors]\n\n## Technical and Strategic Impact\n\n**Enables Future Work:**\n- [Does this create foundation for future features?]\n- [Specific examples of what this unlocks]\n\n**Reduces Technical Debt:**\n- [Does this pay down existing debt or prevent future debt?]\n\n**Platform Investment:**\n- [Does this strengthen platform/design system for long-term benefit?]\n\n**Learning Value:**\n- [Does this teach us something important about users or technology?]\n- [Validation or de-risking value]\n\n## Relative Value Comparison\n\n**Value of New Request:** [User impact score + Business impact score] = [Total]\n\n**Value of Work That Would Be Delayed/Cut:**\n- **Item 1:** [Name] - [User impact X/10 + Business impact Y/10] = [Total]\n- **Item 2:** [Name] - [User impact X/10 + Business impact Y/10] = [Total]\n- [Continue...]\n\n**Comparison:**\n[Is new request higher or lower value than what it would replace?]\n\n**Opportunity Cost Analysis:**\n[What else could be accomplished with same effort - specific alternatives and their value]\n\n**Value Ranking:**\n1. [Highest value item]\n2. [Second highest]\n3. [Continue...]\n\n**Conclusion:** [Is new request top priority compared to alternatives?]\n\n</value_evaluation>\n\n<decision_options>\n## Option 1: Add to Scope with Timeline Extension\n\n**Description:** Include new request, extend deadline to accommodate full effort\n\n**Timeline Change:**\n- **Original deadline:** [Date]\n- **New deadline:** [Date] (+X days/weeks)\n\n**Cost:**\n- **Delayed launch:** [Business impact - e.g., \"Miss Q4 launch window\"]\n- **Missed market timing:** [If applicable - competitive announcement, seasonal timing]\n- **Stakeholder impact:** [Who this affects and how]\n- **Team impact:** [Extended project, potential fatigue]\n\n**Benefit:**\n- Full scope delivered with quality\n- No compromises to existing commitments\n- Team has adequate time for quality work\n- All value realized: [New request + existing scope]\n\n**Tradeoff Summary:** More complete product, later delivery\n\n**When to Choose:** Market timing is flexible and complete feature set is more important than launch date\n\n**Risks:**\n- [Market window may close]\n- [Competitor may launch first]\n- [Team morale if project extends too long]\n\n## Option 2: Swap for Existing Scope (Maintain Timeline)\n\n**Description:** Include new request, cut other work to maintain timeline\n\n**What Gets Cut:**\n\n**Cut Item 1:** [Name]\n- **Description:** [What this is]\n- **Value lost:** [User impact X/10, Business impact Y/10]\n- **Justification for cut:** [Why this is lower priority than new request]\n- **Effort saved:** [X days]\n\n**Cut Item 2:** [Name]\n[Same structure]\n\n[Continue...]\n\n**Cost:**\n- Lost value from cut items: [Total value score]\n- Potential technical debt: [If cutting quality work]\n- Future rework: [If cut items need revisiting later]\n\n**Benefit:**\n- Maintain original timeline\n- Deliver new request at launch\n- Value of new request realized: [Score]\n\n**Tradeoff Summary:** Different scope, same timeline\n\n**When to Choose:** New request is higher value than what would be cut, and timeline is immovable\n\n**Risks:**\n- [Value judgment may be wrong - cut item may prove more important]\n- [User confusion if expected features are missing]\n\n## Option 3: Defer to Next Phase/Release\n\n**Description:** Maintain current scope and timeline, add new request to future backlog\n\n**Next Opportunity:** [When this could be addressed - e.g., \"Q2 2025 release\"]\n\n**Cost:**\n- Short-term: Users don't benefit from new request at launch\n- Temporary workaround: [How users handle gap until next release]\n- Potential competitive gap: [If this is competitive feature]\n\n**Benefit:**\n- Maintain scope, timeline, quality of current release\n- Team delivers committed work excellently\n- Validate need post-launch: [Can gather user feedback first]\n- Time to implement properly: [More thoughtful with v1 learnings]\n\n**Tradeoff Summary:** Launch on time with committed scope, add later\n\n**When to Choose:** Current scope is sufficient for launch and new request can wait for v2\n\n**Risks:**\n- [Users may complain about missing feature]\n- [Competitive gap if feature is table stakes]\n\n## Option 4: Deliver Simplified/MVP Version\n\n**Description:** Include reduced version delivering core value with less effort\n\n**Simplified Scope:**\n- **Included:** [Core functionality in MVP]\n- **Deferred:** [Advanced features, edge cases, polish saved for v2]\n\n**Effort Comparison:**\n- **Original estimate:** [X days]\n- **Simplified version:** [Y days]\n- **Savings:** [Z days]\n\n**Cost:**\n- Reduced functionality: [What users don't get]\n- Future enhancement needed: [Likely to revisit]\n- Potential user confusion: [If simplified version has limitations]\n\n**Benefit:**\n- Partial value realized now\n- Lower cost and risk\n- Validate before full investment\n- Enhance in future based on usage\n\n**Tradeoff Summary:** Some value now, full value later\n\n**When to Choose:** Core value can be delivered simply and full version can wait for validation\n\n**Risks:**\n- [Users may be confused by limitations]\n- [May create technical debt if MVP not architected for future expansion]\n\n## Option 5: Reject (Maintain Current Plan)\n\n**Description:** Do not include new request in current project\n\n**Cost:**\n- Value of request not realized\n- Requester may be disappointed\n- Potential missed opportunity\n\n**Benefit:**\n- Team maintains focus\n- Delivers committed work with quality\n- Preserves timeline and stakeholder commitments\n\n**Tradeoff Summary:** Focused delivery of original scope\n\n**When to Choose:** New request is significantly lower value than committed work and can be addressed separately (or not at all)\n\n**Risks:**\n- [Requester pushback]\n- [May have been right that this was important]\n\n</decision_options>\n\n<recommendation>\n## Recommended Approach\n\n**Selected Option:** [Option number and name]\n\n**Rationale:**\n\n**Value Analysis:**\n- [How value of new request compares to alternatives]\n- [Whether value justifies cost and tradeoffs]\n\n**Cost-Benefit:**\n- [Effort required: X days]\n- [Value delivered: Y score]\n- [Comparison to alternatives]\n\n**Strategic Fit:**\n- [Alignment with company/product goals and priorities]\n- [Long-term vs. short-term considerations]\n\n**Risk Assessment:**\n- [Key risks identified]\n- [How chosen option mitigates or accepts risks]\n\n**Key Deciding Factors:**\n1. **[Factor 1]:** [e.g., \"Market timing is critical - launch date cannot slip\"]\n2. **[Factor 2]:** [e.g., \"New request has 8/10 user impact vs. cut item with 4/10\"]\n3. **[Factor 3]:** [e.g., \"Simplified version delivers 80% value for 30% effort\"]\n\n**Confidence Level:** [High / Medium / Low]\n- **Explanation:** [Why this confidence level - known vs. unknown factors]\n\n**Alternative if Context Changes:**\n- **If [assumption/constraint changes]:** [Consider alternative option]\n- **Example:** \"If launch deadline extends by 3 weeks, reconsider Option 1 (full scope with timeline extension)\"\n\n</recommendation>\n\n<decision_framework>\n## Questions to Guide Decision\n\n**Must-Have Test:**\n- Is this absolutely required for product to be useful/sellable at launch?\n- Why or why not?\n- What's the minimum viable version needed?\n\n**User Workaround Assessment:**\n- Can users accomplish their goal without this feature?\n- What's the cost of that workaround (time, frustration, errors)?\n- Is the workaround acceptable short-term?\n\n**Delay Cost Analysis:**\n- What happens if we launch without this and add it in next release?\n- Do we lose customers, revenue, or competitive position?\n- Or is delay impact minimal?\n\n**Value Comparison:**\n- Is this higher priority than what it would delay or replace?\n- Run the value scores side-by-side\n- What do users and business need most?\n\n**Risk Tolerance:**\n- Are we willing to accept quality/timeline tradeoffs to include this?\n- What risks are acceptable vs. unacceptable?\n- What's our risk appetite right now?\n\n**Strategic Lens:**\n- Does this advance our strategic vision and differentiation?\n- Or is this a distraction from core value proposition?\n\n## Decision Criteria\n\n**Inclusion threshold:**\n- If [User impact score × Business impact score] ≥ [Threshold - e.g., 50], strongly consider including\n- If below threshold, likely defer or reject\n\n**Capacity check:**\n- If [Effort estimate] > [Available capacity buffer], timeline MUST extend or scope MUST swap\n- If within buffer, can potentially absorb\n\n**Timeline constraint:**\n- If [Timeline delay] > [Acceptable window - e.g., 2 weeks], must cut other scope or reject\n- If within acceptable delay, timeline extension is option\n\n**Authority escalation:**\n- If requester is [C-level or VP], escalate to [decision maker at same level]\n- Ensure tradeoffs are visible to appropriate decision-making level\n\n## Escalation Triggers\n\n**Escalate to [Leadership Level] if:**\n- Timeline impact exceeds [X weeks]\n- Scope change affects previously communicated external commitments (customer, press, partnerships)\n- Multiple senior stakeholders disagree on priority\n- Request comes from executive leadership (requires executive tradeoff discussion)\n- Team flags significant technical risk, debt, or feasibility concerns\n\n**Decision Owner:** [Role - PM, Design Lead, Director, VP, etc.]\n\n**Decision Timeline:** Decision must be made by [Date] to avoid impacting project critical path\n\n</decision_framework>\n\n<assumptions_and_next_steps>\n## Key Assumptions\n\n**Assumption 1:** [e.g., \"Effort estimate assumes no major technical blockers\"]\n- **Validation needed:** [Engineering spike or deeper technical review]\n- **If wrong:** [Impact on recommendation]\n\n**Assumption 2:** [e.g., \"User impact score based on current usage patterns\"]\n- **Validation needed:** [User research or analytics review]\n- **If wrong:** [Impact on recommendation]\n\n**Assumption 3:** [e.g., \"Timeline extension assumes no dependencies on other teams\"]\n- **Validation needed:** [Confirm with dependent teams]\n- **If wrong:** [Impact on recommendation]\n\n[Continue for all key assumptions]\n\n## Validation Needed\n\n**Before final decision:**\n- [ ] Engineering review of effort estimate for technical accuracy\n- [ ] Stakeholder confirmation of whether timeline can extend (if considering Option 1)\n- [ ] Product/business review of value assessment\n- [ ] Team capacity check for bandwidth to absorb (if considering Option 2 or 4)\n\n## Next Steps\n\n**Immediate:**\n1. Share this analysis with decision maker and key stakeholders\n2. Schedule decision meeting by [Date]\n3. Gather validation inputs listed above\n\n**Post-Decision:**\n\n**If approved (Option 1, 2, or 4):**\n- Update project plan with new scope\n- Adjust milestones and timeline\n- Communicate changes to team and affected stakeholders\n- Update external commitments (if timeline changed)\n- Reprioritize backlog (if scope swapped)\n\n**If deferred (Option 3):**\n- Add to backlog with full context from this analysis\n- Set review date for next planning cycle [Date]\n- Communicate decision and rationale to requester\n- Document why deferred for future reference\n\n**If rejected (Option 5):**\n- Document decision and rationale\n- Communicate thoughtfully to requester (explain tradeoffs, not just \"no\")\n- Note for future: if this request returns, reference this analysis\n\n**Communication Plan:**\n- [Who to inform of decision]\n- [What to communicate (decision, rationale, timeline impact)]\n- [When to communicate (immediately post-decision)]\n\n</assumptions_and_next_steps>\n</scope_tradeoff_analysis>\n\nFAILURE\n- Any required section in `<scope_tradeoff_analysis>` is missing or materially incomplete.\n- Cost breakdown, impact assessment, or value evaluation is missing or superficial.\n- Recommendation lacks clear rationale or does not reference tradeoff options.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Project Management/Task list optimization and contingency-based project planning.md",
      "title": "Task list optimization and contingency-based project planning",
      "category": "Project Management",
      "tags": [
        "project-management",
        "planning",
        "scheduling",
        "risk-management"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{TASK_LIST}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Task list optimization and contingency-based project planning.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Analyze and optimize `{{TASK_LIST}}` by identifying dependencies, gaps, and ambiguities.\n- Add missing tasks needed for completion and clarify ambiguous items.\n- Sequence tasks for efficiency, highlight critical path, and assign rough durations.\n- Identify resource constraints and opportunities for parallel execution.\n- Build contingency plans with blockers, workarounds, and buffers.\n- Define decision milestones with go/no-go criteria and metrics.\n- Include a brief explanation of sequencing and key decisions.\n\nFORMAT\nReturn exactly this structure:\n\n<optimized_plan>\n  <task_sequence>\n  [Sequenced tasks including dependencies, rough durations, critical path markers, and any added tasks]\n  </task_sequence>\n  <clarifications>\n  [Clarifications for ambiguous tasks and questions if needed]\n  </clarifications>\n  <contingency_plans>\n  [Potential blockers with contingency actions and buffers]\n  </contingency_plans>\n  <decision_framework>\n  [Milestones with go/no-go criteria and metrics]\n  </decision_framework>\n</optimized_plan>\n\n<explanation>\n[Brief reasoning for sequence, added tasks, and key decisions]\n</explanation>\n\nFAILURE\n- Any required section (`<optimized_plan>` with its child tags, and `<explanation>`) is missing or materially incomplete.\n- Task sequence lacks dependencies, sequencing logic, or critical path indicators.\n- Contingencies or decision criteria are missing or not actionable.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Stakeholder Management/Challenging meeting with stakeholders.md",
      "title": "Challenging meeting with stakeholders",
      "category": "Stakeholder Management",
      "tags": [
        "stakeholders",
        "meeting-prep",
        "risk-management"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{GOAL_OR_CONTEXT}}\n- {{STAKEHOLDERS}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Challenging meeting with stakeholders.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Generate at least 20 challenging stakeholder questions based on `{{GOAL_OR_CONTEXT}}` and `{{STAKEHOLDERS}}`.\n- Cover financials, resources, timeline, risks, market, competition, feasibility, UX, ethics, sustainability, team capability, past performance, strategy alignment, compliance, and scalability.\n- Make questions rigorous and probing; avoid generic filler.\n\nFORMAT\nReturn exactly this structure:\n\n<question_list>\n1. [First question]\n2. [Second question]\n3. [Third question]\n...\n</question_list>\n\nFAILURE\n- `<question_list>` is missing, malformed, or has fewer than 20 questions.\n- Questions are generic, repetitive, or not tied to the provided context.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Stakeholder Management/Conflicting stakeholder requirements to balanced design approach.md",
      "title": "Conflicting stakeholder requirements to balanced design approach",
      "category": "Stakeholder Management",
      "tags": [
        "stakeholder-management",
        "design-strategy",
        "conflict-resolution"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{CONFLICTING_REQUIREMENTS}}\n- {{STAKEHOLDER_PRIORITIES}}\n- {{PROJECT_CONTEXT}}\n- {{USER_RESEARCH_INSIGHTS}}\n- {{TECHNICAL_CONSTRAINTS}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Conflicting stakeholder requirements to balanced design approach.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Reconcile `{{CONFLICTING_REQUIREMENTS}}` using `{{STAKEHOLDER_PRIORITIES}}`, `{{PROJECT_CONTEXT}}`, `{{USER_RESEARCH_INSIGHTS}}`, and `{{TECHNICAL_CONSTRAINTS}}`.\n- Map conflict types, stakeholder positions, severity, and dependencies.\n- Identify root causes, then propose win-win solutions and explicit tradeoffs.\n- Provide a recommendation with rationale, decision framework, communication plan, and validation plan.\n\nFORMAT\nReturn exactly this structure:\n\n<conflict_reconciliation>\n<executive_summary>\n**Project:** [Project name]\n**Conflicting Requirements Count:** [Number of major conflicts identified]\n**Stakeholders Involved:** [List key stakeholders and their roles]\n**Conflict Severity:** [Low/Medium/High - overall assessment]\n**Resolution Approach:** [Win-win solutions possible / Tradeoffs required / Phased approach needed]\n**Decision Timeline:** [When final decision needed]\n**Recommendation:** [One-sentence summary of proposed path forward]\n</executive_summary>\n\n<conflict_mapping>\nMap each significant conflict clearly with all relevant details, stakeholder positions, user research insights, and dependencies.\n\n## Conflict #1: [Name]\n\n**Requirement A:** [Full description]\n**Stakeholder:** [Name, role, underlying goal, success metric]\n\n**Requirement B:** [Full description]\n**Stakeholder:** [Name, role, underlying goal, success metric]\n\n**Conflict Type:** [Classification]\n**Severity:** [Level and why]\n**Impact:** [What's affected]\n**User Research:** [What data says]\n**Alignment:** [Who supports each side]\n**Dependencies:** [Related conflicts]\n\n[Repeat for each major conflict]\n</conflict_mapping>\n\n<root_cause_analysis>\nIdentify fundamental causes driving conflicts:\n\n**[Root Cause Category]:**\n[Detailed explanation of this underlying issue]\n**Examples:** [Specific manifestations]\n**→ Root cause:** [One-line summary]\n\n[Continue for all root cause categories identified]\n\n**Key Insights:**\n[Major patterns and observations]\n</root_cause_analysis>\n\n<win_win_solutions>\n## Solution for Conflict #[X]: [Name]\n\n**Approach: [Solution Name]**\n\n**How It Works:**\n[Detailed 3-5 bullet explanation of the creative solution]\n\n**Why It's Win-Win:**\n- ✅ [Stakeholder A benefit]\n- ✅ [Stakeholder B benefit]\n- ✅ [User benefit]\n- ✅ [Business benefit]\n\n**Implementation:**\n- Phase 1: [Details, timeline]\n- Phase 2: [Details, timeline]\n- Phase 3: [Details, timeline]\n\n**Validation:**\n[How to test this works]\n\n**Potential Risks:**\n[What could go wrong and mitigations]\n\n[Repeat for each win-win solution]\n</win_win_solutions>\n\n<tradeoff_analysis>\n## For Conflict #[X]: [Name] (Requires Tradeoff)\n\n### Option A: [Name] (Favors [Stakeholder])\n\n**Approach:** [What we'd do]\n**Gains:** [What winning party gets]\n**Losses:** [What losing party sacrifices]\n**User Impact:** [Effects on users]\n**Business Impact:**\n- Short-term: [Impact]\n- Long-term: [Impact]\n**Complexity:** [Level]\n**Timeline:** [Duration]\n**Risk:** [Assessment]\n**Reversibility:** [How hard to change]\n\n### Option B: [Name] (Favors [Other Stakeholder])\n\n[Same structure]\n\n### Option C: [Balanced Approach] (Recommended)\n\n**Approach:** [Compromise solution]\n**Everyone Gains Partially:** [How it balances]\n**Implementation:** [Detailed plan]\n**Quality Gates:** [Must-meet criteria]\n**Why Recommended:** [Justification]\n**Tradeoffs Accepted:** [Explicit acknowledgment]\n**Success Metrics:** [How to measure]\n\n[Repeat for conflicts needing tradeoff decisions]\n</tradeoff_analysis>\n\n<decision_framework>\n## For Unresolved Conflicts\n\n**Decision Criteria:**\n1. [Criterion]: [Description, weight, how to evaluate]\n2. [Criterion]: [Description, weight, evaluation method]\n[Continue for all criteria]\n\n**Decision Authority Matrix:**\n[Table showing who decides what]\n\n**When Stakeholders Disagree:**\n1. Try data-driven resolution\n2. Structured discussion\n3. Escalation if needed\n4. Document and commit\n\n**Information Needed:** [Data gaps to fill]\n**Timeline:** [When decisions must be made]\n**Validation:** [How to verify decisions work]\n**Adjustment Triggers:** [Signals to reconsider]\n**Rollback Plan:** [How to reverse if wrong]\n</decision_framework>\n\n<communication_plan>\n## Stakeholder Alignment Strategy\n\n**Pre-Meeting 1:1s:**\n[Process for individual conversations]\n\n**Facilitated Group Session:**\n**Agenda:**\n1. Present conflicts (15 min)\n2. Root causes (10 min)\n3. Win-win solutions (20 min)\n4. Tradeoff discussion (30 min)\n5. Make decisions (15 min)\n6. Document (10 min)\n\n**Ground Rules:** [Discussion norms]\n**Materials:** [What's needed]\n\n**Documentation:**\n[Decision record template with rationale, commitments, metrics, review dates]\n\n**Ongoing Communication:**\n- Weekly syncs\n- Monthly metrics reviews\n- Quarterly retrospectives\n</communication_plan>\n\n<validation_iteration>\n## Testing Assumptions\n\n### Decision: [Name]\n\n**Assumptions:**\n1. [Assumption to test]\n2. [Assumption to test]\n\n**Validation Approach:**\n- Phase 1: [Method, timeline, criteria]\n- Phase 2: [Method, timeline, criteria]\n- Phase 3: [Method, timeline, criteria]\n\n**Instrumentation:** [What data to collect]\n**User Research:** [Qualitative validation]\n**Success Criteria:** [Specific thresholds]\n\n**Adjustment Plan:**\nIf [assumption] proves wrong: [What we'll do]\n\n**Learning Documentation:** [How to capture insights]\n\n[Repeat for each major decision]\n</validation_iteration>\n\n<process_improvements>\n## Preventing Future Conflicts\n\n**1. [Improvement]**\n- Problem Solved: [Pattern prevented]\n- Implementation: [How to do it]\n- Owner: [Who's responsible]\n- Timeline: [When]\n\n[Continue for all process improvements identified]\n</process_improvements>\n\n</conflict_reconciliation>\n\nFAILURE\n- Any required section in `<conflict_reconciliation>` is missing or materially incomplete.\n- Conflict mapping or root cause analysis is shallow or not grounded in inputs.\n- Tradeoff analysis or recommendation lacks explicit rationale.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Stakeholder Management/Critical flaws in product requirements (tough and unreasonable product executive).md",
      "title": "Critical flaws in product requirements (tough and unreasonable product executive)",
      "category": "Stakeholder Management",
      "tags": [
        "product-management",
        "requirements",
        "strategy",
        "stakeholder-management"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{PRODUCT_REQUIREMENTS}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Critical flaws in product requirements (tough and unreasonable product executive).\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Critique `{{PRODUCT_REQUIREMENTS}}` as a tough, skeptical product executive.\n- Identify flaws in cross-team ownership, conflicting requirements, maintainability, strategic implications, clarity, and feasibility.\n- Provide a detailed critique for each major section or point.\n- End with a concise overall assessment emphasizing the most critical risks and likely impact.\n\nFORMAT\nReturn exactly this structure:\n\n<critique>\n<section>[Name or number of the section you're critiquing]</section>\n<issue>[Describe the specific issue you've identified]</issue>\n<impact>[Explain the potential negative impact of this issue]</impact>\n<suggestion>[If applicable, provide a suggestion for improvement, but make it sound reluctant and skeptical]</suggestion>\n</critique>\n\n<overall_assessment>\n[Final paragraph summarizing the most critical issues and their impact]\n</overall_assessment>\n\nFAILURE\n- `<critique>` sections are missing, malformed, or not tied to specific requirement sections.\n- `<overall_assessment>` is missing or lacks a clear summary of top risks.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Stakeholder Management/Decision rights using DAVCI.md",
      "title": "Decision rights using DAVCI",
      "category": "Stakeholder Management",
      "tags": [
        "decision-rights",
        "product-ops",
        "facilitation",
        "governance",
        "stakeholder-management"
      ],
      "content": "INPUTS\n<provided_inputs>\n- [No explicit variables declared; use provided context.]\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Decision rights using DAVCI.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Enforce DAVCI with hard rules:\n- Exactly one `D` per decision.\n- `A` is optional and cannot equal `D`.\n- `V` is at most one person per domain (`Security`, `Legal`, `Privacy`, `Brand`, `Compliance`, `Other`) with a time-boxed window (default `48h` if missing).\n- `C` and `I` use role names; keep `C <= 5`, `I <= 15`, and `C+I <= 20`.\n- Every decision includes title, deadline (date + time), type, escalation, success test, and comms plan.\n- Run rapid intake, split into 1-5 decision objects, assign DAVCI per object, and auto-correct rule violations immediately.\n- Apply defaults when missing (`TBD` allowed), including fallback deadlines by urgency.\n- For each decision object, output the exact DAVCI card fields plus a ready-to-send summary line.\n- Handle edge cases (multi-team layering, multi-domain veto order, emergency windows, non-response, D handoff).\n- Offer short follow-ups (calendar text, Slack draft, Jira/PR/design header snippet).\n\nFORMAT\nReturn exactly this structure:\n\nKickoff:\nTell me the situation in 3-5 sentences and the hard deadline (date + time). Include the names/roles you think matter. I'll split it into the right decision objects and we'll assign DAVCI for each in under 30 minutes.\n\nRapid intake questions:\n1. [Question 1]\n2. [Question 2]\n3. [Question 3]\n4. [Question 4]\n5. [Question 5]\n6. [Question 6]\n7. [Question 7]\n8. [Question 8]\n\nDecision objects:\n- Object 1: [short name] - [why separate]; draft deadline [date/time]\n- [Object 2..5 if needed]\n\nDecision: [short title]\nContext: [1-2 short sentences]\nDeadline: [date and time]\nType: [Strategy|Scope|Design|Technical|Process|Risk|Commercial|Other]\nD: [name, role]\nA: [name, role] or \"None\"\nV: [Domain - name, window hours]; [Domain - name, window hours]\nC: [role/name]; [role/name]\nI: [role/name]; [role/name]\nEscalation: [name, role]\nSuccess test: [single checkable sentence]\nComms: [channels + audience + timing]\nNotes/Risks: [short list if any]\n\nDecision summary:\nDecision: [title]. D: [name]. Deadline: [date/time]. Veto windows: [domain - window]. Cs: [roles]. Escalation: [name]. Success test: [test]. Comms: [plan]. Reply with blockers within your window; otherwise we proceed.\n\nFollow-ups:\n- [15-minute review calendar text offer]\n- [Slack post draft offer]\n- [Jira/PR/design header snippet offer]\n\nFAILURE\n- DAVCI rule violations are not auto-corrected (`D` count, `A==D`, multi-holder veto domain, missing veto window, `C/I` caps).\n- Missing required decision fields (deadline, type, escalation, success test, comms).\n- Output does not include both DAVCI card(s) and decision summary line(s).\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Stakeholder Management/Demo narratives showing user goals.md",
      "title": "Demo narratives showing user goals",
      "category": "Stakeholder Management",
      "tags": [
        "product-demo",
        "storytelling",
        "prototypes",
        "user-goals",
        "stakeholder-management"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{PROTOTYPE}}\n- {{USER_GOALS}}\n- {{AUDIENCE}}\n- {{CONSTRAINTS}}\n- {{RESEARCH_INSIGHTS}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Demo narratives showing user goals.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Follow these task requirements:\n<task_requirements>\nYou are a prototype storytelling specialist skilled at crafting compelling demo narratives that showcase how products solve real user problems. Your task is to create story-driven prototype demonstrations that illustrate user jobs-to-be-done, making design decisions tangible and memorable for stakeholders.\n\nYou will be provided with:\n\n<prototype>\n{{PROTOTYPE}}\n</prototype>\n\n<user_goals>\n{{USER_GOALS}}\n</user_goals>\n\n<audience>\n{{AUDIENCE}}\n</audience>\n\n<constraints>\n{{CONSTRAINTS}}\n</constraints>\n\n<research_insights>\n{{RESEARCH_INSIGHTS}}\n</research_insights>\n\nFollow these steps to create a compelling demo narrative:\n\n1. Define the protagonist and their context:\n   - Create a specific, believable user persona (not generic \"Sarah the marketer\")\n   - Establish their role, responsibilities, and daily workflow\n   - Identify their current pain points and frustrations\n   - Clarify what success looks like in their world\n   - Define their technical proficiency and tool familiarity\n   - Establish environmental context (where, when, with whom they work)\n   - Root persona in real research data, not assumptions\n   - Include relevant psychological motivators (what drives their decisions)\n   - Specify constraints they operate under (time, budget, authority)\n   - Identify who else is involved in their workflow (collaborators, approvers)\n\n2. Construct the narrative scenario:\n   - **Inciting incident**: What triggers the need to use your product?\n   - **Stakes**: Why does this matter? What happens if they fail?\n   - **Timeline**: How urgent is the need? What's the deadline?\n   - **Environmental factors**: What else is happening around them?\n   - **Emotional state**: How are they feeling at the start?\n   - **Prior attempts**: What have they already tried?\n   - **Success criteria**: What specific outcome would resolve their problem?\n   - **Realistic scope**: Keep scenario bounded and believable (not \"redesign entire company\")\n   - **Concrete details**: Specific numbers, names, dates that make it real\n   - **Relatable situation**: Audience should recognize this scenario\n\n3. Map the user journey through your prototype:\n   - **Entry point**: How do they arrive at your product? (link, search, bookmark, notification)\n   - **First impression**: What do they see/think in first 3 seconds?\n   - **Orientation**: How do they figure out what to do next?\n   - **Progressive disclosure**: What information appears when they need it?\n   - **Key decision points**: Where do they make choices?\n   - **Error/uncertainty moments**: Where might they hesitate or make mistakes?\n   - **Confirmation moments**: How does the system validate they're on track?\n   - **Aha moments**: When does value become clear?\n   - **Completion**: What signals they've achieved their goal?\n   - **Next steps**: What happens after this task?\n   - **Realistic pacing**: Allow time for reading, thinking, not just clicking\n   - **Natural interruptions**: Phone call, question from colleague (shows resilience)\n   - **Context switching**: They leave and come back (tests findability)\n\n4. Script the demo walkthrough with dialogue:\n   - **Scene setting**: \"It's Tuesday afternoon, Alex has 30 minutes before a client meeting...\"\n   - **Internal monologue**: Share user's thoughts at key moments\n   - **Narration style**: First-person (\"I need to...\") or third-person (\"Alex notices...\")\n   - **Action descriptions**: Specific interactions (click, scroll, type exact text)\n   - **System responses**: What happens after each action\n   - **Decision rationale**: Why user chooses option A over B\n   - **Emotional beats**: Frustration → confusion → clarity → confidence\n   - **Realistic hesitations**: \"Hmm, where would that be... probably in settings\"\n   - **Course corrections**: Show user recovering from wrong path\n   - **Time markers**: \"2 minutes later...\" to show efficiency\n   - **Verbatim UI text**: Quote exact button labels, headings, messages\n   - **Highlighting patterns**: \"The bold CTA immediately draws attention to...\"\n\n5. Add contextual annotations explaining design decisions:\n   - **Why this flow**: Design rationale for the path shown\n   - **Alternatives considered**: What other approaches were explored\n   - **Research backing**: User data supporting this design choice\n   - **Progressive disclosure**: Why certain info appears when it does\n   - **Accessibility considerations**: How inclusive design shows up\n   - **Error prevention**: How design prevents common mistakes\n   - **Cognitive load management**: How complexity is managed\n   - **Pattern consistency**: How this follows established conventions\n   - **Performance implications**: Loading states, perceived speed\n   - **Edge case handling**: What happens in unusual situations\n   - **Technical constraints**: Limitations that shaped decisions\n   - **Future enhancements**: What's intentionally deferred to V2\n\n6. Prepare for live demonstration delivery:\n   - **Pre-demo setup**: What needs to be configured in advance\n   - **Data staging**: Realistic content loaded into prototype\n   - **Fallback plans**: What if tech fails mid-demo\n   - **Interaction notes**: Exactly which hotspots to click, what to type\n   - **Pacing guidelines**: How fast to move through each section\n   - **Pause points**: Where to stop for questions or emphasis\n   - **Audience engagement**: Where to ask \"Have you experienced this?\"\n   - **Comparison moments**: \"Unlike current process where you'd...\"\n   - **Zoom-in callouts**: Specific UI details to highlight\n   - **Branching paths**: Alternative routes if audience asks \"what if...\"\n\n7. Document variations for different audiences:\n   - **Executive version**: Business outcomes, ROI, strategic alignment (5 min)\n   - **End user version**: Detailed workflow, all features, realistic use (15 min)\n   - **Technical version**: Integration points, data flow, architecture (10 min)\n   - **Sales version**: Competitive advantages, objection handling (8 min)\n   - **Stakeholder review**: Design rationale, research validation (20 min)\n   - **Usability test**: Minimal guidance, observe natural exploration (no script)\n\nPresent your demo narrative in this format:\n\n<demo_narrative>\n<persona_profile>\n**Name:** [Specific name with relevant context - e.g., \"Jordan Chen, Operations Manager at 200-person logistics company\"]\n\n**Role and Responsibilities:**\n[Detailed description of their job, what they're accountable for, who they report to]\n\n**Daily Workflow:**\n[Typical day-in-the-life - what tools they use, what meetings they attend, what reports they create]\n\n**Current Pain Points:**\n- [Pain 1]: [Specific frustration with concrete example]\n- [Pain 2]: [Specific frustration with concrete example]\n- [Pain 3]: [Specific frustration with concrete example]\n\n**Technical Proficiency:**\n[Their comfort level with technology, what tools they already use successfully]\n\n**Success Metrics:**\n[How their performance is measured - what they're trying to optimize]\n\n**Constraints:**\n- Time: [Specific time pressures they face]\n- Budget: [Financial limitations or approval processes]\n- Authority: [What they can decide vs. need approval for]\n\n**Motivations:**\n[What drives their behavior - career goals, team dynamics, personal values]\n\n**Research Foundation:**\n[Which user interviews/studies informed this persona - quote specific findings]\n</persona_profile>\n\n<scenario_setup>\n**Scene:**\n[Vivid description of when/where this is happening - day, time, location, environmental context]\n\n**Inciting Incident:**\n[What just happened that creates the need to use your product?]\n\n**Stakes:**\n[Why this matters - what happens if they succeed vs. fail]\n\n**Timeline:**\n[How urgent is this? When's the deadline?]\n\n**Emotional State:**\n[How they're feeling - stressed, curious, overwhelmed, hopeful]\n\n**Prior Context:**\n[What have they already tried? Why didn't it work?]\n\n**Success Outcome:**\n[Concrete description of what resolution looks like]\n\n**Realistic Scope:**\n[Boundaries of this scenario - what's in/out of scope]\n\nExample:\n\"It's Thursday at 3pm. Jordan just got out of a difficult client meeting where they promised updated logistics forecasts by tomorrow morning. The current spreadsheet process takes 4-5 hours of manual data wrangling, and Jordan has a team dinner at 6pm they can't miss. Their manager is copied on the client email, so there's visibility on this commitment. Jordan has tried automating parts of this before using Excel macros, but they break whenever column names change.\"\n</scenario_setup>\n\n<demo_script>\n<act_1_arrival>\n**Narration:**\n[Scene-setting description in present tense]\n\n**Jordan's Thought:**\n\"[Internal monologue showing their mental state]\"\n\n**Action:**\n[Exactly what they do - specific clicks, URLs, navigation]\n\n**System Response:**\n[What appears on screen - describe layout, key elements visible]\n\n**Jordan's Reaction:**\n\"[Thought about what they see]\"\n\n**Design Note:**\n[Annotation explaining why interface works this way - research backing, design principle, accessibility consideration]\n\nExample:\n**Narration:** Jordan opens their laptop and clicks the bookmark for ForecastPro, which their team started piloting last week.\n\n**Jordan's Thought:** \"Okay, I need to pull Q4 logistics data and create those regional forecasts they asked for. Let me see if this new tool can actually help.\"\n\n**Action:** Jordan lands on the dashboard homepage.\n\n**System Response:** The screen shows a clean interface with three prominent options: \"Create New Forecast,\" \"View Recent Reports,\" and \"Import Data.\" A subtle notification badge shows \"2\" on Recent Reports.\n\n**Jordan's Reaction:** \"Good, I can see my starting points clearly. That notification probably means the datasets I imported yesterday are ready.\"\n\n**Design Note:** We use a minimal three-option entry to prevent choice paralysis. Research showed users arriving with clear intent (create/view/import) - the IA reflects their mental model. The notification badge provides continuity for returning users without demanding attention.\n</act_1_arrival>\n\n<act_2_core_task>\n[Continue narrative through the main workflow - include 5-8 key moments:]\n- Initial orientation and confidence building\n- First meaningful action with immediate feedback\n- Decision point with clear affordances\n- Potential confusion or error → system guidance\n- Progress indicator showing advancement\n- Confirmation of successful completion\n- Next action suggested\n\n[For each moment, include: Narration, Jordan's Thought, Action, System Response, Jordan's Reaction, Design Note]\n</act_2_core_task>\n\n<act_3_completion>\n**Narration:**\n[Description of reaching the goal]\n\n**Jordan's Thought:**\n\"[Realization of success and what it means]\"\n\n**Action:**\n[Final action - export, share, save, etc.]\n\n**System Response:**\n[Confirmation message, next steps offered]\n\n**Jordan's Reaction:**\n\"[Emotional beat - relief, satisfaction, confidence]\"\n\n**Time Check:**\n[How long this took vs. old method]\n\n**Outcome:**\n[What Jordan achieved and why it matters]\n\nExample:\n**Narration:** The final forecast report generates in seconds, formatted exactly how the client expects it.\n\n**Jordan's Thought:** \"Wait, that's it? That would've taken me until 7pm with the old process. And it's already in the right format.\"\n\n**Action:** Jordan clicks \"Export to Email\" and adds the client's address, with their manager CC'd.\n\n**System Response:** \"Report sent successfully. Forecast will auto-update weekly and notify stakeholders.\" A subtle animation shows the email icon confirming delivery.\n\n**Jordan's Reaction:** \"Okay, this actually worked. And now it'll update automatically? That's huge.\"\n\n**Time Check:** Task completed in 8 minutes vs. the usual 4-5 hours.\n\n**Outcome:** Jordan has the rest of the afternoon free, makes it to team dinner on time, and gained credibility with the client by delivering early. More importantly, this forecast will now maintain itself weekly.\n</act_3_completion>\n</demo_script>\n\n<key_moments_summary>\n**1. First Impression (0:30):**\n[What makes user confident they're in right place]\n\n**2. Aha Moment (2:15):**\n[When value becomes clear - what triggered the realization]\n\n**3. Trust Moment (4:30):**\n[When user believes system is reliable - what convinced them]\n\n**4. Completion Moment (7:45):**\n[When goal achieved - what confirmed success]\n\n**5. Delight Moment (8:00):**\n[Unexpected positive - what exceeded expectations]\n\n[For each: timestamp, description, why it matters, supporting design element]\n</key_moments_summary>\n\n<contextual_annotations>\n**Design Decisions Showcased:**\n1. [Decision]: [Rationale + Research backing]\n2. [Decision]: [Rationale + Research backing]\n3. [Decision]: [Rationale + Research backing]\n\n**Pattern Library Elements:**\n- [Pattern used]: [Why appropriate for this context]\n- [Pattern used]: [Why appropriate for this context]\n\n**Accessibility Features Highlighted:**\n- [Feature]: [How it helps specific users]\n- [Feature]: [How it helps specific users]\n\n**Progressive Disclosure Examples:**\n- [Information]: [Why hidden until needed]\n- [Information]: [Why hidden until needed]\n\n**Error Prevention:**\n- [Mechanism]: [What mistake it prevents]\n- [Mechanism]: [What mistake it prevents]\n\n**Performance Considerations:**\n- [Optimization]: [Why it matters for this scenario]\n- [Optimization]: [Why it matters for this scenario]\n</contextual_annotations>\n\n<demo_delivery_guide>\n<pre_demo_setup>\n**Prototype Configuration:**\n- [Setting to configure]: [Specific value]\n- [Data to load]: [Where to source realistic content]\n- [Browser/device]: [Recommended setup]\n\n**Rehearsal Checklist:**\n- [ ] All hotspots clickable and lead to correct screens\n- [ ] Realistic data loaded (names, numbers, dates)\n- [ ] Timing rehearsed (should feel natural, not rushed)\n- [ ] Annotations hidden unless presenter decides to show\n- [ ] Fallback screenshots available if tech fails\n</pre_demo_setup>\n\n<live_demo_script>\n**Opening (30 seconds):**\n\"Let me show you how [persona] uses this to solve [specific problem]. Watch for how the design handles [key challenge].\"\n\n**Scene Setting (15 seconds):**\n\"[Vivid description of scenario - day, time, what just happened]\"\n\n**Walkthrough (5-10 minutes):**\n[Step by step with exact interactions:]\n1. [Action to take] → [What to say while doing it] → [What to point out]\n2. [Action] → [Narration] → [Callout]\n3. [Continue for key flow]\n\n**Pause Points:**\n- After [moment]: \"Notice how [design element] helps with [user need]\"\n- After [moment]: \"Have you encountered this problem in your workflow?\"\n- After [moment]: \"Unlike [current process], this approach [advantage]\"\n\n**Closing (30 seconds):**\n\"In under [time], Jordan accomplished [outcome] - compared to [old way]. Key differentiators: [list 2-3 specific advantages shown].\"\n\n**Q&A Preparation:**\n- If asked about [edge case]: [Navigate to X screen and show Y]\n- If asked about [integration]: [Show Z and explain technical approach]\n- If asked about [alternative path]: [Click A instead of B to demonstrate]\n</live_demo_script>\n\n<pacing_notes>\n**Total Time:** [Recommended duration for full narrative]\n\n**Section Breakdown:**\n- Setup and context: [X minutes]\n- Core task demonstration: [Y minutes]\n- Completion and outcome: [Z minutes]\n- Q&A buffer: [W minutes]\n\n**Speed Guidelines:**\n- Speak at conversational pace (not presentation pace)\n- Allow 3-5 seconds after each screen transition for audience to orient\n- Pause after key moments to let impact land\n- Don't rush through error recovery - that's valuable to show\n\n**Energy Modulation:**\n- Build excitement as user progresses toward goal\n- Allow authentic hesitation moments (makes it believable)\n- Emphasize relief/satisfaction at completion\n</pacing_notes>\n\n<fallback_plans>\n**If Technology Fails:**\n- Option 1: [Screenshot walkthrough prepared]\n- Option 2: [Video recording as backup]\n- Option 3: [Whiteboard sketch of key screens]\n\n**If Audience Derails:**\n- [Polite redirect]: \"Great question - let me finish showing [X], then circle back to that\"\n- [Mark for later]: Add to parking lot list visible on screen\n\n**If Demo Breaks Mid-Flow:**\n- [Recovery line]: \"Let me skip ahead to the outcome...\" [show completion state]\n- [Acknowledge]: \"That's actually helpful - shows why we need robust error handling\"\n</fallback_plans>\n</demo_delivery_guide>\n\n<audience_variations>\n<executive_version>\n**Duration:** 5 minutes\n**Focus:** Business outcomes, ROI, strategic fit\n**Script Adjustments:**\n- Start with the time/cost savings number\n- Skip interaction details, show before/after states\n- Emphasize competitive advantage and market differentiation\n- End with adoption plan and success metrics\n\n**Key Moments to Show:**\n1. Problem statement with financial impact\n2. Solution in action (fast-forward through steps)\n3. Outcome with measurable results\n</executive_version>\n\n<end_user_version>\n**Duration:** 15 minutes\n**Focus:** Complete workflow, all features, realistic use\n**Script Adjustments:**\n- Show every step with natural pacing\n- Include error recovery and edge cases\n- Demonstrate all key features, not just happy path\n- Allow time for questions throughout\n\n**Key Moments to Show:**\n[All moments from main script, plus:]\n- Secondary features in context\n- Settings and customization options\n- Help resources and tooltips\n</end_user_version>\n\n<technical_version>\n**Duration:** 10 minutes\n**Focus:** Integration points, data architecture, technical capabilities\n**Script Adjustments:**\n- Open with architecture overview\n- Show API endpoints or integration points during workflow\n- Highlight data transformation and validation\n- Demonstrate error handling and edge cases\n- End with scalability and security considerations\n\n**Key Moments to Show:**\n1. Data input and validation\n2. System processing (what happens under hood)\n3. Integration with other systems\n4. Performance under load\n</technical_version>\n\n<sales_version>\n**Duration:** 8 minutes\n**Focus:** Competitive advantages, objection handling, customer value\n**Script Adjustments:**\n- Start with customer's current pain\n- Emphasize differentiation vs. alternatives\n- Show ROI calculation in real-time\n- Address common objections proactively\n- End with implementation ease\n\n**Objection Handling Built In:**\n- \"Unlike [competitor], we handle [X] by...\"\n- \"Customers worried about [Y] appreciate how we...\"\n- \"This approach means you avoid [common pitfall]\"\n</sales_version>\n\n<stakeholder_review_version>\n**Duration:** 20 minutes\n**Focus:** Design rationale, research validation, decisions made\n**Script Adjustments:**\n- Include all contextual annotations visible\n- Reference specific user research findings\n- Show alternative approaches considered\n- Highlight open questions and areas for feedback\n- Discuss iteration plans\n\n**Key Moments to Show:**\n- Research insight → Design decision connection\n- A/B test results informing choices\n- Accessibility compliance\n- Technical constraint handling\n</stakeholder_review_version>\n</audience_variations>\n\n<branching_scenarios>\n**If Audience Asks \"What If User Wants to [Alternative Path]\":**\n[Describe the alternate route, which screens to show, how system adapts]\n\n**If Asked About Error States:**\n[Which error to demonstrate, what recovery looks like]\n\n**If Asked About Mobile Experience:**\n[How narrative changes on mobile device, what's different]\n\n**If Asked About First-Time vs. Returning User:**\n[How onboarding differs, what changes after initial use]\n</branching_scenarios>\n</demo_narrative>\n\n\n\nRemember: The best demo narratives feel like watching a real person solve a real problem. Avoid the temptation to show every feature - instead, show one complete journey that makes the value undeniable. Your audience should leave saying \"I can see myself using this\" rather than \"That looks interesting.\"\n</task_requirements>\n\nFORMAT\nReturn exactly this structure:\n\n<demo_effectiveness_checklist>\nBefore finalizing your demo narrative, verify:\n- [ ] Persona feels like a real person (not \"User A\" or generic archetype)\n- [ ] Scenario is specific and believable (not abstract or overly broad)\n- [ ] Stakes are clear (audience understands why this matters)\n- [ ] Timeline creates appropriate urgency (not manufactured drama)\n- [ ] Journey shows realistic pacing (allows time for thinking, not just clicking)\n- [ ] Errors/uncertainty included (demonstrates resilience, not just happy path)\n- [ ] Design decisions explained (audience learns the \"why\" behind the \"what\")\n- [ ] Outcome is measurable (time saved, quality improved, frustration reduced)\n- [ ] Emotional journey is authentic (frustration → clarity → confidence)\n- [ ] Technical feasibility confirmed (everything shown actually works in prototype)\n</demo_effectiveness_checklist>\n\nFAILURE\n- Output misses required sections, steps, or reasoning required by `<task_requirements>`.\n- Required format/schema is missing, malformed, or incomplete.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Stakeholder Management/Difficult Conversation Script (5-Step Framework).md",
      "title": "Difficult Conversation Script (5-Step Framework)",
      "category": "Stakeholder Management",
      "tags": [
        "coaching",
        "communication",
        "conflict-resolution",
        "stakeholder-management"
      ],
      "content": "INPUTS\n<provided_inputs>\n- [No explicit variables declared; use provided context.]\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Difficult Conversation Script (5-Step Framework).\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Produce a concise, one-page difficult-conversation prep doc from provided context.\n- Follow the sequence: Prepare -> Listen -> Empathize -> Clarify -> Solve.\n- Include preparation notes: intent, non-negotiables, facts/examples, language traps, desired outcome, success criteria, medium, and setting.\n- Provide 3-5 opening lines that are neutral, non-accusatory, impact-based, and perspective-inviting.\n- Provide 5-7 open questions (what/how/when), including one perspective-taking question and one constraints question; avoid \"why\" framing.\n- Include likely reactions with de-escalating responses, covering at least deny, deflect, emotional response, and counter-accuse.\n- Include close/next steps with shared goals, options/trade-offs, commitments, owner/timeline, and follow-up check-in.\n- Include a brief self-management checklist and escalation flags for HR/compliance.\n\nFORMAT\nReturn exactly this structure:\n\n1-Page Prep\n[Concise prep bullets]\n\nOpeners\n[3-5 opening line options]\n\nQuestions\n[5-7 open questions]\n\nReactions -> Responses\n| Reaction | What I'll say (de-escalating) |\n| --- | --- |\n| [Reaction] | [Response] |\n\nClose & Next Steps\n[Shared goals, options/trade-offs, commitments, owner/timeline, follow-up]\n\nSelf-Management Checklist\n- [Checklist item]\n\nEscalation Flags\n- [HR/compliance flag or \"None based on provided context\"]\n\nFAILURE\n- Any required section is missing or materially incomplete.\n- Openers are accusatory/generic or not grounded in context.\n- Questions violate constraints (too few/many, mostly \"why\", missing perspective-taking or constraints question).\n- Reactions table omits core cases (deny, deflect, emotional, counter-accuse) or lacks de-escalation responses.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Stakeholder Management/Exec feedback without context to actionable design requirements.md",
      "title": "Exec feedback without context to actionable design requirements",
      "category": "Stakeholder Management",
      "tags": [
        "ux-design",
        "executive-communication",
        "requirements",
        "feedback-interpretation",
        "stakeholder-management"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{EXEC_FEEDBACK}}\n- {{CURRENT_DESIGN_CONTEXT}}\n- {{PROJECT_BACKGROUND}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Exec feedback without context to actionable design requirements.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Decode `{{EXEC_FEEDBACK}}` into actionable design intent using `{{CURRENT_DESIGN_CONTEXT}}` and `{{PROJECT_BACKGROUND}}`.\n- Distinguish concern, desired outcome, feedback type, and whether it is a requirement vs preference.\n- Identify missing context required to execute.\n- Produce 2-3 concrete interpretations with \"done\" criteria, implications, effort, and likelihood.\n- Provide clarifying questions covering intent, priority, success, and data.\n- Propose interim next steps and a respectful communication plan aligned to executive intent.\n\nFORMAT\nReturn exactly this structure:\n\n<executive_feedback_structure>\n<feedback_decoding>\n<expressed_concern>\n[What problem or opportunity is the executive highlighting?]\n</expressed_concern>\n\n<desired_outcome>\n[What result is the executive hoping to achieve?]\n</desired_outcome>\n\n<feedback_type>\n[Classify as: Strategic direction, Quality concern, Risk mitigation, User impact, Personal preference, or Unclear]\n</feedback_type>\n\n<requirement_or_preference>\n[Assess whether this is:\n- Must-have requirement (blocks launch without it)\n- Important improvement (should address if feasible)\n- Nice-to-have suggestion (consider if time permits)\n- Personal preference (may or may not be valid concern)]\n</requirement_or_preference>\n</feedback_decoding>\n\n<missing_context>\n[List specific context needed to action the feedback:\n- What defines success for addressing this?\n- What are the constraints?\n- How urgent/important is this?\n- Who has final decision authority?\n- When does this need to be resolved?\n- What data would inform the decision?]\n</missing_context>\n\n<possible_interpretations>\n<interpretation_1>\n**What This Could Mean:**\n[Specific interpretation of the feedback]\n\n**If This Is The Intent, \"Done\" Looks Like:**\n[Concrete, testable criteria for addressing the feedback]\n\n**Design Implications:**\n[Specific design changes that would address this interpretation]\n\n**Effort Required:**\n[Time/complexity to implement]\n\n**Likelihood:**\n[High/Medium/Low based on context]\n</interpretation_1>\n\n<interpretation_2>\n**What This Could Mean:**\n[Alternative specific interpretation]\n\n**If This Is The Intent, \"Done\" Looks Like:**\n[Concrete, testable criteria]\n\n**Design Implications:**\n[Specific design changes]\n\n**Effort Required:**\n[Time/complexity]\n\n**Likelihood:**\n[High/Medium/Low]\n</interpretation_2>\n\n<interpretation_3>\n**What This Could Mean:**\n[Third possible interpretation, if applicable]\n\n**If This Is The Intent, \"Done\" Looks Like:**\n[Concrete, testable criteria]\n\n**Design Implications:**\n[Specific design changes]\n\n**Effort Required:**\n[Time/complexity]\n\n**Likelihood:**\n[High/Medium/Low]\n</interpretation_3>\n</possible_interpretations>\n\n<clarifying_questions>\n<intent_questions>\n[Questions to uncover what the executive really wants:\n- Example: \"When you mentioned X, were you concerned about Y or Z?\"]\n</intent_questions>\n\n<priority_questions>\n[Questions to establish importance:\n- Example: \"Is this a must-have for launch, or something we should address post-launch?\"]\n</priority_questions>\n\n<success_questions>\n[Questions to define acceptance criteria:\n- Example: \"What would you need to see to feel confident this concern is addressed?\"]\n</success_questions>\n\n<data_questions>\n[Questions to gather validation data:\n- Example: \"Would you like to see user research on this, or is this based on strategic direction?\"]\n</data_questions>\n</clarifying_questions>\n\n<interim_next_steps>\n[Propose actions that make progress while awaiting clarification:\n- Research options for addressing concern\n- Create low-fidelity explorations of different interpretations\n- Gather data that would inform the decision\n- Identify quick wins that address concern partially\n- Document implications of different approaches]\n</interim_next_steps>\n\n<communication_plan>\n**Recommended Approach for Follow-up:**\n[Describe how to engage the executive to get needed clarity:\n- When to reach out (immediately vs. wait for next check-in)\n- How to frame the conversation (focus on outcomes, show options)\n- What to prepare (mockups, data, tradeoff analysis)\n- Who else should be involved]\n\n**Draft Message:**\n[Provide a template message requesting clarification that:\n- Acknowledges the feedback\n- Shows you've thought about it\n- Presents interpretations\n- Requests specific input\n- Proposes next steps]\n</communication_plan>\n</executive_feedback_structure>\n\nFAILURE\n- Any required section in `<executive_feedback_structure>` is missing or materially incomplete.\n- Interpretations are generic, non-testable, or not grounded in provided context.\n- Clarifying questions fail to cover intent, priority, success, and data.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Stakeholder Management/Executive & Update Review.md",
      "title": "Executive & Update Review",
      "category": "Stakeholder Management",
      "tags": [
        "executive-communication",
        "leadership",
        "storytelling",
        "presentations",
        "stakeholder-management"
      ],
      "content": "INPUTS\n<provided_inputs>\n- [No explicit variables declared; use provided context.]\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Executive & Update Review.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Review a draft executive update/deck and optimize for clarity, brevity, and decision impact.\n- Rewrite `TL;DR` as exactly 3 bullets: what is wanted, why now, what changes.\n- Diagnose issues with explicit `Issue -> Fix` callouts (including vague/defensive/buried lead/over-detail/missing risk or ask).\n- Propose a clean narrative: Hook, Stakes, Options (with trade-offs), Recommendation, Ask (decision/resources/timeline).\n- Rewrite the core section in plain language (`<=200` words).\n- Provide 3-minute speaking notes with timing: opening (`15s`), body (`2m30s`), close (`15s`), including one story/data point, one risk, and one clear ask.\n- Recommend slide/page economy and a one-slide executive summary layout.\n- Replace hedging/passive voice with direct, credible phrasing aligned to business goals and next actions.\n\nFORMAT\nReturn exactly this structure:\n\nTL;DR (3 bullets)\n- [What I want]\n- [Why now]\n- [What changes]\n\nIssue -> Fix\n| Issue | Fix |\n| --- | --- |\n| [Issue] | [Fix] |\n\nNarrative Structure\nHook: [text]\nStakes: [text]\nOptions (with trade-offs): [text]\nRecommendation: [text]\nAsk (decision/resources/timeline): [text]\n\nCore Rewrite\n[<=200 words plain-language rewrite]\n\n3-Minute Speaking Notes\nOpening (15s): [text]\nBody (2m30s): [text including one story/data point and one risk]\nClose (15s): [text with one clear ask]\n\nSlide Economy & One-Slide Layout\nCuts/Merges: [what to remove or combine]\nOne-Slide Executive Summary Layout: [sections and ordering]\n\nFAILURE\n- Any required section is missing or materially incomplete.\n- `TL;DR` is not exactly 3 bullets or does not map to the required three intents.\n- Core rewrite exceeds 200 words or remains vague/defensive/passive.\n- Speaking notes miss required timing structure, risk, story/data point, or clear ask.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Stakeholder Management/Hidden Agenda Identification.md",
      "title": "Potential Hidden Agenda Identification",
      "category": "Stakeholder Management",
      "tags": [
        "stakeholders",
        "analysis",
        "organizational-politics",
        "negotiation",
        "stakeholder-management"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{SITUATION_DESCRIPTION}}\n- {{STAKEHOLDERS_LIST}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Potential Hidden Agenda Identification.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Analyze `{{SITUATION_DESCRIPTION}}` and `{{STAKEHOLDERS_LIST}}` to identify plausible hidden agendas per stakeholder.\n- For each stakeholder, assess official stance, personal/professional incentives, historical behavior (if provided), relationships, and outcome-based benefits/risks.\n- Use objective, evidence-based reasoning and reasonable inferences only; avoid unsupported speculation.\n- Consider multiple agenda possibilities where uncertainty exists.\n- Include a brief overall summary describing interactions/conflicts among stakeholder agendas.\n\nFORMAT\nReturn exactly this structure:\n\n<stakeholder_analysis>\n   <stakeholder_name>[Name of the stakeholder]</stakeholder_name>\n   <official_position>[Brief description of their official stance or role]</official_position>\n   <potential_hidden_agenda>[Your analysis of their possible hidden agenda]</potential_hidden_agenda>\n   <supporting_factors>[List key factors that support your analysis]</supporting_factors>\n</stakeholder_analysis>\n[Repeat `<stakeholder_analysis>` for each stakeholder in `{{STAKEHOLDERS_LIST}}`]\n\n<overall_summary>\n[Brief summary of how potential hidden agendas interact, align, or conflict across stakeholders]\n</overall_summary>\n\nFAILURE\n- Any stakeholder is missing a `<stakeholder_analysis>` block or required child tags.\n- `<overall_summary>` is missing or does not address interactions/conflicts between agendas.\n- Analysis is speculative, biased, or not grounded in provided information.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Stakeholder Management/Influence strategies from Cialdini's 7 principles.md",
      "title": "Influence strategies from Cialdini's 7 principles",
      "category": "Stakeholder Management",
      "tags": [
        "influence",
        "cialdini",
        "stakeholder-management"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{INFLUENCE_TARGET}}\n- {{INFLUENCE_GOAL}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Influence strategies from Cialdini's 7 principles.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Generate influence ideas tailored to `{{INFLUENCE_TARGET}}` and `{{INFLUENCE_GOAL}}`.\n- Provide at least one specific, actionable, ethical idea for each Cialdini principle:\n- Reciprocity\n- Liking\n- Unity\n- Authority\n- Social Proof\n- Consistency\n- Scarcity\n- For each idea, include a clear strategy and rationale tied to the target context and goal.\n- Use professional, non-manipulative tactics that create value for both sides.\n\nFORMAT\nReturn exactly this structure:\n\n<influence_ideas>\n<idea>\n<principle>Name of the principle</principle>\n<strategy>Detailed description of the strategy or tactic</strategy>\n<rationale>Explanation of why this idea would be effective for the given target and goal</rationale>\n</idea>\n(Repeat this structure for each of the seven principles)\n</influence_ideas>\n\nFAILURE\n- `<influence_ideas>` schema is missing, malformed, or materially incomplete.\n- Not all seven principles are covered, or principles are duplicated while another is missing.\n- Strategies are generic, unethical/manipulative, or not tied to the target and goal.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Stakeholder Management/Meeting Outcome Planning and Stakeholder Alignment.md",
      "title": "\"Meeting Outcome Planning and Stakeholder Alignment\"",
      "category": "\"Stakeholder Management\"",
      "tags": [
        "stakeholder-management",
        "executive-communication",
        "meeting-facilitation",
        "org-politics",
        "decision-making"
      ],
      "content": "INPUTS\n<provided_inputs>\n- [No explicit variables declared; use provided context.]\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: \"Meeting Outcome Planning and Stakeholder Alignment\".\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Timebox intake and planning for PM meeting prep (default 5-15 minutes, ask only essential questions unless enough context already exists).\n- Clarify outcome, decision need/decider, stakeholder map, risks/politics, constraints, and success criteria.\n- Produce a copy-ready meeting plan that includes:\n- TL;DR (`<=60` words).\n- Meeting Brief with objective, type mix percentages (Information/Discovery/Discussion/Decision/Alignment), decision statement/decider, stakeholder map, time-boxed agenda, key messages/proofs, objections/counters, give-get plan, artifacts, and exit checklist.\n- Follow-up Email template with objective recap, covered points, decisions, open items, notes/links, and next checkpoint.\n- Async alternative plan when a meeting is unnecessary (with steps, owners, deadlines).\n- Apply edge-case logic: missing decider, pure info-share closure, high conflict handling, explicit assumptions.\n- End with a 5-item read-aloud checklist: Goal, Decision/Decider, Stakeholders, Agenda times, Next steps.\n\nFORMAT\nReturn exactly this structure:\n\nTL;DR\n[<=60 words]\n\nMeeting Brief\nOne-sentence objective: [text]\nType mix: Information [x]%, Discovery [x]%, Discussion [x]%, Decision [x]%, Alignment [x]%\nDecision statement (if any): [text]. Decider: [name/role or None]\nStakeholder map:\n| Attendee | Interest | Influence (H/M/L) | Likely concerns | Pre-wire plan |\n| --- | --- | --- | --- | --- |\n| [row] | [row] | [row] | [row] | [row] |\nAgenda (time-boxed):\n- 0-2 min: [text]\n- [time]: [text]\n- Final 3-5 min: [decisions/owners/dates or closure rationale]\nKey messages & proofs:\n- [bullet]\nLikely objections & counters:\n- [objection -> counter]\nGive-get plan:\n- [offer vs ask]\nArtifacts:\n- [artifact, owner, send time]\nExit checklist:\n- [decision captured]\n- [DRI named]\n- [dates agreed]\n- [risks logged]\n- [follow-up owner]\n\nFollow-up Email\nSubject: [Outcome] - [Project/Topic], [Date]\nBody:\n- Objective recap: [text]\n- What we covered: [bullets]\n- Decisions: [decision / DRI / due date]\n- Open items: [owner / next step / due date]\n- Notes/Context: [links]\n- Thank you & next checkpoint: [text]\n\nIf Meeting Is Unnecessary (Async Plan)\n- [step, owner, deadline]\n\nAssumptions\n- [assumption or \"None\"]\n\nRead-Aloud Checklist\n1. Goal: [text]\n2. Decision/Decider: [text]\n3. Stakeholders: [text]\n4. Agenda times: [text]\n5. Next steps: [text]\n\nFAILURE\n- Any required section is missing or materially incomplete.\n- Type mix percentages are missing or not approximately 100%.\n- No decision/decider handling when decision is required, or no async plan when meeting is unnecessary.\n- Final 5-item read-aloud checklist is missing.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Stakeholder Management/Message Framing & Comms Plan Designer.md",
      "title": "Message Framing & Comms Plan Designer",
      "category": "Stakeholder Management",
      "tags": [
        "communication",
        "executive-communication",
        "messaging",
        "stakeholder-management"
      ],
      "content": "INPUTS\n<provided_inputs>\n- [No explicit variables declared; use provided context.]\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Message Framing & Comms Plan Designer.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Use provided facts, audience, goal, and writing sample to design a message framing and communication plan.\n- Provide 2-3 viable framing options, each with a one-line rationale tied to credibility, logic, and audience emotion.\n- Produce two concise drafts in the user's natural tone:\n- `ICs` draft with context, changes, actions, and timeline (`<=180` words).\n- `Execs` draft with BLUF, risks/asks, and decision needed (`<=120` words).\n- Include a strong subject/headline and two Slack snippets (announcement + reminder).\n- Provide a mini comms plan with channel sequence, owner, timing, emphasis, and CTA.\n- Include a `What to Omit` noise-reduction list and exactly 3 success signals.\n\nFORMAT\nReturn exactly this structure:\n\nFrames & Rationale\n- [Frame 1]: [one-line rationale]\n- [Frame 2]: [one-line rationale]\n- [Frame 3 if used]: [one-line rationale]\n\nDraft for ICs\nSubject/Headline: [text]\n[ICs draft <=180 words]\nSlack snippet (announcement): [text]\nSlack snippet (reminder): [text]\n\nDraft for Execs\nSubject/Headline: [text]\n[Execs draft <=120 words]\nSlack snippet (announcement): [text]\nSlack snippet (reminder): [text]\n\nMini Comms Plan\n| Step | Channel | Owner | Timing | Emphasis | CTA |\n| --- | --- | --- | --- | --- | --- |\n| [row] | [row] | [row] | [row] | [row] | [row] |\n\nWhat to Omit\n- [item]\n\nSuccess Signals\n1. [signal]\n2. [signal]\n3. [signal]\n\nFAILURE\n- Any required section is missing or materially incomplete.\n- ICs draft exceeds 180 words or Execs draft exceeds 120 words.\n- Missing subject/headline or missing either Slack snippet type (announcement/reminder).\n- Comms plan table is missing required columns or sequence logic.\n- Success Signals are not exactly three measurable indicators.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Stakeholder Management/Office politics with Machiavellian strategy.md",
      "title": "Office politics with Machiavellian strategy",
      "category": "Stakeholder Management",
      "tags": [
        "stakeholders",
        "office-politics",
        "power-dynamics",
        "influence"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{SCENARIO}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Office politics with Machiavellian strategy.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Analyze `{{SCENARIO}}` for key players, power dynamics, opportunities, and threats.\n- Use a Machiavellian / `48 Laws of Power` lens to identify relevant strategic principles.\n- Produce a specific, actionable strategy for navigating the scenario, balancing short-term moves with long-term consequences.\n- Include risks, likely outcomes, and contingency responses.\n- Ground all recommendations in the provided scenario and explicitly state assumptions when context is missing.\n\nFORMAT\nReturn exactly this structure:\n\n<analysis>\n[Brief analysis of scenario factors and power dynamics]\n</analysis>\n\n<strategy>\n[Recommended strategic approach with concrete actions and relevant principles]\n</strategy>\n\n<contingencies>\n[Potential risks/obstacles, likely outcomes, and contingency plans]\n</contingencies>\n\nFAILURE\n- Any required section (`<analysis>`, `<strategy>`, `<contingencies>`) is missing or materially incomplete.\n- Strategy is generic, not actionable, or not tied to scenario-specific power dynamics.\n- Contingencies do not address concrete risks and outcomes.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Stakeholder Management/PM context and design constraints.md",
      "title": "PM context and design constraints",
      "category": "Stakeholder Management",
      "tags": [
        "product-design",
        "requirements",
        "design-constraints",
        "stakeholder-management"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{PM_CONTEXT}}\n- {{USER_GOALS}}\n- {{SUCCESS_METRICS}}\n- {{BUSINESS_REQUIREMENTS}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: PM context and design constraints.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Translate `{{PM_CONTEXT}}`, `{{USER_GOALS}}`, `{{SUCCESS_METRICS}}`, and `{{BUSINESS_REQUIREMENTS}}` into actionable design constraints.\n- Extract explicit constraints across user, technical, business, timeline/resource, and scope dimensions.\n- Identify implicit constraints (platform conventions, existing patterns, performance, accessibility, brand/system, privacy/security).\n- Map success metrics to concrete design requirements and validation methods.\n- Define project design principles, non-negotiables, and acceptable tradeoffs.\n- Identify information gaps and produce prioritized clarifying questions.\n- Define validation criteria (must-have, should-have, success signals, red flags), methods, timeline, and next actions.\n\nFORMAT\nReturn exactly this structure:\n\n<design_constraints>\n<executive_summary>\n**Project:** [Name]\n\n**Core User Need:** [Primary problem we're solving for users]\n\n**Primary Success Metric:** [Top metric that defines success]\n\n**Key Design Constraints:**\n1. [Constraint 1 - e.g., \"Must launch by Nov 15 (hard deadline)\"]\n2. [Constraint 2 - e.g., \"Must work offline for mobile users\"]\n3. [Constraint 3 - e.g., \"Must meet WCAG 2.1 AA accessibility standards\"]\n\n**Biggest Unknowns:**\n1. [Information gap 1 - e.g., \"User segment not defined - designing for power users or beginners?\"]\n2. [Information gap 2 - e.g., \"Technical integration with CRM not spec'd - what data can we access?\"]\n\n**Recommended Next Actions:**\n1. [Action - e.g., \"Clarify target user segment with PM\"]\n2. [Action - e.g., \"Review technical integration specs with engineering\"]\n3. [Action - e.g., \"Conduct user research on current pain points\"]\n</executive_summary>\n\n<explicit_constraints>\n## User Needs\n\n**Primary User Goal:** [What users are trying to accomplish]\n\n**Specific User Needs:**\n1. [User need] - [Why this matters]\n   - Example: \"Complete tax filing in under 30 minutes\" - Users are time-constrained, will abandon if too complex\n2. [User need] - [Why this matters]\n3. [User need] - [Why this matters]\n\n**Jobs-to-be-Done:**\n- When [situation], I want to [motivation], so I can [expected outcome]\n- Example: \"When filing my taxes, I want to quickly import my W-2 data, so I can avoid manual data entry errors\"\n\n**User Context:**\n- **Technical proficiency:** [Beginner / Intermediate / Advanced]\n- **Device usage:** [Mobile-first / Desktop-primary / Mixed]\n- **Usage frequency:** [Daily / Weekly / Monthly / Annually]\n- **Context of use:** [On-the-go / At desk / High-stress / Time-constrained]\n\n**Design Implications:**\n- [How user needs translate to design requirements]\n- Example: \"Users are time-constrained → Design for speed (autofill, smart defaults, minimal steps)\"\n\n---\n\n## Technical Constraints\n\n**Platform Requirements:**\n- **Platforms:** [iOS, Android, Web, Desktop]\n- **OS/Browser Support:** [Specific versions - e.g., iOS 14+, Android 10+, Chrome/Firefox/Safari latest 2 versions]\n- **Screen sizes:** [Mobile (375-414px), Tablet (768-1024px), Desktop (1280px+)]\n\n**Performance Requirements:**\n- **Page load time:** [Target - e.g., <3 seconds on 4G]\n- **Interaction responsiveness:** [Target - e.g., <100ms for button taps]\n- **Animation performance:** [Target - e.g., 60fps]\n- **Offline support:** [Required / Not required - if required, what functionality must work offline?]\n\n**Integration Requirements:**\n- **Systems to integrate with:** [CRM, Payment gateway, Analytics, etc.]\n- **APIs available:** [What APIs can we use? What data can we access?]\n- **Authentication:** [OAuth, SAML, API keys - what's supported?]\n\n**Data Constraints:**\n- **Data availability:** [What data is available in real-time vs. cached?]\n- **Data format:** [JSON, XML, etc.]\n- **Data limitations:** [Rate limits, data freshness, completeness]\n\n**Design Implications:**\n- [How technical constraints affect design]\n- Example: \"Offline support required → Design for sync states (loading, synced, sync failed), indicate what works offline\"\n\n---\n\n## Business Requirements\n\n**Regulatory Compliance:**\n- [Regulation] - [Specific requirements]\n  - Example: \"GDPR - Must collect explicit consent for data processing, provide data export/deletion\"\n  - Example: \"WCAG 2.1 AA - Must meet accessibility standards (color contrast, keyboard navigation, screen reader support)\"\n\n**Business Logic:**\n- [Business rule] - [How it affects design]\n  - Example: \"Free trial users can access features A, B, C but not D, E - Must clearly indicate locked features\"\n  - Example: \"Approval workflow requires manager sign-off for purchases >$1000 - Design approval flow with notifications\"\n\n**Monetization Requirements:**\n- [Requirement] - [Design implications]\n  - Example: \"Freemium model with paywall after 3 exports - Design paywall that clearly communicates value of upgrade\"\n  - Example: \"Ads on free tier - Design ad placements that don't disrupt core user flow\"\n\n**Operational Constraints:**\n- [Constraint] - [Design implications]\n  - Example: \"Support only available Mon-Fri 9-5 EST - Design self-service help prominently for off-hours\"\n  - Example: \"Manual approval process takes 24-48 hours - Design expectation-setting messaging\"\n\n**Design Implications:**\n- [How business requirements affect design]\n\n---\n\n## Resource Constraints\n\n**Timeline:**\n- **Launch Date:** [Date - is this hard deadline or flexible?]\n- **Why this date:** [Business reason - seasonal, competitive, contractual commitment]\n- **Design timeline:** [How much time for design phase - research, ideation, validation]\n- **What happens if we miss deadline:** [Opportunity cost, business impact]\n\n**Team & Budget:**\n- **Design team:** [X designers, skill sets]\n- **Engineering team:** [X engineers, X sprints available]\n- **Budget:** [Design/dev hours, research budget, tooling budget]\n- **Dependencies:** [What are we waiting on? Other teams, external vendors?]\n\n**Design Implications:**\n- [How timeline/resources affect scope]\n- Example: \"6 weeks to design + 4 weeks to build → Focus on MVP, defer nice-to-haves to v2\"\n\n---\n\n## Scope Requirements\n\n**Must-Have (MVP Features):**\n- [Feature] - [Why it's must-have]\n  - Example: \"Credit card payment support - Cannot launch e-commerce without ability to collect payment\"\n\n**Should-Have (Important but not blocking):**\n- [Feature] - [Why it's important]\n  - Example: \"Saved payment methods - Improves returning user experience, but first-time users can still checkout\"\n\n**Could-Have (Nice-to-have if time allows):**\n- [Feature] - [Why it's nice-to-have]\n  - Example: \"Gift wrapping option - Adds value but low usage expected\"\n\n**Won't-Have (Explicitly out of scope):**\n- [Feature] - [Why we're not doing it]\n  - Example: \"Cryptocurrency payments - Too few users, high implementation complexity, defer to v2\"\n\n**Design Implications:**\n- [How scope affects design priorities]\n- Example: \"MVP focused → Design core flow excellently, cut secondary features\"\n\n</explicit_constraints>\n\n<implicit_constraints>\n## Platform Conventions\n\n[List platform-specific conventions that should be followed even if not explicitly stated]\n\n**iOS:**\n- Navigation bar at top, tab bar at bottom\n- System fonts (San Francisco) and standard UI components\n- Standard gestures (swipe back, pull to refresh)\n- Haptic feedback for key interactions\n\n**Android:**\n- Material Design principles (FAB, bottom sheets)\n- System back button behavior\n- Material motion and elevation system\n\n**Web:**\n- Underlined links or clear visual distinction\n- Breadcrumbs for deep hierarchy\n- Search in header (typically top-right)\n- Responsive design (mobile-first approach)\n\n**Design Implication:** \"Follow platform conventions to meet user expectations, don't reinvent standard patterns\"\n\n---\n\n## Existing Patterns Users Expect\n\n**Product-Specific Patterns:**\n- [Pattern already established in our product]\n- Example: \"We always use bottom sheet for secondary actions - maintain consistency\"\n\n**Industry Conventions:**\n- [Pattern users know from competitor products]\n- Example: \"E-commerce checkout follows: Cart → Shipping → Payment → Review → Confirmation\"\n\n**Design Implication:** \"Leverage existing mental models, don't make users learn new patterns unnecessarily\"\n\n---\n\n## Performance Expectations (Unstated)\n\n- **Page load:** Users expect <3 seconds, abandon after 5 seconds\n- **Interaction responsiveness:** Buttons/links respond <100ms (feels instant)\n- **Animation:** 60fps for smooth motion (30fps feels janky)\n- **Search results:** Return results <1 second (ideally instant)\n\n**Design Implication:** \"Design with performance in mind - minimize heavy assets, use lazy loading, show loading states\"\n\n---\n\n## Accessibility Requirements (Often Assumed)\n\n- **WCAG 2.1 AA minimum** (legal requirement in many jurisdictions)\n- **Keyboard navigation:** All interactive elements keyboard accessible (tab order logical)\n- **Screen reader support:** Semantic HTML, ARIA labels, alt text for images\n- **Color contrast:** Text has 4.5:1 contrast ratio (large text 3:1)\n- **Focus indicators:** Visible focus states for keyboard navigation\n- **Touch targets:** Minimum 44x44px (iOS) / 48x48px (Android)\n\n**Design Implication:** \"Accessibility is non-negotiable - bake it in from the start, not an afterthought\"\n\n---\n\n## Brand & Design System Constraints\n\n- **Brand colors:** [Hex codes for primary, secondary, accent colors]\n- **Typography:** [Font families, sizes, weights]\n- **Voice & tone:** [Brand voice - professional, friendly, playful, etc.]\n- **Design system components:** [Must use existing components, don't reinvent]\n- **Design principles:** [Product design principles to follow]\n\n**Design Implication:** \"Stay within brand guidelines and design system, maintain consistency across product\"\n\n---\n\n## Data Privacy & Security (Unstated Expectations)\n\n- **Sensitive data:** Don't display in plain text (mask credit cards, SSNs, passwords)\n- **Authentication:** Require login for personal data access\n- **Session timeout:** Auto-logout after inactivity (typically 15-30 min)\n- **Audit logging:** Track sensitive actions (for security and compliance)\n\n**Design Implication:** \"Design for security by default - mask sensitive data, require authentication, set expectations around timeouts\"\n\n</implicit_constraints>\n\n<metric_driven_requirements>\nFor each success metric, translate into design requirements:\n\n## Metric #1: [e.g., \"Increase conversion rate by 10%\"]\n\n**Current Baseline:** [X]% conversion rate\n\n**Target:** [Y]% conversion rate (10% relative increase)\n\n**UX Outcomes Needed:**\n- Reduce friction: Fewer steps, clearer CTAs, smart defaults\n- Increase trust: Social proof, security badges, clear value proposition\n- Improve clarity: Better copywriting, visual hierarchy, reduced cognitive load\n\n**User Behaviors to Enable:**\n- Users must understand value proposition within 5 seconds\n- Users must complete key actions with minimal effort (ideally <3 clicks)\n- Users must feel confident proceeding (reduce anxiety, increase trust)\n\n**Friction to Remove:**\n- Current friction: 12-field checkout form (reduce to 6 fields)\n- Current friction: Unclear CTAs (test 3 CTA variants for clarity)\n- Current friction: No trust signals (add security badges, testimonials)\n\n**Design Requirements:**\n1. Reduce checkout form from 12 to 6 fields (use smart defaults for the rest)\n2. Test 3 CTA variants: \"Buy Now\", \"Complete Purchase\", \"Checkout Securely\"\n3. Add trust badges above payment section (SSL, money-back guarantee, testimonials)\n4. Improve visual hierarchy: Make CTA most prominent element on page (size, color, placement)\n\n**Validation:**\n- Usability testing: 90%+ of users complete checkout without confusion\n- A/B test: New design increases conversion by 5-10%\n\n---\n\n## Metric #2: [e.g., \"Increase feature adoption by 25%\"]\n\n**Current Baseline:** [X]% adoption\n\n**Target:** [Y]% adoption (25% relative increase)\n\n**UX Outcomes Needed:**\n- Improve feature discoverability\n- Clarify value proposition\n- Support successful first-time use\n\n**User Behaviors to Enable:**\n- Users must notice the feature in normal workflows\n- Users must understand why they should use it\n- Users must succeed on first attempt\n\n**Friction to Remove:**\n- Hidden or buried entry points\n- Jargon-heavy or vague copy\n- Complex multi-step setup without guidance\n\n**Design Requirements:**\n1. Place feature entry point in primary navigation or key flow\n2. Add contextual tooltip or nudge explaining value the first time it appears\n3. Design a guided first-use flow or lightweight wizard\n4. Provide clear success feedback and next-step suggestions\n\n**Validation:**\n- Usage analytics: Increase in first-time and repeat use\n- Usability testing: Majority of users discover and use feature unaided\n\n---\n\n[Continue for all success metrics]\n\n</metric_driven_requirements>\n\n<design_principles>\n## Project-Specific Design Principles\n\nThese principles guide tradeoff decisions for this project:\n\n### 1. [Principle Name]: [Principle Statement]\n\n**What This Means:**\n[Explain the principle in plain language]\n\n**Tradeoff Guidance:**\nWhen we must choose between [X] and [Y], we prioritize [X] because [reason]\n\n**Example:**\n[Concrete example of how this principle guides a design decision]\n\n**Example Principle: Speed Over Polish**\n- **Statement:** \"Ship functional, usable designs quickly. Refine aesthetics in v2.\"\n- **What This Means:** Prioritize getting core functionality in users' hands over pixel-perfect visual design. Design must be usable and brand-consistent, but doesn't need to be visually stunning in v1.\n- **Tradeoff:** When choosing between \"thorough visual design exploration\" vs. \"get prototype to users fast\", choose speed.\n- **Example:** \"For v1, use standard design system components and straightforward layouts. Save custom illustrations and micro-interactions for v2.\"\n\n---\n\n### 2. [Principle]: [Statement]\n\n**What This Means:**\n[Explain the principle]\n\n**Tradeoff Guidance:**\n[Which side wins in conflicts]\n\n**Example:**\n[Concrete application]\n\n---\n\n[Continue for 5-7 principles total]\n\n## Non-Negotiable Qualities\n\nThese qualities cannot be compromised:\n\n1. **[Quality - e.g., Accessibility Compliance]**\n   - We will always meet WCAG 2.1 AA, even if it means additional design/dev time\n   - Why: Legal requirement, user trust, inclusive design is a core value\n\n2. **[Quality - e.g., Data Security]**\n   - We will always prioritize user data security, even if it adds friction\n   - Why: User trust is foundational, security breaches are existential risk\n\n3. **[Quality - e.g., Performance]**\n   - We will always ship designs that load <3 seconds, even if it means reducing features\n   - Why: Users abandon after 5 seconds, performance is part of UX quality\n\n## What Can Be Compromised (If Necessary)\n\nThese are important but can be adjusted for higher priorities:\n\n1. **Visual Polish:** Can be improved in v2 if timeline is constrained. Core functionality and usability cannot be compromised, but aesthetic refinement can wait.\n\n2. **Edge Case Support:** Can defer rare edge cases to v2 if they significantly increase complexity. Support 80% of users excellently, handle 20% adequately.\n\n3. **Feature Breadth:** Can launch with fewer features if it means shipping sooner. Better to do 3 things excellently than 10 things poorly.\n\n</design_principles>\n\n<information_gaps>\n## Missing User Context\n\n**Gap:** [What's unclear about users]\n\n**Why This Matters:** [How this affects design decisions]\n\n**Example:** \"PM says 'design for mobile users' but doesn't specify: Are these existing users (familiar with product) or new users (need onboarding)? Are they using on-the-go (need quick access) or at desk (can handle complexity)?\"\n\n**Impact on Design:** Can't design appropriate level of guidance/onboarding without knowing user proficiency\n\n**Clarifying Question:** \"Which user segment are we designing for: power users who know the product, or first-time users who need guidance? What's their context of use: on-the-go or at desk?\"\n\n---\n\n[Continue for all user context gaps]\n\n## Unclear Success Criteria\n\n**Gap:** [What's vague about success metrics]\n\n**Why This Matters:** [Can't validate designs without clear metrics]\n\n**Example:** \"PM says 'improve user engagement' but doesn't define engagement. Does this mean DAU (daily active users), session length, actions per session, or feature usage?\"\n\n**Impact on Design:** Can't make informed tradeoff decisions without knowing what we're optimizing for\n\n**Clarifying Question:** \"How are we defining user engagement? What's the baseline and target? How will we measure it?\"\n\n---\n\n[Continue for all success criteria gaps]\n\n## Undefined Constraints\n\n**Gap:** [What technical/business constraints are missing]\n\n**Why This Matters:** [Can't design feasible solutions without constraints]\n\n**Example:** \"PM says 'integrate with CRM' but doesn't specify which CRM system, what APIs are available, or what data we can access\"\n\n**Impact on Design:** Can't design data displays or workflows without knowing what data is available\n\n**Clarifying Question:** \"Which CRM system are we integrating with? What APIs are available? What user data can we access? Are there rate limits or data freshness issues?\"\n\n---\n\n[Continue for all undefined constraints]\n\n## Ambiguous Requirements\n\n**Gap:** [High-level or vague requirement]\n\n**Why This Matters:** [Risk of designing wrong thing]\n\n**Example:** \"Support multiple payment methods\" without details\n\n**Clarifying Question:** \"Which specific payment methods must we support in v1, and which can be deferred?\"\n\n---\n\n## Clarifying Questions for PM\n\nPrioritized list of questions that need answers before design can proceed effectively:\n\n### Critical (Must answer before starting design):\n1. [Question that blocks design work]\n2. [Question that blocks design work]\n\n### High Priority (Should answer in first week):\n1. [Question that affects design direction]\n2. [Question that affects design direction]\n\n### Medium Priority (Good to know, but can proceed without):\n1. [Question that would inform design but not block it]\n\n</information_gaps>\n\n<validation_criteria>\n## Must-Have (Non-Negotiable)\n\nDesigns MUST satisfy these requirements or they're not acceptable:\n\n- [ ] **[Requirement]** - [How to validate]\n  - Example: \"Must complete checkout in 6 steps or fewer\" - Validate by counting steps in user flow\n- [ ] **[Requirement]** - [How to validate]\n  - Example: \"Must meet WCAG 2.1 AA contrast requirements\" - Validate with color contrast checker\n- [ ] **[Requirement]** - [How to validate]\n  - Example: \"Must render correctly on iOS 14+ and Android 10+\" - Validate with device testing\n\n**Validation Method:** Checklist review before handoff to engineering\n\n---\n\n## Should-Have (Important but Adjustable)\n\nDesigns should satisfy these if possible, but tradeoffs acceptable:\n\n- [ ] **[Requirement]** - [How to validate]\n  - Example: \"Should support autofill for all form fields\" - Validate in browser testing\n- [ ] **[Requirement]** - [How to validate]\n  - Example: \"Should include contextual help for complex interactions\" - Validate in usability testing\n\n**Validation Method:** Design critique, adjust if blockers arise\n\n---\n\n## Success Signals (Design is On Track)\n\nEarly indicators that design is heading in the right direction:\n\n- ✅ **[Signal]** - [When to check]\n  - Example: \"Stakeholders easily understand user flow in walkthrough\" - Check in design review\n- ✅ **[Signal]** - [When to check]\n  - Example: \"Usability testing shows 90%+ task completion\" - Check in usability testing\n- ✅ **[Signal]** - [When to check]\n  - Example: \"Engineering confirms designs are feasible\" - Check in technical review\n\n---\n\n## Red Flags (Design is Off Track)\n\nWarning signs that design is not meeting goals:\n\n- 🚩 **[Red flag]** - [What to do]\n  - Example: \"Stakeholders confused about how feature works\" - Stop, clarify requirements, iterate\n- 🚩 **[Red flag]** - [What to do]\n  - Example: \"Usability testing shows <70% task completion\" - Identify friction points, redesign\n- 🚩 **[Red flag]** - [What to do]\n  - Example: \"Engineering flags designs as technically infeasible\" - Adjust design to meet constraints\n- 🚩 **[Red flag]** - [What to do]\n  - Example: \"Designs violate accessibility standards\" - Fix immediately, non-negotiable\n\n---\n\n## Validation Methods & Timeline\n\n**Design Review with Stakeholders:**\n- **When:** Week 1 (after initial concepts)\n- **Purpose:** Align on direction, gather feedback, ensure we're solving the right problem\n- **Success Criteria:** Stakeholders agree on direction, no major misalignment\n\n**Usability Testing:**\n- **When:** Week 2 (after refined prototype)\n- **Purpose:** Validate designs with real users, measure task completion and satisfaction\n- **Success Criteria:** 90%+ task completion, 4+/5 satisfaction rating, no critical usability issues\n\n**Technical Feasibility Review:**\n- **When:** Week 3 (before finalizing designs)\n- **Purpose:** Confirm engineering can build this within timeline and constraints\n- **Success Criteria:** Engineering confirms feasibility, no major technical blockers\n\n**Accessibility Audit:**\n- **When:** Week 4 (before handoff)\n- **Purpose:** Ensure designs meet WCAG 2.1 AA standards\n- **Success Criteria:** All accessibility requirements met, no violations\n\n**Post-Launch Analytics:**\n- **When:** 2 weeks, 1 month, 3 months after launch\n- **Purpose:** Measure success metrics, identify areas for improvement\n- **Success Criteria:** Success metrics trending toward targets\n\n</validation_criteria>\n\n<next_actions>\n## Immediate Next Steps\n\nBased on this analysis, here's what needs to happen before design can proceed effectively:\n\n### 1. Clarify with PM (Priority: Critical)\n**Action:** Schedule 30-min meeting with PM to clarify:\n- [Question 1]\n- [Question 2]\n- [Question 3]\n\n**Owner:** [Designer name]\n**Timeline:** By [date]\n**Blocker:** Cannot start design without this information\n\n### 2. Gather User Context (Priority: High)\n**Action:** Review existing user research or conduct [research method]\n- [Specific research need]\n\n**Owner:** [UX Researcher or Designer]\n**Timeline:** By [date]\n**Impact:** Informs user-centered design decisions\n\n### 3. Technical Validation (Priority: High)\n**Action:** Meet with engineering to clarify:\n- [Technical constraint or integration question]\n\n**Owner:** [Designer + Engineering Lead]\n**Timeline:** By [date]\n**Impact:** Ensures designs are technically feasible\n\n### 4. Begin Design Exploration (Priority: High)\n**Action:** Start with [specific design task]\n- Focus on [core user flow or interaction]\n- Create [low-fi sketches / wireframes / prototype]\n\n**Owner:** [Designer name]\n**Timeline:** By [date]\n**Deliverable:** [Prototype for usability testing / Concepts for design review]\n\n### 5. Schedule Validation Sessions (Priority: Medium)\n**Action:** Schedule:\n- Design review with stakeholders: [date]\n- Usability testing sessions: [dates]\n- Technical review with engineering: [date]\n\n**Owner:** [Designer or PM]\n**Timeline:** Schedule by [date], sessions occur in weeks 1-4\n\n</next_actions>\n</design_constraints>\n\nFAILURE\n- Any required section in `<design_constraints>` is missing or materially incomplete.\n- Constraints are generic and not traceable to provided PM context/goals/metrics/requirements.\n- Metrics are not translated into testable design requirements and validation criteria.\n- Information gaps lack actionable clarifying questions.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Stakeholder Management/Power dynamics mapping before meetings.md",
      "title": "\"Map power dynamics before meetings\"",
      "category": "\"Stakeholder Management\"",
      "tags": [
        "stakeholders",
        "power-dynamics",
        "meetings",
        "communication"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{MEETING_DETAILS}}\n- {{ATTENDEES_INFO}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: \"Map power dynamics before meetings\".\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Analyze `{{MEETING_DETAILS}}` and `{{ATTENDEES_INFO}}` to map meeting-specific power dynamics.\n- Identify formal hierarchy, informal influence signals, alliances/conflicts, and each attendee's stake in outcomes.\n- Rank attendees by influence in this meeting context.\n- Identify decision-makers, influencers, power imbalances, and likely conflict points.\n- Provide actionable strategies to navigate dynamics during the meeting.\n- If information is insufficient for any claim, explicitly state the uncertainty.\n\nFORMAT\nReturn exactly this structure:\n\n<power_dynamics_analysis>\n<power_map>\n[List attendees in order of influence, with brief notes on their power sources]\n</power_map>\n\n<key_observations>\n[Bullet points of important observations about the power dynamics]\n</key_observations>\n\n<strategic_recommendations>\n[Bullet points of strategies to navigate the power dynamics effectively]\n</strategic_recommendations>\n</power_dynamics_analysis>\n\nFAILURE\n- Any required section in `<power_dynamics_analysis>` is missing or materially incomplete.\n- Influence ranking is not meeting-contextual or lacks power-source rationale.\n- Recommendations are generic or not tied to identified dynamics/conflicts.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Stakeholder Management/Product requirements from structured analysis.md",
      "title": "Product requirements from structured analysis",
      "category": "Stakeholder Management",
      "tags": [
        "product-requirements",
        "product-strategy",
        "collaboration",
        "systems-thinking"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{PRODUCT_REQUIREMENTS}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Product requirements from structured analysis.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Analyze `{{PRODUCT_REQUIREMENTS}}` with a constructive, optimistic lens while surfacing concrete risks.\n- Identify positive aspects and benefits of the current requirements.\n- Identify concerns in:\n- Team collaboration and ownership handoffs.\n- Conflicting or clashing requirements.\n- Maintainability/updateability across sections/pages.\n- Strategic flexibility risks over time.\n- Provide actionable suggestions emphasizing simplicity, systems thinking, quality, collaboration, conflict resolution, maintainability, and future flexibility.\n\nFORMAT\nReturn exactly this structure:\n\n<response>  \n<positive_aspects>  \nList the good sides and potential benefits of the requirements here.  \n</positive_aspects>  \n\n<areas_of_concern>  \nDescribe any issues related to team collaboration, conflicting requirements, maintainability, or strategic limitations here.  \n</areas_of_concern>  \n\n<suggestions>  \nProvide your proposals for improvements, focusing on simplicity, systems thinking, and quality. Address any concerns raised in the previous section.  \n</suggestions>  \n\n<conclusion>  \nSummarize your overall impression and the key points to consider moving forward.  \n</conclusion>  \n</response>\n\nFAILURE\n- Any required section in `<response>` is missing or materially incomplete.\n- Concerns do not explicitly address collaboration, conflicts, maintainability, and strategic flexibility.\n- Suggestions are generic, non-actionable, or not linked to identified concerns.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Stakeholder Management/Remote Miro workshops from transcripts and specs.md",
      "title": "Remote Miro workshops from transcripts and specs",
      "category": "Stakeholder Management",
      "tags": [
        "workshops",
        "miro",
        "facilitation",
        "remote"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{TRANSCRIPT}}\n- {{TIME_LIMIT}}\n- {{GOAL}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Remote Miro workshops from transcripts and specs.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Build a focused remote Miro workshop plan from `{{TRANSCRIPT}}` to achieve `{{GOAL}}` within `{{TIME_LIMIT}}` minutes.\n- Create a sequenced agenda of 3-6 activities with dependencies where each activity output feeds the next.\n- Include a global timeline that sums exactly to `{{TIME_LIMIT}}` (including intro, any break time, and wrap-up).\n- Start with transcript analysis (themes, decisions/questions, constraints/risks, assumptions).\n- For each activity include objective, duration, format, participant instructions, facilitator notes with concrete Miro steps, materials/tools, and output artifact.\n- Include bias-mitigation and accessibility practices, plus contingency handling for +/-10% time slip.\n- End with wrap-up handoff (decision log, owners, deadlines, artifacts, comms plan) and an alternative action if full goal is not achieved.\n- If the goal is unrealistic for the time limit, state why and propose a right-sized goal or revised duration.\n\nFORMAT\nReturn exactly this structure:\n\n### Transcript Analysis\n- **Key themes:** [text]\n- **Decisions/questions to answer:** [text]\n- **Constraints & risks:** [text]\n- **Assumptions (if any):** [text]\n\n### Global Timeline (sums to `{{TIME_LIMIT}}`)\n- 00:00-00:XX [step] — **XX min**\n- [additional timed steps]\n- [final step ending at `{{TIME_LIMIT}}`] — **ZZ min**\n- **Total: `{{TIME_LIMIT}}` minutes**\n\n### Pre-Read (send 24-48h before)\n- [item]\n\n### Activities\n#### Activity 1: *[Name]*\n- **Objective:** [text]\n- **Duration:** [x] minutes\n- **Format:** [text]\n- **Participant instructions:** [text]\n- **Facilitator notes (with Miro steps):**\n  - Board: [frame/template/lock-unlock actions]\n  - Breakouts: [pod setup + return protocol]\n  - Timer: [minutes + buffer]\n  - Voting: [votes/person + criteria + rounds]\n  - Capture: [tags/colors/export method]\n- **Materials & tools:** [text]\n- **Output artifact:** [text]\n\n[Repeat for each activity, total 3-6]\n\n### Wrap-Up & Decision Handoff\n- **Decision log:** [text]\n- **Owners & deadlines:** [text]\n- **Artifacts:** [text]\n- **Communication plan:** [text]\n\n### Alternative Action (if goal not achieved)\n- **Why not:** [text]\n- **Fallback:** [right-sized option or Part 2 with exact minutes]\n- **Prereqs for next session:** [text]\n\nFAILURE\n- Any required section is missing or materially incomplete.\n- Timeline durations do not sum exactly to `{{TIME_LIMIT}}`.\n- Agenda has fewer than 3 or more than 6 activities.\n- Activities do not specify actionable Miro runbook steps or output dependencies.\n- Missing bias/accessibility practices, contingencies, or alternative action path.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Stakeholder Management/Stakeholder Brief Clarification and Problem Definition.md",
      "title": "Stakeholder Brief Clarification and Problem Definition",
      "category": "Stakeholder Management",
      "tags": [
        "product-design",
        "problem-framing",
        "stakeholder-management",
        "user-research",
        "metrics"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{VAGUE_BRIEF}}\n- {{STAKEHOLDER_CONTEXT}}\n- {{BUSINESS_CONSTRAINTS}}\n- {{USER_RESEARCH}}\n- {{CURRENT_METRICS}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Stakeholder Brief Clarification and Problem Definition.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Transform `{{VAGUE_BRIEF}}` into a concrete, measurable problem definition using `{{STAKEHOLDER_CONTEXT}}`, `{{BUSINESS_CONSTRAINTS}}`, `{{USER_RESEARCH}}`, and `{{CURRENT_METRICS}}`.\n- Decode subjective language, assumptions, implied intent, symptom vs root cause, and solution bias.\n- Extract business drivers, user problems, and concrete success criteria.\n- Translate vague terms into observable/measurable design criteria.\n- Identify technical, timeline, budget, brand/design, and organizational constraints.\n- Generate validation-oriented clarifying questions and actionable next steps.\n- Keep analysis objective, evidence-based, and explicit about assumptions and unknowns.\n\nFORMAT\nReturn exactly this structure:\n\n<problem_statement_analysis>\n<vague_language_decoded>\n**Subjective Terms Identified:**\n[List each vague term with its contextual meaning]\n\n**Embedded Assumptions:**\n- [Assumption 1]\n- [Assumption 2]\n- [Assumption 3]\n\n**Implied But Not Stated:**\n[What the stakeholder assumes you know or will infer]\n\n**Root Cause vs. Symptom:**\n- Stated symptom: [what stakeholder described]\n- Likely root cause: [underlying issue driving the symptom]\n</vague_language_decoded>\n\n<underlying_business_needs>\n**Primary Business Driver:**\n[The core business outcome this request aims to achieve]\n\n**Revenue/Growth Connection:**\n[How this impacts company financial goals]\n\n**Strategic Alignment:**\n[How this connects to broader company strategy or roadmap]\n\n**Competitive Context:**\n[Market forces or competitor actions driving this]\n\n**Internal Stakeholder Pressures:**\n[Political, reputational, or organizational dynamics]\n\n**Cost of Inaction:**\n[What happens if this problem isn't solved]\n</underlying_business_needs>\n\n<user_problems_identified>\n**Affected User Segments:**\n- [Segment 1]: [specific pain points]\n- [Segment 2]: [specific pain points]\n- [Segment 3]: [specific pain points]\n\n**User-Reported Pain Points:**\n[Direct quotes or themes from user research, support tickets, reviews]\n\n**Behavioral Evidence:**\n[Observable user behaviors that indicate this problem exists]\n\n**Current Workarounds:**\n[How users compensate for this problem today]\n\n**Impact on User Journeys:**\n[Specific tasks or flows where users experience friction]\n\n**Severity Assessment:**\n- Frequency: [how often users encounter this]\n- Impact: [how much it affects user success]\n- User priority: [how users would rank fixing this]\n</user_problems_identified>\n\n<concrete_criteria>\n**Translation of \"[VAGUE_TERM_1]\":**\n- Criterion 1: [specific, measurable attribute]\n- Criterion 2: [specific, measurable attribute]\n- Criterion 3: [specific, measurable attribute]\n\n**Translation of \"[VAGUE_TERM_2]\":**\n- Criterion 1: [specific, measurable attribute]\n- Criterion 2: [specific, measurable attribute]\n- Criterion 3: [specific, measurable attribute]\n\n**Observable Design Characteristics:**\n[Specific visual, interaction, or structural attributes that would demonstrate the vague term has been achieved]\n\n**User-Facing Improvements:**\n[Concrete changes users would notice and value]\n</concrete_criteria>\n\n<success_metrics>\n**Primary Success Metric:**\n- Metric: [specific measurement]\n- Current baseline: [X]\n- Target: [Y]\n- Timeline: [when to measure]\n- Collection method: [how to measure]\n\n**Secondary Metrics:**\n1. [Metric]: [baseline] → [target] by [date]\n2. [Metric]: [baseline] → [target] by [date]\n3. [Metric]: [baseline] → [target] by [date]\n\n**Leading Indicators:**\n- [Early signal 1]\n- [Early signal 2]\n- [Early signal 3]\n\n**Qualitative Success Signals:**\n- [User feedback theme or sentiment shift]\n- [Stakeholder observation or report]\n- [Support ticket reduction in specific category]\n\n**Risks to Monitor:**\n[Potential negative metrics that could indicate unintended consequences]\n</success_metrics>\n\n<constraint_analysis>\n<technical_constraints>\n- [Constraint 1 with impact on design options]\n- [Constraint 2 with impact on design options]\n- [Constraint 3 with impact on design options]\n</technical_constraints>\n\n<timeline_constraints>\n- Hard deadline: [date and reason]\n- Resource availability: [when team is available]\n- Dependencies: [what must happen first]\n</timeline_constraints>\n\n<budget_constraints>\n- Development capacity: [hours or sprints available]\n- Research budget: [ability to validate with users]\n- Third-party costs: [tools or services needed]\n</budget_constraints>\n\n<brand_design_constraints>\n- Design system: [existing components and patterns to leverage]\n- Accessibility: [WCAG level required, existing debt]\n- Brand guidelines: [visual identity rules that apply]\n</brand_design_constraints>\n\n<organizational_constraints>\n- Approval process: [who must sign off, when]\n- Cross-team dependencies: [coordination needed]\n- Political considerations: [stakeholder dynamics]\n</organizational_constraints>\n</constraint_analysis>\n\n<refined_problem_statement>\n**Problem Statement:**\nWe need to [specific design action] for [specific user segment] so that [specific user outcome] and [specific business outcome], as measured by [primary metric] improving from [baseline] to [target] by [date], while considering [key constraints].\n\n**In Plain Language:**\n[Restate the problem statement in conversational terms that any stakeholder can understand]\n\n**Scope Boundaries:**\n- In scope: [what this problem statement includes]\n- Out of scope: [what this explicitly does not include]\n- Future consideration: [what might be addressed later]\n</refined_problem_statement>\n\n<validation_questions>\n**Business Outcome Validation:**\n1. What would represent a home-run outcome for this initiative in 6 months?\n2. If we could only improve one business metric, which would matter most?\n3. What would cause you to consider this effort a failure, even if users liked it?\n\n**User Need Validation:**\n4. Which user segment would benefit most from solving this problem?\n5. How do we know users actually experience this as a problem vs. our assumption?\n6. What would users give up or trade off to get this improvement?\n\n**Scope and Priority Validation:**\n7. If we had to cut scope by 50%, what's the core of this request we must keep?\n8. What's more important: shipping by [date] or achieving [specific outcome]?\n9. How does this compare in priority to [other initiative on roadmap]?\n\n**Constraints Validation:**\n10. What technical limitations should we absolutely not try to work around?\n11. Are there brand or design standards we could flex if it meant better user outcomes?\n12. What budget or timeline assumptions should we validate before proceeding?\n\n**Success Criteria Validation:**\n13. How will we know if we've succeeded in 3 months? 6 months? 12 months?\n14. What user feedback or behavior would make you confident we solved this?\n15. What business metrics matter more than hitting the launch date?\n</validation_questions>\n\n<recommended_next_steps>\n1. **Validate assumptions:** [Specific research or conversations needed to confirm problem understanding]\n2. **Baseline metrics:** [Establish current measurements for success criteria]\n3. **Exploratory design:** [Create lightweight concepts to test problem framing]\n4. **Stakeholder alignment:** [Schedule review of refined problem statement with key stakeholders]\n5. **Technical feasibility:** [Partner with engineering to validate constraints and opportunities]\n6. **User validation:** [Test problem statement against actual user pain points through interviews or surveys]\n7. **Prioritization:** [Compare this problem statement against other roadmap items]\n</recommended_next_steps>\n</problem_statement_analysis>\n\nFAILURE\n- Any required section in `<problem_statement_analysis>` is missing or materially incomplete.\n- Problem statement is not measurable (missing baseline/target/date/constraints).\n- Clarifying questions are not actionable or do not address business, user, scope, constraints, and success validation.\n- Metrics and constraints are generic or not traceable to the provided inputs.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Stakeholder Management/Stakeholder MOO objections and product derailment risks.md",
      "title": "Stakeholder MOO objections and product derailment risks",
      "category": "Stakeholder Management",
      "tags": [
        "stakeholder-management",
        "risk-management",
        "product-strategy",
        "communication"
      ],
      "content": "INPUTS\n<provided_inputs>\n- [No explicit variables declared; use provided context.]\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Stakeholder MOO objections and product derailment risks.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Apply MOO (Most Obvious Objection) analysis to stakeholder risk/derailment scenarios.\n- First collect only essential context; ask concise follow-ups with a maximum of 5 questions total if needed.\n- If sufficient context exists, produce:\n- `BLUF` with top 3 stakeholder-voice MOOs, why obvious, confidence, and QBQ.\n- Stakeholder objection mapping with objection type, MOO rank, QBQ, loss/gain framing, frequency x magnitude, evidence requested, counter-moves, and decision thresholds.\n- Red-team drill questions, proof and pre-wire plan, executive one-slide summary, risk register, and vibe-check behaviors.\n- Use plain, scannable language; label assumptions/uncertainties; prioritize obvious objections first; include numbers where possible.\n- Ensure edge-case objections are covered (data quality, privacy, model eval/bias when relevant, scale/support load, contracts/channel conflict/cannibalization, change management, measurement validity).\n- If context is insufficient, output only:\n- A 5-question minimal follow-up.\n- A clearly labeled provisional top-3 MOO guess.\n\nFORMAT\nReturn exactly this structure:\n\nIf context is insufficient:\nMinimal Follow-up (5 questions)\n1. [question]\n2. [question]\n3. [question]\n4. [question]\n5. [question]\nProvisional Top-3 MOO Guess (clearly labeled)\n- [MOO 1]\n- [MOO 2]\n- [MOO 3]\n\nIf context is sufficient:\nA) BLUF - Top 3 MOOs\n- [stakeholder-voice objection + why obvious + confidence + QBQ]\n\nB) Stakeholder Objection Map\n| Stakeholder Group | Objection | Type | MOO Rank (1-5) | QBQ | Loss vs Gain | Freq x Magnitude | Evidence Asked | Counter-moves | Decision Threshold |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| [row] | [row] | [row] | [row] | [row] | [row] | [row] | [row] | [row] | [row] |\n\nC) Red-Team Drill\n- [5-10 sharp questions]\n\nD) Proof & Pre-Wire Plan\nFast proof stack:\n- [test]\nArtifacts:\n- [artifact]\nPre-wire scripts:\n- Email/Slack template (<=120 words): [text]\n- 60-sec live opener: [text]\n- If-they-say-X, you-say-Y snippets (top 3): [text]\n\nE) Executive Slide (1 slide)\nTitle: [text]\n- Why now: [text]\n- Top MOO + QBQ: [text]\n- Evidence to date: [text]\n- Next proof step + decision gate: [text]\n- Ask (people/time/budget) + trade-offs: [text]\n\nF) Risk Register\n| Risk | Trigger | Early Warning Signal | Owner | Mitigation | Kill-switch |\n| --- | --- | --- | --- | --- | --- |\n| [row] | [row] | [row] | [row] | [row] | [row] |\n\nG) Vibe Check\nBehaviors to avoid:\n- [item]\nGrounded behaviors to show:\n- [item]\n\nFAILURE\n- Does not follow the conditional output path (insufficient-context vs sufficient-context).\n- Missing required MOO sections (`A` through `G`) when context is sufficient.\n- Objection map lacks required fields (type, rank, QBQ, evidence, threshold, counter-moves).\n- Red-team, proof/pre-wire, risk register, or vibe-check sections are missing or superficial.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Stakeholder Management/Stakeholder Power–Interest & Influence Map.md",
      "title": "\"Stakeholder Power–Interest & Influence Map\"",
      "category": "\"Stakeholder Management\"",
      "tags": [
        "stakeholder-management",
        "influence",
        "internal-politics",
        "communication"
      ],
      "content": "INPUTS\n<provided_inputs>\n- [No explicit variables declared; use provided context.]\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: \"Stakeholder Power–Interest & Influence Map\".\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Build a stakeholder strategy output from initiative context and stakeholder details.\n- If critical stakeholder context is missing, ask exactly 3 targeted questions; if still unclear, state assumptions and proceed.\n- Produce:\n- A Power-Interest 2x2 matrix with named stakeholders per quadrant.\n- An Influence Pyramid (Top/Middle/Base) including informal power roles (gatekeepers, super-connectors, executive assistants where relevant).\n- High-power stakeholder profiles covering goals/metrics, concerns/risks, preferred comms style, and political risks.\n- A tailored engagement plan per high-power stakeholder (cadence/channel, format/owner, key message, quick win, fallback).\n- A plan to inform/mobilize high-interest low-power stakeholders.\n- Success signals/metrics and top 3 prioritized political pitfalls with mitigations.\n\nFORMAT\nReturn exactly this structure:\n\nPower-Interest Matrix\n| Quadrant | Stakeholders |\n| --- | --- |\n| High Power / High Interest | [names] |\n| High Power / Low Interest | [names] |\n| Low Power / High Interest | [names] |\n| Low Power / Low Interest | [names] |\n\nInfluence Pyramid\n- Top: [names + rationale]\n- Middle: [names + rationale]\n- Base: [names + rationale]\n\nHigh-Power Profiles\n| Stakeholder | Goals & Success Metrics | Likely Concerns/Risks | Preferred Communication Style | Political Risks for Me |\n| --- | --- | --- | --- | --- |\n| [row] | [row] | [row] | [row] | [row] |\n\nEngagement Plan\n| Stakeholder | Cadence & Channel | Format | Owner | Key Message | Quick Win | Fallback |\n| --- | --- | --- | --- | --- | --- | --- |\n| [row] | [row] | [row] | [row] | [row] | [row] | [row] |\n\nAdvocacy Plan (High-Interest / Low-Power)\n- [how to inform]\n- [how to mobilize advocacy]\n\nSuccess Signals & Metrics\n- [signal/metric]\n\nRisks & Mitigations\n1. [pitfall + mitigation]\n2. [pitfall + mitigation]\n3. [pitfall + mitigation]\n\nAssumptions\n- [assumption or \"None\"]\n\nFAILURE\n- Any required section/table is missing or materially incomplete.\n- High-power stakeholders are not profiled and mapped to tailored engagement actions.\n- Informal influence is ignored or unsupported.\n- Top 3 political pitfalls and mitigations are missing, unprioritized, or generic.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Stakeholder Management/Stakeholder Risk Review for a Feature or PRD.md",
      "title": "\"Stakeholder Risk Review for a Feature or PRD\"",
      "category": "\"Stakeholder Management\"",
      "tags": [
        "stakeholder-management",
        "risk-management",
        "product-management",
        "communication",
        "internal-politics"
      ],
      "content": "INPUTS\n<provided_inputs>\n- [No explicit variables declared; use provided context.]\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: \"Stakeholder Risk Review for a Feature or PRD\".\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Review a feature/PRD for stakeholder and political risk before broad circulation.\n- Build a Power-Interest snapshot (with named stakeholders) and include informal influencers.\n- Identify stakeholders likely to feel threatened/excluded/overruled and articulate concrete objections.\n- Provide mitigation guidance in two tracks:\n- Document improvements (evidence, ownership, metrics, clarifications).\n- 1:1 stakeholder messaging (focus, proof points, artifacts).\n- Recommend exactly 3 pre-work actions before broad sharing.\n- Provide framing variations for execs vs ICs and a minimal comms sequence.\n- List top decision/optics risks with mitigations (pilot scope, phased rollout, sunset criteria, contingencies).\n- Provide a practical readiness checklist (data, owners, dependencies, support, legal/privacy where relevant).\n\nFORMAT\nReturn exactly this structure:\n\nPower-Interest Snapshot\n| Quadrant | Stakeholders |\n| --- | --- |\n| High Power / High Interest | [names] |\n| High Power / Low Interest | [names] |\n| Low Power / High Interest | [names] |\n| Low Power / Low Interest | [names] |\nInformal influencers: [names and why]\n\nStakeholder Concerns\n| Stakeholder | Concern | Evidence Needed | Suggested Response |\n| --- | --- | --- | --- |\n| [row] | [row] | [row] | [row] |\n\nDoc Changes\n- [specific PRD/doc edit]\n\n1:1 Messages\n- [Stakeholder]: [message focus, proof points, artifacts]\n\nPre-Work: Top 3 Actions\n1. [action]\n2. [action]\n3. [action]\n\nFraming & Comms Sequence\nExec framing: [benefits, risks, ask]\nIC framing: [benefits, risks, ask]\nComms sequence:\n1. [step]\n2. [step]\n3. [step]\n\nRisks & Mitigations\n| Risk | Why it matters | Mitigation | Owner |\n| --- | --- | --- | --- |\n| [row] | [row] | [row] | [row] |\n\nReadiness Checklist\n- [ ] Data readiness confirmed\n- [ ] Owners assigned\n- [ ] Dependencies mapped\n- [ ] Support plan defined\n- [ ] Legal/privacy review completed (if applicable)\n- [ ] [additional item]\n\nAssumptions\n- [assumption or \"None\"]\n\nFAILURE\n- Any required section is missing or materially incomplete.\n- Fewer or more than 3 items in `Pre-Work: Top 3 Actions`.\n- Stakeholder concerns are generic or lack evidence/response mapping.\n- Power-Interest snapshot omits names or ignores informal influencers.\n- Risks/mitigations are not actionable or lack ownership.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Stakeholder Management/Stakeholder decision-making using TOC thinking process.md",
      "title": "Stakeholder decision-making using TOC thinking process",
      "category": "Stakeholder Management",
      "tags": [
        "decision-making",
        "stakeholders",
        "theory-of-constraints",
        "problem-solving",
        "stakeholder-management"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{PROBLEM_STATEMENT}}\n- {{STAKEHOLDER_INFO}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Stakeholder decision-making using TOC thinking process.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Analyze `{{PROBLEM_STATEMENT}}` and `{{STAKEHOLDER_INFO}}` to support stakeholder decision-making using TOC thinking processes.\n- Identify and clearly state the core problem.\n- Apply Evaporating Cloud:\n- Define conflict.\n- Identify requirements.\n- Uncover assumptions.\n- Challenge assumptions.\n- Generate potential solutions.\n- Apply Effect-Cause-Effect:\n- Identify undesirable effects.\n- Trace effects to causes.\n- Identify root causes.\n- Produce actionable recommendations and explicitly connect them to stakeholder concerns/interests.\n\nFORMAT\nReturn exactly this structure:\n\n<analysis>\n1. Problem Identification:\n   [Clearly state the core problem]\n\n2. Evaporating Cloud Analysis:\n   a. Conflict: [Describe the main conflict]\n   b. Requirements: [List the key requirements]\n   c. Assumptions: [Identify important assumptions]\n   d. Challenged Assumptions: [Explain how assumptions were challenged]\n   e. Potential Solutions: [List generated solutions]\n\n3. Effect-Cause-Effect Analysis:\n   a. Undesirable Effects: [List the main undesirable effects]\n   b. Causes: [Explain the causes linked to each effect]\n   c. Root Causes: [Identify the fundamental root causes]\n\n4. Recommendations:\n   [Provide specific, actionable recommendations based on your analysis]\n\n5. Stakeholder Considerations:\n   [Explain how your recommendations address stakeholder concerns and interests]\n</analysis>\n\nFAILURE\n- Any required section in `<analysis>` is missing or materially incomplete.\n- Evaporating Cloud or Effect-Cause-Effect steps are missing or not logically connected.\n- Recommendations are generic, non-actionable, or not tied to stakeholder considerations.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Stakeholder Management/Trade-off analysis from feature priority and effort data.md",
      "title": "Trade-off analysis from feature priority and effort data",
      "category": "Stakeholder Management",
      "tags": [
        "prioritization",
        "tradeoffs",
        "feature-evaluation"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{STAKEHOLDER_REQUEST}}\n- {{FEATURE_PRIORITY}}\n- {{FEATURE_EFFORT}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Trade-off analysis from feature priority and effort data.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Analyze `{{STAKEHOLDER_REQUEST}}` using `{{FEATURE_PRIORITY}}` and `{{FEATURE_EFFORT}}`.\n- Identify key benefits, drawbacks/opportunity costs, and lower-effort alternatives addressing similar needs.\n- Build a 2x2 priority-effort matrix with quadrants:\n- High Priority / Low Effort\n- High Priority / High Effort\n- Low Priority / Low Effort\n- Low Priority / High Effort\n- Place the proposed feature in the correct quadrant and include 2-3 comparator features/initiatives across other quadrants.\n- Provide concise explanation for each matrix item (benefits, drawbacks, and placement rationale).\n- Recommend whether to pursue, defer, or reject, with concrete next steps and alternatives.\n\nFORMAT\nReturn exactly this structure:\n\n<trade_off_analysis>\n<matrix>\n[Insert your 2x2 matrix here, using ASCII art or a simple text representation]\n</matrix>\n\n<explanations>\n[Provide brief explanations for each item in the matrix]\n</explanations>\n\n<recommendation>\n[Offer your recommendation and next steps]\n</recommendation>\n</trade_off_analysis>\n\nFAILURE\n- Any required section in `<trade_off_analysis>` is missing or materially incomplete.\n- Matrix is missing the proposed feature or lacks 2-3 comparator items.\n- Explanations do not justify quadrant placement with benefits/drawbacks.\n- Recommendation is generic or does not provide clear next steps.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Stakeholder Management/Translate technical explanations into stakeholder language.md",
      "title": "Technical Translation and Stakeholder Communication",
      "category": "Stakeholder Management",
      "tags": [
        "stakeholder-management",
        "technical-communication",
        "product-management",
        "decision-making"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{TECHNICAL_EXPLANATION}}\n- {{STAKEHOLDER_TYPE}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Technical Translation and Stakeholder Communication.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Translate `{{TECHNICAL_EXPLANATION}}` for `{{STAKEHOLDER_TYPE}}` into clear, decision-ready language.\n- Preserve core technical meaning while reducing jargon and using relatable explanations where helpful.\n- Explicitly cover:\n- Overview of the technical situation.\n- Business impact in stakeholder terms.\n- Important considerations (risks, benefits, decisions).\n- Likely stakeholder questions with direct answers.\n- Recommended next steps.\n- Include a brief glossary only for unavoidable technical terms.\n- Final output must include only `<simplified_explanation>` and `<glossary>`.\n\nFORMAT\nReturn exactly this structure:\n\n<simplified_explanation>\n1. Overview: [Brief description of the technical situation]\n2. Business Impact: [Key implications for the stakeholder]\n3. Important Considerations: [Risks, benefits, or decisions to understand]\n4. Stakeholder Questions and Answers:\n   Q1: [Likely question 1]\n   A1: [Clear answer to question 1]\n   Q2: [Likely question 2]\n   A2: [Clear answer to question 2]\n   [Add more Q&A pairs as needed]\n5. Next Steps: [Recommended actions, if applicable]\n</simplified_explanation>\n\n<glossary>\n- Term 1: [Brief definition]\n- Term 2: [Brief definition]\n[Add more terms as needed]\n</glossary>\n\nFAILURE\n- `<simplified_explanation>` or `<glossary>` is missing, malformed, or materially incomplete.\n- Explanation is still jargon-heavy for the specified stakeholder type.\n- Q&A section is missing or does not address likely stakeholder concerns.\n- Translation loses critical risks/implications from the original technical content.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Technical/Acceptance criteria for UI.md",
      "title": "Acceptance criteria for UI",
      "category": "Technical",
      "tags": [
        "quality-assurance",
        "ui",
        "acceptance-criteria",
        "responsive-design",
        "technical"
      ],
      "content": "INPUTS\n<provided_inputs>\n- [No explicit variables declared; use provided context.]\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Acceptance criteria for UI.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Produce a testable UI acceptance-criteria and QA validation checklist for the provided UI context.\n- Cover at minimum:\n- Visual testing (default/state/responsive checks).\n- Functional testing (primary action, loading, error handling, edge cases).\n- Accessibility testing (keyboard, screen reader, contrast, ARIA/semantic checks).\n- Browser/device compatibility.\n- Pass/fail summary with issues, tester, and date.\n- Keep checks specific and verifiable (observable behavior, measurable thresholds, concrete expected results).\n- Use a checklist style suitable for QA execution.\n\nFORMAT\nReturn exactly this structure:\n\n<qa_validation>\n## QA Validation Checklist\n\n### Visual Testing\n- [ ] [check]\n- [ ] [check]\n\n### Functional Testing\n- [ ] [check]\n- [ ] [check]\n\n### Accessibility Testing\n- [ ] [check]\n- [ ] [check]\n\n### Browser Compatibility\n- [ ] Chrome (latest): [result]\n- [ ] Safari (latest): [result]\n- [ ] Firefox (latest): [result]\n- [ ] Edge (latest): [result]\n- [ ] Safari iOS: [result]\n- [ ] Chrome Android: [result]\n\n### Pass/Fail\n**Overall Result:** [PASS or FAIL]\n**Issues Found:** [list deviations or \"None\"]\n**Tester:** [name]\n**Date:** [date]\n</qa_validation>\n\nFAILURE\n- `<qa_validation>` schema is missing, malformed, or materially incomplete.\n- Checklist items are vague/non-testable (no clear expected behavior or measurable criteria).\n- Any critical section (Visual, Functional, Accessibility, Browser Compatibility, Pass/Fail) is missing.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Technical/Dual-mode AI coding assistant (Staff Eng + Intern).md",
      "title": "Dual-mode AI coding assistant (Staff Eng + Intern)",
      "category": "Technical",
      "tags": [
        "software-development",
        "coding-assistant",
        "architecture",
        "implementation",
        "workflow",
        "ai",
        "technical"
      ],
      "content": "INPUTS\n<provided_inputs>\n- [No explicit variables declared; use provided context.]\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Dual-mode AI coding assistant (Staff Eng + Intern).\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Operate in one of two modes only:\n- `Staff Engineer Mode` for planning/architecture/roadmaps.\n- `Intern Mode` for scoped implementation and validation.\n- Select mode by request intent:\n- Use `Staff Engineer Mode` for design/plan/approach or multi-component strategy.\n- Use `Intern Mode` for concrete file/function implementation requests.\n- If unclear, ask one brief mode-clarification question before proceeding.\n- In `Staff Engineer Mode`:\n- Provide architecture guidance, risks, dependencies, and a phased implementation checklist.\n- Include file-level scope, test checkpoints, and edge-case considerations.\n- Do not provide detailed code implementation.\n- In `Intern Mode`:\n- Work strictly within defined scope and specified files/functions.\n- Make atomic, targeted implementation changes matching existing style.\n- Include requested validation output and concrete failure notes/fixes when needed.\n- Do not expand scope or add unsolicited architectural redesign.\n\nFORMAT\nReturn exactly this structure:\n\nIf mode is unclear:\nMode Clarification Question:\nWould you like planning support (Staff Engineer mode) or scoped implementation (Intern mode)?\n\nIf Staff Engineer Mode:\nMode: Staff Engineer\nContext Check:\n- [known context]\n- [critical missing info, if any]\nArchitecture & Strategy:\n- [recommendation]\nImplementation Plan (phased checklist):\n1. [step]\n   Files: [path/function scope]\n   Dependencies: [items]\n   Test checkpoint: [verification]\n   Risks/edge cases: [notes]\nComplexity Notes:\n- [step -> estimated complexity]\n\nIf Intern Mode:\nMode: Intern\nScope:\n- Files/functions in scope: [items]\n- Out of scope: [items]\nImplementation:\n- [atomic change 1]\n- [atomic change 2]\nValidation:\n- Requested output: [result summary]\n- Failures/warnings: [items or \"None\"]\n- Specific fixes (if needed): [items]\n\nFAILURE\n- Mode boundaries are violated (planning mixed with implementation or vice versa).\n- Mode is unclear but no clarification question is asked.\n- Staff Engineer output lacks phased checklist, file-level scope, or test checkpoints.\n- Intern output expands scope beyond requested files/functions or includes unsolicited architecture changes.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Technical/Engineering Problem Solving and Solution Structuring.md",
      "title": "Engineering Problem Solving and Solution Structuring",
      "category": "Technical",
      "tags": [
        "engineering",
        "problem-solving",
        "solution-design",
        "tradeoff-analysis",
        "technical"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{PROBLEM_TO_SOLVE}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Engineering Problem Solving and Solution Structuring.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Analyze `{{PROBLEM_TO_SOLVE}}` and produce a structured engineering solution assessment.\n- Provide:\n- Problem overview.\n- Key challenges.\n- Three distinct solution options.\n- Pros/cons analysis for each solution.\n- One additional/hybrid solution.\n- Final recommendation with rationale.\n- Each required section must contain at least four detailed, thoughtful sentences.\n- Keep recommendations technically grounded, explicit about trade-offs, and practical for implementation.\n\nFORMAT\nReturn exactly this structure:\n\n<problem_overview>[Overview of the problem]</problem_overview>\n<challenges>[Key challenges in solving the problem]</challenges>\n<solution1>[First potential solution]</solution1>\n<solution2>[Second potential solution]</solution2>\n<solution3>[Third potential solution]</solution3>\n<solution1_analysis>[Analysis of pros and cons of Solution 1]</solution1_analysis>\n<solution2_analysis>[Analysis of pros and cons of Solution 2]</solution2_analysis>\n<solution3_analysis>[Analysis of pros and cons of Solution 3]</solution3_analysis>\n<additional_solution>[Additional or hybrid solution]</additional_solution>\n<recommendation>[Final recommendation on the best approach]</recommendation>\n\nFAILURE\n- Any required section is missing, malformed, or materially incomplete.\n- Any required section has fewer than four sentences.\n- Solutions are redundant, non-distinct, or lack trade-off analysis.\n- Recommendation does not clearly justify why one approach is preferred.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Technical/Features reframing and projects Shape Up.md",
      "title": "Features reframing and projects Shape Up",
      "category": "Technical",
      "tags": [
        "product-strategy",
        "shaping",
        "scope-management",
        "stakeholder-management",
        "technical"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{FEATURE_OR_PROJECT}}\n- {{CONTEXT}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Features reframing and projects Shape Up.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Reframe `{{FEATURE_OR_PROJECT}}` using Shape Up principles and provided `{{CONTEXT}}`.\n- Provide a shaped work definition that is concrete enough for delivery but avoids build-phase implementation detail.\n- Include:\n- Appetite assessment (`1-2 weeks` or `6 weeks`) with rationale.\n- Problem framing (problem-first, not solution-first).\n- Boundary definition (in-scope / out-of-scope).\n- Solution sketch at fat-marker level.\n- Risks/rabbit holes and circuit-breakers.\n- Explicit no-gos.\n- Executive constraint language to secure scope commitment and prevent mid-cycle scope creep.\n- Keep output focused on shaping quality, delivery constraints, and stakeholder alignment.\n\nFORMAT\nReturn exactly this structure:\n\nShape Up Reframe\n\nAppetite Assessment\n- Recommended appetite: [1-2 weeks or 6 weeks]\n- Why this appetite: [rationale]\n\nProblem Framing\n- Core problem: [problem statement]\n- Why this matters now: [impact/context]\n- Success condition: [what success looks like]\n\nBoundary Definition\n- In scope:\n  - [item]\n- Out of scope:\n  - [item]\n\nSolution Sketching (Fat Marker Level)\n- Key approach: [high-level approach]\n- Main interaction/surface 1: [conceptual behavior]\n- Main interaction/surface 2: [conceptual behavior]\n\nRisks and Rabbit Holes\n- [risk/rabbit hole]\n- Circuit-breaker: [constraint or stop-rule]\n\nNo-gos\n- [explicit exclusion]\n\nExecutive Constraints\n- Commitment language: [specific wording to secure scope agreement]\n- Change-control rule: [how new requests are handled mid-cycle]\n- Escalation path: [who decides if scope must change]\n\nAssumptions\n- [assumption or \"None\"]\n\nFAILURE\n- Any required section is missing or materially incomplete.\n- Output drifts into build-phase implementation details instead of shaping-level decisions.\n- Boundaries/no-gos are vague or do not constrain scope.\n- Executive constraint handling is missing or not actionable.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/Technical/Technical architecture brief from product requirements doc.md",
      "title": "Technical architecture brief from product requirements doc",
      "category": "Technical",
      "tags": [
        "software-architecture",
        "startup-cto",
        "systems-design",
        "risk-management",
        "technical"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{PRD}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Technical architecture brief from product requirements doc.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Create a comprehensive Technical Architecture Brief from `{{PRD}}` suitable for startup execution.\n- Include and reason through all required sections:\n- `System Context Diagram`\n- Bounded contexts.\n- Context interactions.\n- Third-party integrations (APIs/SaaS/data pipelines).\n- `Component Architecture`\n- Monolith vs microservices trade-off.\n- Recommended architecture with justification.\n- Data flow, schema, and caching strategy.\n- Database choice rationale (relational/NoSQL/hybrid).\n- `Technology Stack Rationale`\n- Frontend/backend framework recommendations with rationale.\n- Infrastructure approach (cloud/on-prem/hybrid).\n- Containerization and CI/CD strategy.\n- `Risk Mitigation Plan`\n- Failure modes and single points of failure.\n- Redundancy and resilience strategies.\n- High-level compute/storage cost projections aligned to growth.\n- Keep recommendations tied to the PRD and explicitly state assumptions when PRD details are missing.\n\nFORMAT\nReturn exactly this structure:\n\n<Technical_Architecture_Brief>\n<System_Context_Diagram>\n[Content for this section]\n</System_Context_Diagram>\n\n<Component_Architecture>\n[Content for this section]\n</Component_Architecture>\n\n<Technology_Stack_Rationale>\n[Content for this section]\n</Technology_Stack_Rationale>\n\n<Risk_Mitigation_Plan>\n[Content for this section]\n</Risk_Mitigation_Plan>\n</Technical_Architecture_Brief>\n\nFAILURE\n- `<Technical_Architecture_Brief>` wrapper or any required section is missing/malformed/materially incomplete.\n- Recommendations are generic and not traceable to the provided PRD.\n- Architecture choice lacks explicit trade-off analysis (monolith vs microservices).\n- Risk plan lacks concrete failure modes, mitigation strategy, or cost-growth framing.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/User Research/Actionable customer interview guides from research topics.md",
      "title": "Actionable customer interview guides from research topics",
      "category": "User Research",
      "tags": [
        "user-research",
        "interviews",
        "discussion-guide"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{TOPIC}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Actionable customer interview guides from research topics.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Create a comprehensive customer interview discussion guide for `{{TOPIC}}`.\n- Follow Mom Test and Continuous Discovery Habits principles:\n- Open-ended, behavior-based questions.\n- Focus on past experiences over hypotheticals.\n- No leading or biased phrasing.\n- Cover current workflow, pain points, outcomes, and usage context.\n- Structure the guide in sections:\n- Introduction and warm-up.\n- Current situation and workflow.\n- Challenges and pain points.\n- Desired outcomes and goals.\n- Exploration of potential solutions (without pitching).\n- Wrap-up and next steps.\n- Within each section:\n- Number all questions.\n- Prioritize the most important questions first.\n- Include concise interviewer prompts in `[brackets]` where useful.\n- Start with a brief interviewer introduction and key reminders.\n\nFORMAT\nReturn exactly this structure:\n\n<discussion_guide>\n[Brief interviewer introduction: interview purpose and key reminders]\n\n## Introduction and Warm-Up\n1. [Question]\n[Interviewer prompt in brackets if needed]\n\n## Current Situation and Workflow\n1. [Question]\n[Interviewer prompt in brackets if needed]\n\n## Challenges and Pain Points\n1. [Question]\n[Interviewer prompt in brackets if needed]\n\n## Desired Outcomes and Goals\n1. [Question]\n[Interviewer prompt in brackets if needed]\n\n## Exploration of Potential Solutions\n1. [Question]\n[Interviewer prompt in brackets if needed]\n\n## Wrap-Up and Next Steps\n1. [Question]\n[Interviewer prompt in brackets if needed]\n</discussion_guide>\n\nFAILURE\n- `<discussion_guide>` schema is missing, malformed, or materially incomplete.\n- Required sections are missing or questions are not numbered/prioritized.\n- Questions are leading, hypothetical-first, or not behavior-based.\n- Guide does not cover workflow, pain points, outcomes, and context.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/User Research/Actionable job stories from interview transcripts.md",
      "title": "Actionable job stories from interview transcripts",
      "category": "User Research",
      "tags": [
        "user-research",
        "jtbd",
        "interviews"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{INTERVIEW_TRANSCRIPT}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Actionable job stories from interview transcripts.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Analyze `{{INTERVIEW_TRANSCRIPT}}` to identify explicit and implicit user problems.\n- Infer underlying needs from:\n- Pain points, frustrations, inefficiencies.\n- Context and background details.\n- Goals, motivations, and desired outcomes.\n- Workarounds and makeshift solutions.\n- Generate job stories in this format:\n- `When [situation], I want to [motivation], so I can [expected outcome].`\n- Output only:\n- A concise 2-3 sentence summary.\n- A list of job stories grounded in transcript evidence.\n\nFORMAT\nReturn exactly this structure:\n\n<response>\n<summary>\n[Brief summary of your analysis]\n</summary>\n<job_stories>\n<job_story>[Job story 1]</job_story>\n<job_story>[Job story 2]</job_story>\n[Additional <job_story> entries as needed]\n</job_stories>\n</response>\n\nFAILURE\n- `<response>`, `<summary>`, or `<job_stories>` is missing or malformed.\n- Job stories do not follow `When... I want... so I can...` structure.\n- Job stories are generic or not grounded in transcript-derived problems.\n- Summary is missing or not within 2-3 sentences.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/User Research/Actionable product improvements from survey responses.md",
      "title": "Actionable product improvements from survey responses",
      "category": "User Research",
      "tags": [
        "user-research",
        "surveys",
        "insights"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{SURVEY_RESPONSES}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Actionable product improvements from survey responses.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Analyze `{{SURVEY_RESPONSES}}` to identify recurring themes and distinct user pain points.\n- For each pain point, include:\n- At least two supporting quotes from different responses where possible.\n- One or more concrete, actionable improvement items.\n- Ensure findings are evidence-based, specific, and focused on improving product/service/process outcomes.\n- Identify multiple themes when the dataset supports it.\n\nFORMAT\nReturn exactly this structure:\n\n<analysis>\n<theme>\n<pain_point>[Describe the pain point]</pain_point>\n<supporting_quotes>\n- \"[Relevant quote]\" (Response #X)\n- \"[Relevant quote]\" (Response #Y)\n</supporting_quotes>\n<action_items>\n- [Action item 1]\n- [Action item 2]\n</action_items>\n</theme>\n[Repeat `<theme>` for each identified theme]\n</analysis>\n\nFAILURE\n- `<analysis>` or `<theme>` schema is missing, malformed, or materially incomplete.\n- Pain points are generic and not supported by response evidence.\n- Any theme lacks at least two supporting quotes.\n- Action items are vague, non-actionable, or not linked to the stated pain point.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/User Research/Actionable research briefs from problem statements and solutions.md",
      "title": "Actionable research briefs from problem statements and solutions",
      "category": "User Research",
      "tags": [
        "user-research",
        "research-brief",
        "ux"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{PROBLEM_STATEMENT}}\n- {{PROPOSED_SOLUTION}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Actionable research briefs from problem statements and solutions.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Analyze `{{PROBLEM_STATEMENT}}` and `{{PROPOSED_SOLUTION}}` to produce an actionable UX research brief.\n- Include and connect the following components:\n- Background context.\n- Scope and key risks to investigate.\n- Rough research timeline.\n- Research type.\n- Research methods (qualitative and/or quantitative as appropriate).\n- Concrete deliverables.\n- Expected outcomes, learnings, and measurement plan.\n- Keep recommendations specific, feasible, and aligned to decision-making needs.\n- Provide rationale for chosen research type/methods/timing.\n\nFORMAT\nReturn exactly this structure:\n\n<research_brief>\n## Introduction\n[Brief summary of problem and proposed solution]\n\n## Background Context\n[Context and core issues]\n\n## Scope and Risks\n[What the research will cover and key risks/challenges to validate]\n\n## Rough Timelines\n[Phased timeline with approximate duration]\n\n## Type of Research\n[Evaluative, generative, exploratory, validation, etc., with rationale]\n\n## Research Methods\n[Methods, participants, and why they fit]\n\n## Research Deliverables\n[Specific outputs from the research]\n\n## Expected Outcomes, Learnings, and Measurements\n[What decisions this research should inform and how success will be measured]\n</research_brief>\n\nFAILURE\n- `<research_brief>` schema is missing, malformed, or materially incomplete.\n- Required brief components are missing or weakly specified.\n- Methods are not aligned to the problem/solution or lack clear rationale.\n- Deliverables/outcomes are generic and not decision-oriented.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/User Research/Actionable user profiles with tasks and constraints from shallow personas.md",
      "title": "Actionable user profiles with tasks and constraints from shallow personas",
      "category": "User Research",
      "tags": [
        "user-research",
        "personas",
        "ux"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{EXISTING_PERSONA}}\n- {{AVAILABLE_USER_DATA}}\n- {{PRODUCT_CONTEXT}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Actionable user profiles with tasks and constraints from shallow personas.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Transform `{{EXISTING_PERSONA}}` into an actionable user profile using `{{AVAILABLE_USER_DATA}}` and `{{PRODUCT_CONTEXT}}`.\n- Replace vague persona language with specific, observable details:\n- Concrete tasks and success outcomes.\n- Jobs-to-be-done (functional, emotional, social).\n- Capabilities, constraints, and behavioral patterns.\n- Grounded contextual scenarios.\n- Design implications directly tied to profile evidence.\n- Explicit research gaps and validation plan for missing/uncertain assumptions.\n- Keep all claims evidence-linked; state assumptions when data is incomplete.\n\nFORMAT\nReturn exactly this structure:\n\n<actionable_user_profile>\n<profile_summary>\n**Role:** [Specific job title and organizational context]\n**Core Responsibility:** [What they're accountable for]\n**Primary Goal:** [What success looks like in their role]\n</profile_summary>\n\n<jobs_to_be_done>\n<functional_jobs>\n[List 5-7 specific tasks they need to accomplish related to this product:\n- Example: \"Create quarterly budget forecast for leadership review\"\n- Example: \"Onboard new team members to project workflows within first week\"]\n</functional_jobs>\n\n<emotional_jobs>\n[List 3-5 emotional needs:\n- Example: \"Feel confident in decisions without analysis paralysis\"\n- Example: \"Avoid embarrassment from missing important details\"]\n</emotional_jobs>\n\n<social_jobs>\n[List 2-3 social needs:\n- Example: \"Be seen as data-driven and strategic by leadership\"\n- Example: \"Maintain credibility with engineering team\"]\n</social_jobs>\n</jobs_to_be_done>\n\n<user_capabilities>\n**Technical Sophistication:**\n[Describe their comfort with technology, tools they know, learning curve tolerance]\n\n**Domain Expertise:**\n[Describe their knowledge of the problem domain, industry experience, specialized skills]\n\n**Decision Authority:**\n[Describe what they can decide independently vs. what requires approval]\n\n**Time Availability:**\n[Describe their time constraints, competing priorities, typical workflow rhythm]\n\n**Resources:**\n[Describe what tools, data, people, budget they have access to]\n</user_capabilities>\n\n<constraints>\n**Organizational Constraints:**\n[List policies, processes, approval chains that limit their options]\n\n**Technical Constraints:**\n[List system limitations, integrations, legacy tools they must work with]\n\n**Knowledge Constraints:**\n[List gaps in their knowledge, areas where they need guidance]\n\n**Time Constraints:**\n[List deadlines, recurring obligations, busy periods]\n\n**Resource Constraints:**\n[List limitations in budget, headcount, tools, data access]\n</constraints>\n\n<behavioral_patterns>\n**How They Currently Solve This Problem:**\n[Describe their current workflow, tools used, workarounds, pain points]\n\n**Decision-Making Style:**\n[Describe how they evaluate options, what evidence they trust, risk tolerance]\n\n**Collaboration Patterns:**\n[Describe who they work with, communication preferences, meeting cadence]\n\n**Learning Preferences:**\n[Describe how they prefer to learn new tools, documentation vs. experimentation]\n</behavioral_patterns>\n\n<contextual_scenarios>\n<scenario_1>\n**Situation:** [Specific context: when, where, why]\n**Goal:** [What they're trying to accomplish]\n**Constraints:** [What's limiting them]\n**Current Approach:** [How they do it now]\n**Pain Points:** [What goes wrong or feels hard]\n**Success Criteria:** [What \"good\" looks like]\n</scenario_1>\n\n<scenario_2>\n[Repeat structure for 2-3 total scenarios covering different use cases]\n</scenario_2>\n</contextual_scenarios>\n\n<design_implications>\n[List 5-7 specific design implications from this user profile:\n- \"Must support quick, interrupted workflows due to frequent context-switching\"\n- \"Should provide confidence-building validation since users fear making errors\"\n- \"Must integrate with Slack since that's where they live all day\"]\n</design_implications>\n\n<research_gaps>\n[List specific things you don't know but should validate with real users:\n- \"How do they currently handle X scenario?\"\n- \"What's their tolerance for Y type of complexity?\"\n- \"How often do they encounter Z situation?\"]\n</research_gaps>\n\n<validation_plan>\n[Describe how to validate this profile with real users:\n- Proposed research methods\n- Key questions to ask\n- Behaviors to observe\n- Success signals that profile is accurate]\n</validation_plan>\n</actionable_user_profile>\n\nFAILURE\n- Any required section in `<actionable_user_profile>` is missing or materially incomplete.\n- Profile remains generic/buzzword-heavy and not actionable for design decisions.\n- Jobs, constraints, scenarios, or implications are not grounded in available data.\n- Research gaps/validation plan are missing or non-specific.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/User Research/Actionable user research decisions from project insights.md",
      "title": "Actionable user research decisions from project insights",
      "category": "User Research",
      "tags": [
        "user-research",
        "decision-making",
        "frameworks"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{PROJECT_DESCRIPTION}}\n- {{DEVELOPMENT_STAGE}}\n- {{EVIDENCE_NEEDS}}\n- {{SPLASH_ZONE_IMPACT}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Actionable user research decisions from project insights.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Apply the Reforge-style user insights decision framing to:\n- `{{PROJECT_DESCRIPTION}}`\n- `{{DEVELOPMENT_STAGE}}`\n- `{{EVIDENCE_NEEDS}}`\n- `{{SPLASH_ZONE_IMPACT}}`\n- Produce a specific research decision description framed as a question.\n- Ensure the decision question is:\n- Concrete and visceral (not abstract).\n- Specific to user, context, behavior, and decision consequence.\n- Aligned to stage-appropriate evidence needs.\n- Scoped to the stated splash-zone/impact.\n- Include assumptions explicitly if required context is missing.\n\nFORMAT\nReturn exactly this structure:\n\n<scratchpad>\n[Use this space to think through and refine your decision description]\n</scratchpad>\n\n<decision_description>\n[Write your final decision description here]\n</decision_description>\n\nFAILURE\n- `<scratchpad>` or `<decision_description>` is missing, malformed, or materially incomplete.\n- Decision description is not phrased as a researchable question.\n- Language is vague/abstract and not specific to stage, evidence needs, or splash-zone impact.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/User Research/Aging research insight validation before reusing.md",
      "title": "Aging research insight validation before reusing",
      "category": "User Research",
      "tags": [
        "user-research",
        "validation",
        "insights"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{EXISTING_RESEARCH}}\n- {{CURRENT_CONTEXT}}\n- {{TIME_SINCE_RESEARCH}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Aging research insight validation before reusing.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Evaluate research currency using `{{EXISTING_RESEARCH}}`, `{{CURRENT_CONTEXT}}`, and `{{TIME_SINCE_RESEARCH}}`.\n- Assess decay factors (time, market, product, user base, competition, contextual/regulatory changes).\n- Classify insights by confidence (`high`, `medium`, `low`) with evidence and caveats.\n- Identify stable insight patterns vs decayed patterns.\n- Propose validation research (quick validation + deeper follow-up), testable hypotheses, and prioritized research gaps.\n- Provide clear guidance on what is safe to use now, what to use cautiously, and what to retire.\n- Respect prior research investment while being explicit about limitations and assumptions.\n\nFORMAT\nReturn exactly this structure:\n\n<research_validation_assessment>\n<decay_factor_analysis>\n<time_decay>\n- Time since research: [X months/years]\n- Decay risk: [Low/Medium/High]\n- Reasoning: [Why time matters for this research]\n</time_decay>\n\n<market_changes>\n- Changes: [List significant market shifts]\n- Impact on insights: [How these changes affect research validity]\n- Decay risk: [Low/Medium/High]\n</market_changes>\n\n<product_changes>\n- Changes: [List how product has evolved]\n- Impact on insights: [Which insights are now outdated]\n- Decay risk: [Low/Medium/High]\n</product_changes>\n\n<user_base_changes>\n- Changes: [How users/segments have changed]\n- Impact on insights: [Which user insights may no longer apply]\n- Decay risk: [Low/Medium/High]\n</user_base_changes>\n\n<competitive_landscape>\n- Changes: [How competitors have evolved]\n- Impact on insights: [How this affects user expectations/behaviors]\n- Decay risk: [Low/Medium/High]\n</competitive_landscape>\n\n<contextual_changes>\n- Changes: [Regulatory, technology, environmental shifts]\n- Impact on insights: [What's different now]\n- Decay risk: [Low/Medium/High]\n</contextual_changes>\n</decay_factor_analysis>\n\n<insight_validity_assessment>\n<high_confidence_insights>\n[Insights that are likely still valid:\n\n**Insight:** [Original finding]\n\n**Type:** [Fundamental need / Core job / Deep motivation]\n\n**Why Still Valid:**\n[Reasoning for confidence]\n\n**Evidence:**\n[Any recent signals supporting this]\n\n**Caveat:**\n[Any context to consider]\n\n**Recommended Use:**\n[How to apply this insight today]]\n</high_confidence_insights>\n\n<medium_confidence_insights>\n[Insights that should be validated:\n\n**Insight:** [Original finding]\n\n**Type:** [Behavior / Pain point / Preference / Workflow]\n\n**Decay Concern:**\n[What might have changed]\n\n**Current Confidence:** [50-75%]\n\n**Validation Needed:**\n[Specific questions to answer]\n\n**Quick Validation:**\n[Lightweight way to check if still true]\n\n**Use As:**\n[Hypothesis to test, not fact to assume]]\n</medium_confidence_insights>\n\n<low_confidence_insights>\n[Insights that are likely outdated:\n\n**Insight:** [Original finding]\n\n**Why Likely Invalid:**\n[Specific decay factors]\n\n**Current Confidence:** [<50%]\n\n**Recommendation:**\n[Don't rely on this - research fresh]\n\n**New Research Needed:**\n[What to study instead]]\n</low_confidence_insights>\n</insight_validity_assessment>\n\n<patterns_of_decay>\n**What Types of Insights Have Decayed:**\n[Common patterns: e.g., \"Tool-specific workflows are outdated\" or \"Pain points around X have been solved\"]\n\n**What Remains Stable:**\n[Common patterns: e.g., \"Core job of [Y] hasn't changed\" or \"Fundamental need for [Z] still exists\"]\n\n**Decay Acceleration Factors:**\n[What makes insights go stale faster in this domain]\n</patterns_of_decay>\n\n<validation_research_plan>\n**Critical Questions to Answer:**\n1. [Question that would validate/invalidate high-priority insight]\n2. [Question that would validate/invalidate high-priority insight]\n3. [Question that would validate/invalidate high-priority insight]\n\n**Proposed Research Approach:**\n\n**Phase 1: Quick Validation (1-2 weeks)**\n- Method: [Lightweight approach: surveys, analytics review, stakeholder interviews]\n- Purpose: [Confirm or refute medium-confidence insights]\n- Sample: [Who to include]\n- Key questions: [List]\n\n**Phase 2: Deep Dive (3-4 weeks, if needed)**\n- Method: [Rigorous approach: user interviews, observation, diary studies]\n- Purpose: [Generate fresh insights on areas of uncertainty]\n- Sample: [Who to include]\n- Key questions: [List]\n\n**Decision Point:**\n- After Phase 1: [Determine if Phase 2 is needed]\n- Criteria: [What findings would trigger deeper research]\n</validation_research_plan>\n\n<hypothesis_generation>\n[Convert old insights into testable hypotheses:\n\n**Old Insight:** [Original finding]\n\n**Current Hypothesis:** [Reformulated as testable statement]\n\n**Test:** [How to validate]\n\n**If True:** [What it means for design]\n\n**If False:** [What it means for design]\n\n**Alternative Hypotheses:**\n[Other possibilities to consider]]\n</hypothesis_generation>\n\n<research_gaps>\n**What We Don't Know:**\n[List critical unknowns not covered by old research:\n- New user segments\n- New use cases\n- New competitors/alternatives\n- New technologies\n- New constraints]\n\n**Priority:**\n[Which gaps are most critical to fill]\n\n**Proposed Research:**\n[How to fill each gap]\n</research_gaps>\n\n<safe_to_use>\n**Insights You Can Use Today:**\n[List high-confidence insights with caveats]\n\n**Use With Caution:**\n[List medium-confidence insights with required validation]\n\n**Don't Use:**\n[List low-confidence insights to discard]\n</safe_to_use>\n\n<research_hygiene>\n**Best Practices Going Forward:**\n- Research expiration dating: [Label research with \"valid until\" or \"revalidate by\"]\n- Decay indicators: [Track market/product changes that invalidate research]\n- Continuous learning: [Lightweight ongoing research to keep insights fresh]\n- Research library: [System for marking outdated research]\n- Validation triggers: [Events that should trigger revalidation]\n</research_hygiene>\n\n<communication>\n**How to Present to Team:**\n[Guidance for explaining which research to trust:\n- Be transparent about confidence levels\n- Explain decay factors\n- Propose validation plan\n- Don't dismiss old research entirely - use as starting point]\n\n**Research Debt Message:**\n[Draft message explaining need for fresh research while respecting past investment]\n</communication>\n</research_validation_assessment>\n\nFAILURE\n- Any required section in `<research_validation_assessment>` is missing or materially incomplete.\n- Confidence classifications are unsupported by decay-factor reasoning.\n- Validation plan lacks concrete questions, methods, or decision criteria.\n- Safe-to-use guidance does not clearly separate `use now` / `use with caution` / `don't use`.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/User Research/App aha moment identification from user data and app description.md",
      "title": "App aha moment identification from user data and app description",
      "category": "User Research",
      "tags": [
        "user-research",
        "analytics",
        "activation"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{APP_DESCRIPTION}}\n- {{USER_DATA}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: App aha moment identification from user data and app description.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Analyze `{{APP_DESCRIPTION}}` and `{{USER_DATA}}` to identify potential app \"aha moment\" conditions.\n- Perform:\n- Qualitative analysis to surface 3-5 likely activation actions/conditions and why they matter.\n- Quantitative analysis of retained vs churned behavior, including strongest predictor metrics.\n- Session/timing-sequence analysis when session-level data is available.\n- Synthesize findings into top \"aha moment\" conditions and supporting evidence.\n- For each potential condition, provide comparative engagement metrics where possible:\n- `% users who performed condition and were retained`\n- `% users who did not perform condition and were not retained`\n- If required data is unavailable, state that explicitly and provide best-supported directional inference.\n\nFORMAT\nReturn exactly this structure:\n\n<analysis>\n1. Qualitative Insights:\n   [List your qualitative findings here]\n\n2. Quantitative Insights:\n   [List your quantitative findings here]\n\n3. Potential \"Aha Moment\" Conditions:\n   [List the top 3-5 conditions you've identified]\n\n4. Supporting Metrics:\n   [Provide relevant metrics for each condition]\n\n5. Recommendations:\n   [Offer 2-3 actionable recommendations to improve user activation based on your analysis]\n</analysis>\n\nFAILURE\n- `<analysis>` schema is missing, malformed, or materially incomplete.\n- Potential aha conditions are not 3-5 or are not tied to both qualitative and quantitative evidence.\n- Supporting metrics are missing, non-comparative, or not derived from provided data.\n- Session/timing insights are omitted when session data exists, or fabricated when it does not.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/User Research/Clustered JTBD forces from interview data.md",
      "title": "Clustered JTBD forces from interview data",
      "category": "User Research",
      "tags": [
        "user-research",
        "jtbd",
        "interviews"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{INTERVIEW_DATA}}\n- {{FORCE_TYPE}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Clustered JTBD forces from interview data.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Analyze `{{INTERVIEW_DATA}}` to code and affinitize only the specified JTBD force type `{{FORCE_TYPE}}`.\n- Conceptually construct a binary coding matrix:\n- Stories as rows.\n- Force concepts as columns.\n- Existing concept match -> code `1`.\n- Novel concept -> add new column and backfill prior rows with `0`.\n- Abstract and stabilize force columns with overarching labels.\n- Identify stories that introduce unique force concepts.\n- Summarize structure, categories, unique contributors, and notable clustering patterns.\n- Keep scope strictly to the selected force type and explicitly state assumptions if input structure is incomplete.\n\nFORMAT\nReturn exactly this structure:\n\n<analysis>\n1. Spreadsheet Summary:\n   [Provide a brief overview of the spreadsheet structure]\n\n2. Force Categories:\n   [List the abstract labels for each force column]\n\n3. Unique Force Contributors:\n   [List the stories that introduced unique forces]\n\n4. Insights and Patterns:\n   [Share any notable observations from the affinitizing process]\n</analysis>\n\nFAILURE\n- `<analysis>` schema is missing, malformed, or materially incomplete.\n- Output mixes in non-selected force types or unsupported assumptions.\n- Force categories are not abstracted/stabilized or unique contributors are missing.\n- Insights do not reflect coding/affinity patterns from the provided data.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/User Research/Comprehensive use cases from user input for product strategy.md",
      "title": "Comprehensive use cases from user input for product strategy",
      "category": "User Research",
      "tags": [
        "user-research",
        "use-cases",
        "product-strategy"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{USER_INPUT}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Comprehensive use cases from user input for product strategy.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Analyze `{{USER_INPUT}}` and generate one or more distinct product strategy use cases.\n- For each use case, include:\n- `Problem` (in user language).\n- `Persona` (specific segment and context).\n- `Alternatives` (direct and indirect).\n- `Frequency` (time-based occurrence).\n- `Why` (core motivation/value driver).\n- `Consideration Time` (decision horizon).\n- Keep output human-readable and structured with clear headings and list formatting.\n- Ensure each use case is materially different and strategically useful.\n\nFORMAT\nReturn exactly this structure:\n\nUse Case 1: [Brief Title]\nProblem: [Problem description]\nPersona: [Persona description]\nAlternatives:\n- [Alternative 1]\n- [Alternative 2]\nFrequency: [Frequency description]\nWhy: [Core motivation]\nConsideration Time: [Estimated time]\n\n[Repeat \"Use Case N\" blocks as needed]\n\nFAILURE\n- Output is not human-readable structured use-case blocks.\n- Any use case is missing one or more required components.\n- Use cases are repetitive, generic, or not grounded in `{{USER_INPUT}}`.\n- Alternatives/frequency/consideration-time fields are vague or non-actionable.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/User Research/Customer insights extraction from interview transcript using JTBD framework.md",
      "title": "Customer insights extraction from interview transcript using JTBD framework",
      "category": "User Research",
      "tags": [
        "user-research",
        "interviews",
        "jtbd"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{INTERVIEW_TRANSCRIPT}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Customer insights extraction from interview transcript using JTBD framework.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Analyze `{{INTERVIEW_TRANSCRIPT}}` using JTBD forces:\n- Pushes.\n- Pulls.\n- Habits.\n- Anxieties.\n- Extract force statements with required phrasing:\n- Pushes and Habits as `When...` statements.\n- Pulls as `So I can...` / `So I don't...` statements.\n- Anxieties as concerns/questions.\n- Synthesize decision dynamics including:\n- Decision criteria.\n- Trade-offs interviewee accepts.\n- Functional, social, and emotional priorities.\n- Ground all outputs in transcript evidence and state assumptions only when necessary.\n\nFORMAT\nReturn exactly this structure:\n\n<analysis>\n<context>\n[Briefly describe the interviewee's current situation, job, and challenges]\n</context>\n\n<pushes>\n[List the identified \"When...\" statements for Pushes]\n</pushes>\n\n<pulls>\n[List the identified \"So I can...\" or \"So I don't...\" statements for Pulls]\n</pulls>\n\n<habits>\n[List the identified \"When...\" statements for Habits]\n</habits>\n\n<anxieties>\n[List the identified questions or statements of concern for Anxieties]\n</anxieties>\n\n<insights>\n[Provide a summary of your insights about the interviewee's decision-making process]\n</insights>\n</analysis>\n\nFAILURE\n- Any required section in `<analysis>` is missing or materially incomplete.\n- JTBD force phrasing rules are not followed (`When...`, `So I can.../So I don't...`, anxiety concerns).\n- Insights do not cover decision criteria, trade-offs, and functional/social/emotional drivers.\n- Statements are generic or not grounded in transcript evidence.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/User Research/Data-driven research plans from leadership intuition.md",
      "title": "Data-driven research plans from leadership intuition",
      "category": "User Research",
      "tags": [
        "user-research",
        "research-planning",
        "product-strategy"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{COMPANY_CONTEXT}}\n- {{INTUITION}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Data-driven research plans from leadership intuition.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Convert `{{INTUITION}}` into an evidence-based research plan grounded in `{{COMPANY_CONTEXT}}`.\n- Include:\n- Intuition summary with explicit bias/assumption check.\n- Prioritized key assumptions affecting feature success.\n- 3-5 measurable research objectives tied to assumptions.\n- Mixed quantitative + qualitative methods with rationale per objective.\n- Validation/refutation success metrics aligned to business goals.\n- Risks/challenges with mitigation strategies.\n- Realistic milestone-based timeline.\n- Keep analysis objective and decision-oriented (validate, refute, or partially support intuition).\n\nFORMAT\nReturn exactly this structure:\n\n<research_plan>\n1. Executive Summary: [brief decision-oriented summary]\n2. Analysis of Intuition: [key points + potential biases/assumptions]\n3. Key Assumptions: [prioritized assumptions]\n4. Research Objectives: [3-5 measurable objectives]\n5. Research Methods: [mixed methods + why each fits]\n6. Success Metrics: [clear validation/refutation thresholds]\n7. Potential Challenges and Mitigation Strategies: [risk -> mitigation]\n8. Proposed Timeline: [milestones and duration]\n9. Conclusion: [how findings will inform go/no-go or iteration decisions]\n</research_plan>\n\nFAILURE\n- `<research_plan>` schema is missing, malformed, or materially incomplete.\n- Research objectives are not measurable or not tied to key assumptions.\n- Methods do not include both quantitative and qualitative approaches (unless explicitly justified by context).\n- Success metrics are vague and lack decision thresholds.\n- Timeline lacks milestones or is not feasible for proposed methods.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/User Research/Easy signal identification from product assumption.md",
      "title": "Easy signal identification from product assumption",
      "category": "User Research",
      "tags": [
        "user-research",
        "assumptions",
        "validation"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{ASSUMPTION}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Easy signal identification from product assumption.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Design an early, efficient validation signal for `{{ASSUMPTION}}` (`We believe that ...`).\n- Output must be plain text only: no XML/HTML tags, no code fences.\n- Use optional context if provided (segment, function, stage, constraints, assets/access, time/budget); if missing, infer minimally and note in summary.\n- Internally classify assumption lens (Desirability / Feasibility / Viability / Usability) and choose methods accordingly.\n- Apply suitability rules:\n- Enterprise/B2B with procurement/security: favor interviews, LOIs, security dry-runs, demos, ROI/TCO checks, RFP/API alignment; avoid fake-door/consumer funnel tactics.\n- SMB SaaS: favor discovery calls, lightweight trial/offer tests, POC requests, list tests, analytics.\n- Consumer: favor ad intent, waitlist conversion, community/panel, preorders, competitor-behavior proxies.\n- Regulated contexts: favor standards mapping, SME/regulatory preflight, de-identified/synthetic data; avoid sensitive-data collection without approvals.\n- Feasibility assumptions: favor spikes, benchmarks, vendor/data audits over user-facing tests where unnecessary.\n- Quality bar for selected signal:\n- Early (idea/prototype viable), cheap, attributable, decisive (quantified threshold), context-suitable, and ethical/compliant.\n- Provide exactly three sections in this order: `SCRATCHPAD`, `EFFICIENT SIGNAL`, `SUMMARY`.\n\nFORMAT\nReturn exactly this structure:\n\nSCRATCHPAD\n- [Signal name] — [positive evidence] — [quick capture method] — [context suitability]\n- [At least 5 total lines]\n\nEFFICIENT SIGNAL\nSignal description: [clear signal]\nMethod: [minimal-step approach]\nSuitability: [why this fits context]\nEarliest stage: [Idea | Prototype | Alpha | Beta]\nParticipants/sample: [who/how many]\nTimebox & cost: [duration and estimate]\nSuccess threshold: [quantified pass/fail criterion]\nData captured: [metrics/notes/artifacts]\nRisks/ethics: [risks and mitigations]\nNext evidence rung: [single next step if positive]\n\nSUMMARY\n[3-5 sentences restating the assumption, diagnostic lens, rationale for chosen signal, and key excluded options]\n\nFAILURE\n- Output is not plain text or includes XML/HTML/code fences.\n- Missing required sections or wrong section order (`SCRATCHPAD`, `EFFICIENT SIGNAL`, `SUMMARY`).\n- `SCRATCHPAD` has fewer than 5 distinct signals.\n- `EFFICIENT SIGNAL` misses any required line or lacks quantified success threshold.\n- Selected method violates suitability/ethics constraints for the given context.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/User Research/Effective customer interview guides for any topic.md",
      "title": "Effective customer interview guides for any topic",
      "category": "User Research",
      "tags": [
        "user-research",
        "interviews",
        "discussion-guide"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{TOPIC}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Effective customer interview guides for any topic.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Create a comprehensive customer interview discussion guide for `{{TOPIC}}` to support feature-development insights.\n- Internally analyze topic components, interview priorities, and interview flow before writing the final guide.\n- Build sections in this order:\n- Introduction and warm-up.\n- Current situation and workflow.\n- Challenges and pain points.\n- Desired outcomes and goals.\n- Exploration of potential solutions.\n- Wrap-up and next steps.\n- Use best practices from Mom Test and Continuous Discovery Habits:\n- Open-ended, non-leading, behavior-based questions.\n- Focus on past experiences over hypotheticals.\n- Prioritize highest-value questions first in each section.\n- Use friendly professional tone, numbered questions, and optional interviewer prompts in `[brackets]`.\n- Output only the final `<discussion_guide>`; do not include analysis/thinking notes.\n\nFORMAT\nReturn exactly this structure:\n\n<discussion_guide>\n[Brief introduction for the interviewer, explaining the purpose of the interview and key points to remember]\n\n1. Introduction and Warm-up\n   1.1. [Question]\n   1.2. [Question]\n   [Additional questions as needed]\n\n2. Current Situation and Workflow\n   2.1. [Question]\n   2.2. [Question]\n   [Additional questions as needed]\n\n3. Challenges and Pain Points\n   3.1. [Question]\n   3.2. [Question]\n   [Additional questions as needed]\n\n4. Desired Outcomes and Goals\n   4.1. [Question]\n   4.2. [Question]\n   [Additional questions as needed]\n\n5. Exploration of Potential Solutions\n   5.1. [Question]\n   5.2. [Question]\n   [Additional questions as needed]\n\n6. Wrap-up and Next Steps\n   6.1. [Question]\n   6.2. [Question]\n   [Additional questions as needed]\n</discussion_guide>\n\nFAILURE\n- `<discussion_guide>` schema is missing, malformed, or materially incomplete.\n- Required sections are missing or question numbering/order is inconsistent.\n- Questions are leading, hypothetical-first, or not behavior-based.\n- Questions are not prioritized by importance within each section.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/User Research/Empathy maps.md",
      "title": "Empathy maps",
      "category": "User Research",
      "tags": [
        "user-research",
        "empathy-map",
        "personas"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{AUDIENCE}}\n- {{TOPIC}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Empathy maps.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Build a detailed empathy map for `{{AUDIENCE}}` in relation to `{{TOPIC}}`.\n- Include all eight categories:\n- Thinks\n- Feels\n- Says\n- Does\n- Sees\n- Hears\n- Pains\n- Goals\n- For each category, provide 3-5 numbered insights that are specific, non-redundant, and behaviorally meaningful.\n- Prioritize depth over surface-level statements, including motivations, fears, desires, social influences, and decision drivers where relevant.\n- End with a concise summary of key takeaways and implications.\n\nFORMAT\nReturn exactly this structure:\n\n<empathy_map>\n<thinks>\n1. [Insight]\n2. [Insight]\n3. [Insight]\n</thinks>\n\n<feels>\n1. [Insight]\n2. [Insight]\n3. [Insight]\n</feels>\n\n<says>\n1. [Insight]\n2. [Insight]\n3. [Insight]\n</says>\n\n<does>\n1. [Insight]\n2. [Insight]\n3. [Insight]\n</does>\n\n<sees>\n1. [Insight]\n2. [Insight]\n3. [Insight]\n</sees>\n\n<hears>\n1. [Insight]\n2. [Insight]\n3. [Insight]\n</hears>\n\n<pains>\n1. [Insight]\n2. [Insight]\n3. [Insight]\n</pains>\n\n<goals>\n1. [Insight]\n2. [Insight]\n3. [Insight]\n</goals>\n\n<summary>\n[Brief key-takeaways and implications]\n</summary>\n</empathy_map>\n\nFAILURE\n- `<empathy_map>` wrapper or any required category/summary tag is missing or malformed.\n- Any category has fewer than 3 insights.\n- Insights are generic, repetitive across categories, or not tied to `{{AUDIENCE}}` and `{{TOPIC}}`.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/User Research/Fragmented user research synthesis into coherent insights.md",
      "title": "Fragmented user research synthesis into coherent insights",
      "category": "User Research",
      "tags": [
        "user-research",
        "synthesis",
        "insights"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{RESEARCH_INPUTS}}\n- {{PRODUCT_CONTEXT}}\n- {{DESIGN_QUESTIONS}}\n- {{CURRENT_ASSUMPTIONS}}\n- {{BUSINESS_GOALS}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Fragmented user research synthesis into coherent insights.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Synthesize fragmented research inputs into coherent, evidence-based insights that inform design and product decisions.\n- Use the provided inputs:\n- `{{RESEARCH_INPUTS}}`\n- `{{PRODUCT_CONTEXT}}`\n- `{{DESIGN_QUESTIONS}}`\n- `{{CURRENT_ASSUMPTIONS}}`\n- `{{BUSINESS_GOALS}}`\n- Perform synthesis rigorously:\n- Inventory and assess source quality/coverage.\n- Extract coded observations (quotes, behaviors, themes, segment/context metadata).\n- Identify cross-source patterns and contradictions.\n- Assign confidence levels with explicit rationale.\n- Map insights to JTBD and user-needs hierarchy.\n- Link insights directly to design questions and actionable recommendations.\n- Identify research gaps, unresolved assumptions, and prioritized follow-up research.\n- Keep evidence traceable, avoid over-generalization, and state assumptions/uncertainties explicitly.\n\nFORMAT\nReturn exactly this structure:\n\n<research_synthesis>\n<input_inventory>\n**Data Sources Summary:**\n- User interviews: [X participants] covering [topics, user segments, dates]\n- Support tickets: [Y tickets] from [date range] about [primary themes]\n- NPS feedback: [Z responses] with [average score] discussing [key topics]\n- Usage analytics: [data range, key metrics, user actions analyzed]\n- Feature requests: [count] requests across [platforms/sources]\n- Usability tests: [sessions count] testing [specific flows or features]\n- Survey data: [respondents count] on [topics covered]\n- Anecdotal feedback: [source count] from [stakeholders, channels]\n- Session recordings: [count] sessions showing [behaviors]\n- Other sources: [specify any additional data]\n\n**Data Quality Assessment:**\n- Time range: [how recent is this data?]\n- User segment coverage: [which personas/segments are represented?]\n- Sample size adequacy: [sufficient for confidence in findings?]\n- Potential bias: [what perspectives might be over/under-represented?]\n- Data completeness: [what's missing or sparse?]\n</input_inventory>\n\n<key_insights>\n<insight_1>\n**Insight Statement:**\n[One clear, specific sentence stating what you learned about users]\n\n**Evidence:**\n- User interviews: \"[verbatim quote]\" (Participant X, [segment])\n- Support tickets: [Y tickets] report \"[specific issue]\" with keywords: [terms]\n- NPS feedback: \"[example comment]\" (common theme in Z% of detractor responses)\n- Analytics data: [X% of users] exhibit [specific behavior], [frequency/context]\n- Additional evidence: [any other supporting data points]\n\n**Confidence Level:** High / Medium / Low\n**Rationale for Confidence:** [Why you assigned this confidence level]\n\n**User Segments Affected:**\n- [Segment 1]: [how this manifests for them]\n- [Segment 2]: [how this manifests for them]\n\n**Jobs-to-be-Done Connection:**\n[Which job is this insight related to? How does it help or hinder job completion?]\n\n**Design Implications:**\n- Consider: [specific design approach this suggests]\n- Avoid: [what this insight argues against]\n- Prioritize: [which aspect of the experience to focus on]\n- Measure: [how to validate design addressed this insight]\n\n**Related Patterns:**\n[Which other insights connect to this? How do they reinforce or complicate each other?]\n\n**Business Impact:**\n[How does addressing this insight connect to business goals or metrics?]\n</insight_1>\n\n<insight_2>\n[Repeat the full structure for 5-10 key insights, maintaining consistent depth and evidence rigor]\n</insight_2>\n\n<insight_3>\n[Continue for all major insights...]\n</insight_3>\n</key_insights>\n\n<conflicting_signals>\n**Conflict 1:**\n- Signal A: [what one source or segment indicates]\n- Signal B: [what contradicts this]\n- Possible explanations:\n  * [Explanation 1: e.g., different user segments with different needs]\n  * [Explanation 2: e.g., stated preference vs. actual behavior]\n  * [Explanation 3: e.g., context-dependent variation]\n- Recommended resolution: [What research or analysis would clarify this?]\n- Design strategy given conflict: [How to proceed despite uncertainty?]\n\n**Conflict 2:**\n[Repeat structure for each major contradiction in the data]\n\n**Synthesis:**\n[What do these conflicts reveal about user diversity, product complexity, or research gaps?]\n</conflicting_signals>\n\n<insight_mapping_to_design_questions>\n**Question 1:** [Restate the first design question]\n- **Answer based on research:** [What the data tells you]\n- **Supporting insights:** [Which insights from above inform this answer]\n- **Confidence level:** High / Medium / Low\n- **Caveats and limitations:** [What qualifies or nuances this answer]\n- **What we still don't know:** [Gaps specific to this question]\n- **Recommended action:** [What to design/test/research next]\n\n**Question 2:** [Restate the second design question]\n[Repeat structure for each design question provided]\n\n**New Questions Surfaced:**\n[Design questions that emerged from the research but weren't originally asked]\n</insight_mapping_to_design_questions>\n\n<user_needs_hierarchy>\n<critical_needs>\n**Must-Have Needs (Strong Evidence, High Impact):**\n1. [Need 1]: [description]\n   - Evidence: [cross-source validation]\n   - If unmet: [severe user/business consequence]\n   - Current state: [how well is this met today?]\n\n2. [Need 2]: [description]\n   [Repeat structure for 3-5 critical needs]\n</critical_needs>\n\n<important_needs>\n**Should-Have Needs (Moderate Evidence, Meaningful Impact):**\n1. [Need 1]: [description]\n   - Evidence: [validation from 1-2 strong sources]\n   - If unmet: [moderate user friction or business impact]\n   - Current state: [how well is this met today?]\n\n2. [Need 2]: [description]\n   [Repeat for 5-8 important needs]\n</important_needs>\n\n<nice_to_have>\n**Nice-to-Have Needs (Weak Signal, Low/Uncertain Impact):**\n1. [Need 1]: [description]\n   - Evidence: [limited mentions or single source]\n   - Potential value: [why this might matter despite weak signal]\n   - Validation needed: [how to test if this is actually important]\n\n2. [Need 2]: [description]\n   [Repeat for 3-5 nice-to-have needs]\n</nice_to_have>\n\n<needs_by_segment>\n**Segment-Specific Needs:**\n- [Segment A]: [unique needs not shared by other segments]\n- [Segment B]: [unique needs not shared by other segments]\n- [Universal needs]: [needs expressed across all segments]\n</needs_by_segment>\n</user_needs_hierarchy>\n\n<behavioral_patterns>\n**Current Workflows and Workarounds:**\n[Describe how users actually accomplish tasks today, including inefficient or creative workarounds that reveal unmet needs]\n\n**Decision-Making Patterns:**\n[How users make choices within the product, what information they seek, what causes hesitation or confidence]\n\n**Pain Point Triggers:**\n[Specific circumstances, contexts, or actions that consistently lead to user frustration]\n\n**Success Patterns:**\n[When and how users successfully achieve their goals, what enables their success]\n\n**Usage Context and Frequency:**\n[When, where, why, and how often users engage with the product or specific features]\n\n**Adoption and Learning Patterns:**\n[How users onboard themselves, what helps or hinders learning, common confusion points]\n\n**Abandonment and Recovery Patterns:**\n[What causes users to give up, what brings them back, how they recover from errors]\n\n**Cross-Tool Workflows:**\n[How users combine your product with other tools, what gaps force tool-switching]\n</behavioral_patterns>\n\n<jobs_to_be_done>\n**Primary Functional Jobs:**\n1. [Job]: When [situation], I want to [motivation], so I can [expected outcome]\n   - Evidence: [how research revealed this job]\n   - Current obstacles: [what prevents job completion]\n   - Success criteria: [how users define successful job completion]\n\n2. [Job]: [Repeat structure for 3-5 primary jobs]\n\n**Emotional Jobs:**\n- [Feel]: [emotion users want to feel, e.g., \"feel confident in my decisions\"]\n- [Avoid]: [emotion users want to avoid, e.g., \"avoid feeling overwhelmed\"]\n- Evidence: [quotes, observations, sentiment indicators]\n\n**Social Jobs:**\n- [Perception]: [how users want to be seen, e.g., \"be perceived as data-driven\"]\n- [Context]: [social situations where product use matters]\n- Evidence: [research indicators of social motivations]\n\n**Related Jobs in the Consumption Chain:**\n- Before main job: [how users discover, evaluate, and choose the product]\n- After main job: [how users share, report, or build on outcomes]\n- Maintenance jobs: [ongoing tasks to keep getting value]\n</jobs_to_be_done>\n\n<research_gaps>\n<unanswered_questions>\n**Critical Unknowns (Blocking Design Decisions):**\n1. [Question]: [why this matters for design]\n2. [Question]: [why this matters for design]\n3. [Question]: [why this matters for design]\n\n**Important Unknowns (Would Significantly Inform Design):**\n1. [Question]: [how this would help]\n2. [Question]: [how this would help]\n\n**Curiosities (Interesting But Not Urgent):**\n1. [Question]: [potential value]\n2. [Question]: [potential value]\n</unanswered_questions>\n\n<recommended_research>\n**Research Activity 1:**\n- **Method:** [interviews / usability testing / survey / analytics deep-dive / diary study / etc.]\n- **Target participants:** [which user segments, how many, recruitment criteria]\n- **Key questions to answer:** [specific questions this research would resolve]\n- **Expected outcomes:** [what you'll learn and how it informs design]\n- **Effort estimate:** [time and resources required]\n- **Priority:** High / Medium / Low - [rationale]\n\n**Research Activity 2:**\n[Repeat structure for 3-5 recommended research activities, prioritized by impact and urgency]\n</recommended_research>\n\n<assumptions_to_validate>\n**Design Assumptions:**\n1. [Assumption about user behavior or preferences]: Currently [validated / unvalidated / contradicted] by research\n2. [Assumption about priorities or needs]: Currently [status]\n3. [Assumption about technical or business constraints]: Currently [status]\n\n**Team Assumptions:**\n[Assumptions stakeholders or team members hold that aren't supported by data—list with gentle evidence-based reframing]\n\n**Testing Strategy:**\n[How to quickly validate or invalidate the most critical assumptions through lightweight tests]\n</assumptions_to_validate>\n</research_gaps>\n\n<actionable_recommendations>\n**Priority 1 Recommendations (Supported by High-Confidence Insights):**\n1. [Specific design action]: [rationale tied to insight X, Y, Z]\n   - Expected impact: [user and business outcomes]\n   - Success metrics: [how to measure if this worked]\n\n2. [Specific design action]: [rationale tied to insights]\n   [Repeat for 3-5 top-priority recommendations]\n\n**Priority 2 Recommendations (Supported by Medium-Confidence Insights):**\n1. [Specific design action]: [rationale]\n   [Repeat for 5-7 secondary recommendations]\n\n**Quick Wins (Low Effort, Clear User Value):**\n1. [Specific design action]: [why this is easy and valuable]\n   [Repeat for 3-5 quick wins]\n\n**Strategic Bets (Lower Confidence, High Potential):**\n1. [Specific design action]: [why worth exploring despite uncertainty]\n   - Validation approach: [how to test before full commitment]\n   [Repeat for 2-3 strategic bets]\n\n**Do Not Pursue:**\n[Features, changes, or directions that research argues against, with rationale]\n</actionable_recommendations>\n\n<one_page_summary>\n**Executive Summary**\n\n**What We Learned:**\n[2-3 sentences capturing the most important insights from the research]\n\n**User Needs Priority:**\nUsers critically need [top need], strongly want [second need], and would appreciate [third need]. The evidence is strongest for [insight area] and weakest for [insight area requiring validation].\n\n**Key Behavioral Patterns:**\n[1-2 sentences on how users actually behave vs. what we might have assumed]\n\n**Design Implications:**\nThe research strongly supports [recommended direction 1] and [recommended direction 2], while arguing against [current assumption or planned direction]. We should prioritize [specific user segment or job-to-be-done] because [evidence-based rationale].\n\n**Critical Unknowns:**\nWe still need to understand [key gap 1] and [key gap 2] through [recommended research method].\n\n**Recommended Next Steps:**\n1. [Immediate action based on high-confidence insights]\n2. [Design exploration for medium-confidence opportunities]\n3. [Targeted research to fill critical gaps]\n\n**Business Impact:**\nAddressing these insights is expected to improve [business metric] by [directional estimate] because [user behavior change expected].\n\n[Total: 250-350 words]\n</one_page_summary>\n</research_synthesis>\n\nFAILURE\n- Any required section in `<research_synthesis>` is missing or materially incomplete.\n- Insights are not supported by cross-source evidence or confidence rationale.\n- Contradictions are ignored or not addressed with a resolution approach.\n- Recommendations are not prioritized or not linked to synthesized insights/business goals.\n- Research gaps and assumption validation plan are missing or non-specific.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/User Research/Ideal Customer Profile (ICP) representative for X product.md",
      "title": "Ideal Customer Profile (ICP) representative for X product",
      "category": "User Research",
      "tags": [
        "user-research",
        "icp",
        "personas"
      ],
      "content": "INPUTS\n<provided_inputs>\n- {{PRODUCT_NAME}}\n- {{ICP_PROFILE}}\n- {{PM_QUESTION}}\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Ideal Customer Profile (ICP) representative for X product.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Answer `{{PM_QUESTION}}` as the ICP voice for `{{PRODUCT_NAME}}`, using `{{ICP_PROFILE}}` as the source of truth.\n- Ground responses in specific, first-person, concrete experiences and observable behavior.\n- Prefer recent, timestamped examples and workflow context (what happened, where, with which tools, and outcome).\n- For hypothetical/aggregate questions, redirect to concrete experienced examples; do not generalize to all users.\n- If experience is missing, explicitly state \"I don't know from direct experience\" and explain the limit.\n- Do not invent usage events, feature exposure, or claims not supported by provided context.\n- Focus on actionable product feedback: what worked, what failed, impact, and why it matters.\n\nFORMAT\nReturn exactly this structure:\n\nICP Response\n\nQuestion\n[Restate `{{PM_QUESTION}}` in one line]\n\nRecent Real Experiences\n- [Specific instance with timing/context]\n- [Specific instance with timing/context]\n\nWhat Worked\n- [Concrete behavior/outcome and why]\n\nWhat Didn't Work\n- [Concrete friction/failure and impact]\n\nWorkflow Context\n- [Step-by-step summary of how task was done in practice]\n\nRedirect (if question is hypothetical/aggregate)\n- [Short first-person redirection to real experience]\n\nConfidence & Limits\n- Confidence: [High/Medium/Low]\n- Limits: [What is unknown or not directly experienced]\n\nActionable Takeaway for PM\n- [Specific implication for product decision]\n\nFAILURE\n- Any required section is missing or materially incomplete.\n- Response is hypothetical, generic, or not rooted in provided ICP context.\n- Claims are made without concrete experience examples or stated limits.\n- Response speaks for all users instead of first-person ICP perspective.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/User Research/Interactive intake for OST inputs.md",
      "title": "Interactive intake for OST inputs",
      "category": "User Research",
      "tags": [
        "user-research",
        "ost",
        "continuous-discovery"
      ],
      "content": "INPUTS\n<provided_inputs>\n- [No explicit variables declared; use provided context.]\n</provided_inputs>\n\nGOAL\nProduce a high-quality deliverable for: Interactive intake for OST inputs.\nSuccess metric:\n- Completes all required tasks and decision logic from the prompt instructions.\n- Output is specific, evidence-based, and actionable.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and clearly state assumptions when information is missing.\n- Do not skip required analysis steps, sections, or validation logic.\n- Keep recommendations/outputs grounded in the input context; avoid generic filler.\n- Act as an intake orchestrator for downstream OST inputs.\n- Parse existing user-provided context first, then ask only missing critical questions.\n- Collect and normalize exactly four variables:\n- `{{business_outcome}}`: one concise, outcome-focused sentence (no solution wording).\n- `{{journey_nodes_as_list}}`: JSON array of distinct journey moments (not features).\n- `{{interview_transcripts_or_story_snippets}}`: markdown snippets with attribution and timestamps when available.\n- `{{constraints_or_principles}}`: short markdown list/sentence or `None stated`.\n- Apply quality guards:\n- Reframe solution-flavored outcomes into measurable outcomes.\n- Rephrase feature-like nodes into moments in time.\n- Add minimal attribution labels when transcript context is sparse.\n- Stop only when all four fields are present, clear, distinct, normalized, and confirmed.\n\nFORMAT\nReturn exactly this structure:\n\n{{business_outcome}}: [one concise, outcome-focused sentence]\n\n{{journey_nodes_as_list}}: [\"[Moment 1]\", \"[Moment 2]\", \"[Moment 3]\"]\n\n{{interview_transcripts_or_story_snippets}}:\n[markdown transcript/snippets with speaker labels and timestamps if available]\n\n{{constraints_or_principles}}:\n[short markdown list or sentence; if none provided, write \"None stated\"]\n\nFAILURE\n- Any of the four required variables is missing or malformed.\n- `{{business_outcome}}` is solution-flavored or not measurable/outcome-oriented.\n- `{{journey_nodes_as_list}}` is not valid JSON array syntax or contains features instead of moments.\n- Interview material lacks usable attribution/context when source data allows it.\n- Constraints field is omitted instead of explicitly set to `None stated`.\n- Claims are generic or not grounded in provided inputs.\n- Assumptions are used but not explicitly stated."
    },
    {
      "path": "Prompts/User Research/Opportunity Solution Tree from input.md",
      "title": "Opportunity Solution Tree from input",
      "category": "User Research",
      "tags": [
        "user-research",
        "ost",
        "continuous-discovery"
      ],
      "content": "INPUTS\n<provided_inputs>\n- `{{business_outcome}}`: The business outcome the OST must support.\n- `{{journey_nodes_as_list}}`: Ordered list of journey moments (for example: `[\"Add to calendar\", \"Edit calendar\", \"Review calendar\"]`).\n- `{{interview_transcripts_or_story_snippets}}`: Interview material with speaker labels and timestamps when available.\n- `{{constraints_or_principles}}` (optional): Guardrails, principles, or constraints to respect.\n</provided_inputs>\n\nGOAL\nTransform interview evidence into a Teresa Torres-aligned Opportunity Solution Tree with distinct, properly nested opportunity nodes by journey moment.\nSuccess metric:\n- Output includes all required parts (A-E) with complete, internally consistent references.\n- Opportunity nodes are user-need statements (not solutions), evidence-linked, and structurally valid.\n- Prioritization is computable and traceable to interview evidence and `{{business_outcome}}`.\n\nCONSTRAINTS\n- Use only provided inputs; if data is missing or ambiguous, state assumptions in Part E.\n- Phrase opportunities from the end-user perspective.\n- Assign each opportunity to exactly one primary moment from `{{journey_nodes_as_list}}`; if needed, list secondary moments in `alt_moments`.\n- Enforce sibling distinctness: if two siblings cannot be pursued independently, merge or reframe.\n- Enforce parent-child logic: solving a child must partially solve its parent.\n- Remove generic parents that have only one specific child.\n- Collapse duplicates into the clearest phrasing and preserve traceability.\n- Keep opportunities specific when supported by quotes; keep general opportunities only when they organize multiple specific children.\n- Include only opportunity nodes in the OST (no solutions).\n- Preserve short supporting quotes and avoid introducing new facts not present in inputs.\n- Use stable IDs and ensure all references resolve (`parent_id`, `duplicates_of`, `traceability`).\n\nFORMAT\nReturn all sections below in this exact order.\n\nPart A - Opportunity Inventory (Markdown Table)\n- Include both parent and leaf opportunities.\n- Use exactly these columns:\n`| id | moment | opportunity_reframed (user-need) | parent_id | duplicates_of | representative_quotes | frequency_count | confidence (low/med/high) | alt_moments | notes/reframe_rationale |`\n- `duplicates_of` is blank unless collapsed into another ID.\n\nPart B - Structured OST (Strict JSON in `<ost_json>` tags)\n- Output must be wrapped exactly as:\n`<ost_json>`\n`{ ... }`\n`</ost_json>`\n- JSON schema:\n```json\n{\n  \"outcome\": \"{{business_outcome}}\",\n  \"moments\": [\n    {\n      \"moment\": \"<journey moment>\",\n      \"tree\": [\n        {\n          \"id\": \"A0\",\n          \"title\": \"<user need>\",\n          \"type\": \"opportunity\",\n          \"children\": []\n        }\n      ]\n    }\n  ],\n  \"traceability\": {\n    \"A0\": {\n      \"quotes\": [\"...\"],\n      \"frequency_count\": 1,\n      \"confidence\": \"low\"\n    }\n  }\n}\n```\n- Every node must include `id`, `title`, `type`, `children`.\n- `type` must always be `\"opportunity\"`.\n- Top-level moments must come from `{{journey_nodes_as_list}}`.\n- JSON must be valid and parseable.\n\nPart C - Markdown Tree View (Human-readable)\n- For each moment, render an indented opportunity tree:\n`## <moment>`\n`- <parent opportunity>`\n`  - <child opportunity>`\n`    - <grandchild opportunity>`\n- Include opportunities only (no solutions).\n\nPart D - Prioritized Leaf Backlog (Markdown Table)\n- Include only leaf opportunities.\n- Use exactly these columns:\n`| id | moment | leaf_opportunity | impact (1-5) | frequency (1-5) | alignment_to_outcome (1-5) | priority_score | rationale |`\n- Compute `priority_score = impact * frequency * alignment_to_outcome`.\n\nPart E - Assumptions & Open Questions\n- Include:\n- Uncertainties in placement/reframing.\n- Potential missing siblings to test in future interviews.\n- Ambiguities or contradictory evidence in quotes.\n- Any hypotheses not supported by current interview evidence.\n\nFAILURE\n- Any required part (A-E), required table column, or required JSON field is missing.\n- JSON is malformed, non-parseable, or violates required schema/rules.\n- Output includes solutions inside the OST opportunity tree.\n- Opportunities are generic/overlapping and fail distinctness or parent-child logic.\n- Claims are not traceable to interview evidence.\n- IDs or references are inconsistent/unresolved.\n- Priority scores are missing or incorrectly computed.\n- Assumptions/ambiguities exist but are not explicitly listed in Part E."
    },
    {
      "path": "Prompts/User Research/Problem framing before jumping to solutions.md",
      "title": "Problem framing before jumping to solutions",
      "category": "User Research",
      "tags": [
        "user-research",
        "problem-framing",
        "product-design"
      ],
      "content": "INPUTS\n<provided_inputs>\n- `{{PROPOSED_SOLUTION}}`: The proposed solution idea or concept.\n- `{{CONTEXT}}`: Product, user, business, and operational context related to the proposal.\n</provided_inputs>\n\nGOAL\nReorient teams from premature solution mode to rigorous, evidence-driven problem framing before solution design.\nSuccess metric:\n- The analysis diagnoses solution-jumping clearly and identifies assumptions, evidence, and risks.\n- The output defines a user-centered problem statement with measurable success criteria.\n- The output provides a concrete validation research plan and preserves collaborative team alignment.\n\nCONSTRAINTS\n- Use only provided inputs; if information is missing, state explicit assumptions.\n- Diagnose the proposed solution before prescribing alternatives.\n- Address all required analysis steps:\n- Identify solution-jumping (proposed solution, embedded assumptions, implied problem, evidence status).\n- Extract underlying problem (user need, JTBD, desired outcome, current state, constraints).\n- Challenge assumptions (validity, evidence, risk if wrong, validation method).\n- Frame a complete problem statement (who, where/when, impact, workarounds, success).\n- Provide alternative problem framings to widen exploration.\n- Propose pre-solution research to validate the problem.\n- Recommendations must be specific, testable, and grounded in `{{CONTEXT}}`.\n- Maintain a collaborative tone that frames validation as de-risking, not rejection.\n\nFORMAT\nReturn exactly this structure:\n\n<problem_framing_analysis>\n<solution_jumping_diagnosis>\n**Proposed Solution:**\n[Describe the solution being discussed]\n\n**Embedded Assumptions:**\n[List assumptions built into this solution:\n- Assumes users need X\n- Assumes current problem is Y\n- Assumes best approach is Z]\n\n**Implied Problem:**\n[What problem is this solution trying to solve?]\n\n**Evidence Status:**\n[What evidence exists that this is the right problem to solve? What's missing?]\n</solution_jumping_diagnosis>\n\n<underlying_problem_extraction>\n**User Need:**\n[What fundamental user need is being addressed?]\n\n**Job-to-be-Done:**\n[What job is the user trying to accomplish?]\n\n**Desired Outcome:**\n[What result does the user want to achieve?]\n\n**Current State:**\n[How do users accomplish this today? What goes wrong?]\n\n**Constraints:**\n[What limitations exist: technical, business, user, environmental?]\n</underlying_problem_extraction>\n\n<assumption_challenges>\n[For each key assumption, ask:\n- Assumption: [state it]\n- Is it validated? [Yes/No/Partially]\n- Evidence: [what supports or contradicts it]\n- Risk if wrong: [what happens if this assumption is false]\n- How to validate: [proposed test]]\n</assumption_challenges>\n\n<problem_statement>\n**Who:** [Specific user segment]\n\n**Experiences:** [Specific problem or friction]\n\n**When/Where:** [Context and triggers]\n\n**Impact:** [Consequence and severity]\n\n**Current Workarounds:** [What users do today]\n\n**Success Would Be:** [Measurable outcome]\n\n**Problem Statement:**\n[Complete: \"Users [who] struggle to [what] when [context] because [root cause], which leads to [impact]. Success would mean [outcome]\"]\n</problem_statement>\n\n<alternative_problem_framings>\n<framing_1>\n[Present alternative way to frame this problem that might lead to different solutions]\n</framing_1>\n\n<framing_2>\n[Present second alternative framing]\n</framing_2>\n\n<framing_3>\n[Present third alternative framing if applicable]\n</framing_3>\n</alternative_problem_framings>\n\n<validation_research>\n**Research Questions:**\n[List 5-7 questions that would validate the problem:\n- Do users actually experience this problem?\n- How frequently and severely?\n- What triggers it?\n- How do they currently cope?\n- What would \"solved\" look like to them?]\n\n**Proposed Method:**\n[Suggest appropriate research approach:\n- User interviews focused on problem space\n- Observational research of current workflows\n- Diary studies to capture problem in context\n- Analytics analysis of behavior patterns]\n\n**Success Criteria:**\n[What would confirm this is the right problem to solve?]\n\n**Timeline:**\n[How long would this research take?]\n</validation_research>\n\n<solution_divergence_plan>\n**Once Problem Is Validated:**\n\n**Divergence Questions:**\n[Questions to open up solution space:\n- How might we [solve aspect 1]?\n- What if [constraint] didn't exist?\n- How do other domains solve similar problems?\n- What would the ideal solution look like?]\n\n**Solution Criteria:**\n[What should any solution achieve? List must-haves and nice-to-haves]\n\n**Exploration Approach:**\n[Suggest how to explore solutions once problem is understood:\n- Competitive analysis\n- Analogous research\n- Design studio\n- Rapid prototyping]\n</solution_divergence_plan>\n\n<communication_strategy>\n**How to Redirect the Team:**\n[Suggest how to shift the conversation from solution to problem:\n- Acknowledge the solution thinking\n- Reframe as problem exploration\n- Show value of problem validation\n- Set timeline for problem then solution phases]\n\n**Draft Message:**\n[Provide a tactful message to the team explaining the value of problem framing]\n</communication_strategy>\n</problem_framing_analysis>\n\nFAILURE\n- Any required section/tag in `FORMAT` is missing, reordered, or materially incomplete.\n- Analysis skips core problem-framing steps (solution-jumping diagnosis, problem extraction, assumption challenge, validation plan).\n- Claims are generic, not evidence-linked, or not grounded in provided inputs.\n- Output proposes solutions before adequately framing/validating the problem.\n- Assumptions or uncertainties are used but not explicitly stated.\n- Tone is adversarial or dismissive rather than collaborative and de-risking."
    },
    {
      "path": "Prompts/User Research/Problem statement framing from conversation transcript.md",
      "title": "Problem statement framing from conversation transcript",
      "category": "User Research",
      "tags": [
        "user-research",
        "problem-framing",
        "transcripts"
      ],
      "content": "INPUTS\n<provided_inputs>\n- `{{SESSION_CONTEXT}}`: Conversation/session transcript and related context to analyze.\n</provided_inputs>\n\nGOAL\nConvert session context into a clear, empathetic, user-centered Problem Framing Canvas that stakeholders can use to align on the real problem before solutioning.\nSuccess metric:\n- The canvas accurately reflects transcript evidence and persona perspective.\n- The narrative captures need, barriers, root cause, and emotional impact.\n- The final problem statement is concise, actionable, and faithful to the input context.\n\nCONSTRAINTS\n- Use only `{{SESSION_CONTEXT}}`; if data is missing, state assumptions explicitly.\n- Perform all required analysis steps before writing the final canvas:\n- Analyze persona, pain points, desired outcomes, barriers, root cause, emotional impact, and contextual constraints.\n- Build a complete Problem Framing Narrative from the persona point of view.\n- Enumerate relevant context and constraints (for example: geographic, technological, temporal, demographic, operational).\n- Generate multiple candidate final statements internally, then select the strongest one.\n- Keep claims evidence-based and grounded in transcript details.\n- Final output must include only the finalized Problem Framing Canvas (no chain-of-thought, no extra sections).\n\nFORMAT\nReturn only this final Markdown structure:\n\n```markdown\n## Problem Framing Canvas\n\n### Problem Framing Narrative\n\nI am:\n- [Point 1]\n- [Point 2]\n- [Point 3]\n\nTrying to:\n- [Desired outcomes]\n\nBut:\n- [Barrier 1]\n- [Barrier 2]\n- [Barrier 3]\n\nBecause:\n- [Root cause]\n\nWhich makes me feel:\n- [Emotional impact]\n\n### Context & Constraints\n\n- [Factor 1]\n- [Factor 2]\n- [Factor 3]\n...\n\n### Final Problem Statement\n\n[Concise problem statement]\n```\n\nAdditional format rules:\n- Keep headings exactly as shown.\n- Maintain persona-first wording in the narrative.\n- Use concise bullet points and avoid generic filler.\n\nFAILURE\n- Output is not exactly a `Problem Framing Canvas` in the required Markdown structure.\n- Any required canvas section is missing or materially incomplete.\n- Narrative is not written from persona perspective.\n- Problem statement is vague, solution-biased, or not grounded in transcript evidence.\n- Context/constraints are generic or irrelevant to provided input.\n- Assumptions are required but not explicitly stated."
    },
    {
      "path": "Prompts/User Research/Product assumptions from core strategy inputs.md",
      "title": "Product assumptions from core strategy inputs",
      "category": "User Research",
      "tags": [
        "user-research",
        "assumptions",
        "product-strategy"
      ],
      "content": "INPUTS\n<provided_inputs>\n- `{{PRODUCT_DESCRIPTION}}`: Product concept, scope, and intended value.\n- `{{CORE_PROBLEM}}`: Core user/business problem the product addresses.\n- `{{TARGET_USER}}`: Primary target user segment(s).\n</provided_inputs>\n\nGOAL\nProduce a rigorous, testable assumption set underlying the product strategy across desirability, feasibility, viability, and usability.\nSuccess metric:\n- Assumptions are specific, falsifiable, and impact-aware.\n- Assumptions are non-duplicative across categories and grounded in provided inputs.\n- Output follows the required plain-text structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs and disciplined inference.\n- If any input is missing or vague, proceed with prudent defaults and note gaps only in `SUMMARY`.\n- Do not use XML, HTML, angle-bracket tags, or code fences in the model output.\n- Return only the required sections in the required order.\n- Create exactly four assumption categories in this order:\n- Desirability Assumptions\n- Feasibility Assumptions\n- Viability Assumptions\n- Usability Assumptions\n- Each category must contain at least 5 assumptions.\n- Each assumption must be one numbered item with exactly two labeled lines:\n- `Statement:` starts with `We believe that...`, is one idea only, specific/falsifiable, and max 35 words.\n- `Impact if wrong:` one concise sentence describing concrete consequence (adoption, cost, timeline, risk, or strategy).\n- Avoid repeating the same assumption across categories.\n- Include measurable thresholds, segments, conditions, or timeframes where possible.\n- Reflect relevant product-strategy realities (for example: compliance, integrations, data quality, reliability/SLOs, scalability, CAC/LTV, retention, pricing power, partner economics).\n\nFORMAT\nReturn plain text only, using exactly this section structure and order:\n\nASSUMPTIONS LIST\nDesirability Assumptions\n1.\nStatement: We believe that ...\nImpact if wrong: ...\n\n2.\nStatement: We believe that ...\nImpact if wrong: ...\n\n[at least 5 items]\n\nFeasibility Assumptions\n1.\nStatement: We believe that ...\nImpact if wrong: ...\n\n[at least 5 items]\n\nViability Assumptions\n1.\nStatement: We believe that ...\nImpact if wrong: ...\n\n[at least 5 items]\n\nUsability Assumptions\n1.\nStatement: We believe that ...\nImpact if wrong: ...\n\n[at least 5 items]\n\nSUMMARY\n- Key risk themes across the four categories.\n- Most critical assumptions to validate first.\n- Any missing/vague input gaps and explicit defaults used.\n\nFAILURE\n- Output contains anything other than `ASSUMPTIONS LIST` followed by `SUMMARY`.\n- Any category is missing, out of order, or has fewer than 5 assumptions.\n- Any assumption is missing either `Statement:` or `Impact if wrong:`.\n- Any `Statement:` does not start with `We believe that...`, exceeds 35 words, or contains multiple claims.\n- Assumptions are generic, non-falsifiable, duplicated across categories, or not grounded in provided inputs.\n- Missing/vague input handling is not explicitly documented in `SUMMARY`.\n- Output includes XML/HTML tags, angle-bracket tags, or code fences."
    },
    {
      "path": "Prompts/User Research/Product decision analysis from anthropological research insights.md",
      "title": "Product decision analysis from anthropological research insights",
      "category": "User Research",
      "tags": [
        "research",
        "anthropology",
        "product-strategy",
        "user-personas"
      ],
      "content": "INPUTS\n<provided_inputs>\n- `{{ROLE}}`: Professional role perspective to combine with anthropological analysis.\n- `{{USER_PERSONA}}`: The studied user group/persona.\n- `{{TOPIC}}`: Product decision or topic to evaluate.\n</provided_inputs>\n\nGOAL\nEvaluate a product decision through an anthropological lens grounded in deep understanding of a specific user group while maintaining objective analysis.\nSuccess metric:\n- Analysis covers all seven required dimensions of user-group fit and decision viability.\n- Findings are specific, behavior-grounded, and actionable for product decisions.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs; if details are missing, state assumptions explicitly.\n- Maintain third-person, objective analysis while reflecting deep empathy for the user group.\n- Address all required dimensions:\n1. Initial reactions\n2. Relevance to daily life/goals/challenges\n3. Adoption potential\n4. Barriers\n5. Opportunities\n6. Modifications\n7. Communication approach\n- Ground claims in plausible observed behavior patterns, routines, motivations, and constraints of `{{USER_PERSONA}}`.\n- Avoid generic advice; recommendations must tie directly to persona realities and `{{TOPIC}}`.\n- Do not output scratchpad or hidden reasoning.\n\nFORMAT\nReturn exactly this structure:\n\n<analysis>\n1. Initial Reactions: [Your insights here]\n2. Relevance: [Your insights here]\n3. Adoption Potential: [Your insights here]\n4. Barriers: [Your insights here]\n5. Opportunities: [Your insights here]\n6. Modifications: [Your insights here]\n7. Communication: [Your insights here]\n</analysis>\n\nFAILURE\n- Output is not in the required `<analysis>` schema with all seven numbered sections.\n- Any required dimension is missing, merged incorrectly, or materially incomplete.\n- Claims are generic and not grounded in `{{USER_PERSONA}}` behaviors/motivations or `{{TOPIC}}` context.\n- Analysis becomes purely subjective advocacy instead of objective, evidence-oriented framing.\n- Assumptions are required but not explicitly stated."
    },
    {
      "path": "Prompts/User Research/Proto-persona profiles from user research and market data.md",
      "title": "Proto-persona profiles from user research and market data",
      "category": "User Research",
      "tags": [
        "user-research",
        "personas",
        "ux"
      ],
      "content": "INPUTS\n<provided_inputs>\n- `{{USER_RESEARCH}}`: Interview notes, quotes, observations, transcripts.\n- `{{MARKET_DATA}}`: Segment size, competitors, market trends.\n- `{{BEHAVIORAL_INSIGHTS}}`: Analytics, JTBD signals, usage patterns.\n- `{{DEMOGRAPHICS}}`: Age, location, income, education, and related profile context.\n- `{{CONSTRAINTS}}` (optional): Industry, region, compliance, accessibility constraints.\n- `{{PREFERENCES}}` (optional): `tone`, `depth` (`brief|standard|deep`), `number_of_personas` (default `1`).\n</provided_inputs>\n\nGOAL\nSynthesize mixed research inputs into concise, evidence-linked proto-persona profile(s) ready for early product decisions and validation.\nSuccess metric:\n- Persona profiles are internally consistent and clearly distinguish evidence from assumptions.\n- Each profile includes confidence, explicit unknowns, and prioritized probing questions.\n- Output follows required markdown canvas structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs; if data is missing, write `TBD` and cover it in Probing Questions.\n- Extract concrete signals first (quotes, facts, metrics), then synthesize into pains/goals/behaviors.\n- Clearly mark each claim as evidence-based or assumption with confidence (`High|Med|Low`).\n- Use bracketed source tags (for example: `[UR#3]`, `[GA]`, `[MD]`) wherever evidence is cited.\n- Avoid demographic stereotyping; unsupported demographics must be `TBD` or explicit assumptions.\n- Ensure behaviors are observable and distinct from goals.\n- If `number_of_personas > 1`, output distinct personas.\n- Output markdown only; no JSON, XML, or HTML.\n- Keep each persona under 400 words unless `depth = deep`.\n\nFORMAT\n- Return one markdown code block per persona.\n- Inside each code block, render exactly this structure:\n\n```markdown\n# Proto Persona: {{Alliterative Name}}\n\n## Bio & Demographics\n- Age: {{x-y}}, Location: {{region/city}}, Education: {{...}}\n- Role/Status: {{job title or life stage}}\n- Income/Spending Power: {{range or TBD}}\n- Household/Partner Status: {{...}}\n- Digital/Channel Habits: {{top channels/devices}}\n- Leisure & Interests: {{...}}\n- Notable Constraints: {{time, budget, compliance, accessibility}}\n\n## Representative Quotes\n- \"{{quote}}\" - [{{source tag}}]\n- \"{{quote}}\" - [{{source tag}}]\n- \"{{quote}}\" - [{{source tag}}]\n\n## Pains\n- {{pain statement}} [evidence|assumption, {{confidence}}, {{source|TBD}}]\n- {{...}}\n\n## What They're Trying to Accomplish (Behaviors & JTBD)\n- {{job story or observed behavior}} [evidence|assumption, {{confidence}}, {{source|TBD}}]\n- {{...}}\n\n## Goals\n- {{goal}} [evidence|assumption, {{confidence}}, {{source|TBD}}]\n- {{...}}\n\n## Attitudes & Influences\n- **Decision-Making Authority:** {{buyer|user|champion|blocker|none}} [{{confidence}}]\n- **Decision Influencers:** {{roles/peers/communities}} [{{confidence}}]\n- **Beliefs & Attitudes:** {{heuristics, risk posture, trust signals}} [{{confidence}}]\n\n## Purchasing & Adoption Signals (Optional)\n- Triggers: {{events that start the search}}\n- Selection Criteria: {{top 3 decision criteria}}\n- Objections: {{anticipated blockers}}\n- Success Metrics: {{how they judge value}}\n\n## Accessibility & Inclusion (Optional)\n- Considerations: {{access, language, bandwidth, cognitive load}}\n\n## Evidence & Confidence Summary\n- Evidence Sources: {{list with counts, e.g., UR:6, GA:1, MD:2}}\n- Assumptions: {{key assumptions}}\n- Overall Confidence: {{High|Med|Low}} - {{1-2 sentence rationale}}\n\n## Probing Questions (Prioritized)\n1. {{highest-value unknown}}\n2. {{next unknown}}\n3. {{next unknown}}\n```\n\nFAILURE\n- Output is not markdown code block(s), or required persona section headings are missing.\n- `number_of_personas > 1` is requested but personas are not distinct or separated.\n- Quotes/sources do not support key pains, goals, or JTBD claims.\n- Claims are untagged (missing evidence/assumption + confidence + source markers).\n- `TBD`/low-confidence gaps are not reflected in prioritized probing questions.\n- Content exceeds 400 words per persona when `depth` is not `deep`.\n- Output includes JSON/XML/HTML or generic filler not grounded in provided inputs."
    },
    {
      "path": "Prompts/User Research/Raw interview transcript cleanup.md",
      "title": "Raw interview transcript cleanup",
      "category": "User Research",
      "tags": [
        "user-research",
        "interviews",
        "transcripts"
      ],
      "content": "INPUTS\n<provided_inputs>\n- `{{RAW_TRANSCRIPT}}`: Raw interview transcript with speaker turns.\n</provided_inputs>\n\nGOAL\nClean a raw interview transcript for readability while preserving original meaning, intent, and speaker voice.\nSuccess metric:\n- Transcript is easier to read and remains faithful to original content.\n- Speaker labels and conversational flow are preserved.\n- Output follows the required schema exactly.\n\nCONSTRAINTS\n- Use only the provided transcript content.\n- Make light edits only; do not summarize, reinterpret, or remove meaningful content.\n- Remove filler words, false starts, and redundant repetitions only when they do not change meaning.\n- Preserve each speaker's voice and tone; avoid over-formalizing casual language.\n- Keep original speaker labels at the beginning of each turn (for example: `Interviewer:`, `Interviewee:`).\n- Preserve unclear/inaudible markers exactly as given (for example: `[inaudible]`).\n- Correct punctuation and capitalization for readability.\n- Do not add commentary, analysis, or extra sections.\n\nFORMAT\nReturn exactly this structure:\n\n<edited_transcript>\n[Cleaned transcript text with original speaker labels and turn order preserved.]\n</edited_transcript>\n\nFAILURE\n- Output is not wrapped in `<edited_transcript>` tags.\n- Meaning, intent, or factual content is altered.\n- Speaker labels are removed, changed, or inconsistently applied.\n- Transcript is over-edited (excessive cuts, paraphrasing, or tone normalization).\n- Inaudible/unclear markers from source are removed or rewritten.\n- Extra sections, commentary, or metadata are included."
    },
    {
      "path": "Prompts/User Research/Realistic JTBD interview transcripts.md",
      "title": "Realistic JTBD interview transcripts",
      "category": "User Research",
      "tags": [
        "user-research",
        "jtbd",
        "interviews"
      ],
      "content": "INPUTS\n<provided_inputs>\n- `{{PRODUCT_TYPE}}`: Product category to explore.\n- `{{TARGET_AUDIENCE}}`: Core audience profile for the interview.\n- `{{NUM_PARTICIPANTS}}`: Number of participants to include in the transcript.\n</provided_inputs>\n\nGOAL\nGenerate a realistic multi-participant JTBD interview transcript that surfaces the four forces of progress (push, pull, anxiety, habit) through natural conversation.\nSuccess metric:\n- Transcript is realistic, exploratory, and participant-driven.\n- Conversation captures current behaviors, pain points, desired outcomes, switching concerns, and habits.\n- Output follows the required structure exactly.\n\nCONSTRAINTS\n- Use only provided inputs; if details are missing, state assumptions briefly in the handover.\n- Role-play both Product Designer and participants in a realistic dialogue.\n- Product Designer behavior must be:\n- Open-ended questioning.\n- Follow-up on ambiguity and interesting signals.\n- Encouraging elaboration.\n- Non-leading and solution-neutral.\n- Curious and empathetic tone.\n- Cover these conversation phases naturally:\n1. Introduction and warm-up.\n2. Current solutions and pain points.\n3. Desired outcomes and aspirations.\n4. Concerns and hesitations about change.\n5. Existing routines and habitual behaviors.\n- Ensure all participants contribute meaningfully.\n- Reveal the four JTBD forces implicitly through content, without naming them explicitly.\n\nFORMAT\nReturn exactly this structure:\n\n<transcript>\nProduct Designer: [Introduction and first question]\n\nParticipant 1: [Response]\n\nProduct Designer: [Follow-up question]\n\nParticipant 2: [Response]\n\n[Continue until all participants contribute and the conversation feels complete.]\n</transcript>\n\n<handover>\nThis concludes the interview transcript. What specific aspects of the conversation would you like me to elaborate on or analyze further?\n</handover>\n\nFAILURE\n- Output is missing either `<transcript>` or `<handover>`.\n- Transcript does not include the Product Designer plus the requested number of participants.\n- Conversation is generic, shallow, or fails to cover required interview phases.\n- Product Designer asks leading/solution-prescriptive questions.\n- Four JTBD force signals are not inferable from the dialogue.\n- Participants do not contribute meaningfully or are not differentiated.\n- Assumptions are required but not explicitly noted in handover."
    },
    {
      "path": "Prompts/User Research/Risky assumption prioritization for rapid validation.md",
      "title": "Risky assumption prioritization for rapid validation",
      "category": "User Research",
      "tags": [
        "user-research",
        "assumptions",
        "validation"
      ],
      "content": "INPUTS\n<provided_inputs>\n- `{{ASSUMPTIONS}}`: Plain-text assumption list (typically with Category, `Statement: We believe that...`, and `Impact if wrong:`).\n</provided_inputs>\n\nGOAL\nPrioritize assumptions by strategic risk using an Importance × Certainty model.\nSuccess metric:\n- Highest-risk assumptions are clearly ranked and justified.\n- Scoring is consistent and traceable to assumption impact/evidence quality.\n- Output follows strict plain-text structure exactly.\n\nCONSTRAINTS\n- Focus only on prioritization; do not include validation plans, experiments, or recommendations.\n- Use only provided assumptions; if Category is missing, infer one of:\n- Desirability\n- Feasibility\n- Viability\n- Usability\n- Normalize duplicates before scoring (keep strongest impact framing).\n- Score each assumption with:\n- Importance (1-5): business/strategy impact if false.\n- Certainty (1-5): strength of evidence assumption is true.\n- Risk score = `Importance * (6 - Certainty)`.\n- Use consistent scoring based on impact severity, blast radius, dependency risk, irreversibility/time sensitivity, and evidence quality.\n- Perform decomposition/self-critique internally; report only final outcomes.\n- Output must be plain text only (no XML/HTML tags, no code fences).\n\nFORMAT\nReturn exactly two sections in this order and nothing else:\n\nPRIORITIZATION\n2x2 Summary (counts): HI/LC: x; HI/HC: y; LI/LC: z; LI/HC: w\n\nTop Risks (HI/LC), ranked by Risk score (highest first). For each item, include exactly:\nAssumption: \"We believe that ...\" (verbatim)\nCategory: [Desirability | Feasibility | Viability | Usability]\nImportance: [1-5]\nCertainty: [1-5]\nRisk score: [number]\nRationale: [max 2 short bullets referencing severity, blast radius, dependency, irreversibility, or evidence quality]\n\nFull Ranked List: All assumptions sorted by Risk score (desc). Each line:\n[Rank]. [Category] - Importance:[x] Certainty:[y] Risk:[z] - \"We believe that ...\"\n\nQUALITY CHECK\n- 3-6 concise bullets summarizing self-critique outcomes (for example: duplicate merges, re-scored items, category balance, scoring ambiguities).\n- Do not include chain-of-thought or step-by-step internal reasoning.\n\nFAILURE\n- Output includes anything beyond the two required sections or wrong section order.\n- Output contains XML/HTML tags, angle-bracket wrappers, or code blocks.\n- Includes validation plans/recommendations instead of prioritization-only results.\n- Top Risks entries are missing required fields.\n- Risk formula is not applied consistently or rankings are not sorted by Risk score descending.\n- `Assumption` text is not preserved verbatim where required.\n- Quality check is missing, too short (<3 bullets), or exposes internal reasoning."
    },
    {
      "path": "Prompts/User Research/Robust experiment design from goals and systems.md",
      "title": "Robust experiment design from goals and systems",
      "category": "User Research",
      "tags": [
        "user-research",
        "experiments",
        "validation"
      ],
      "content": "INPUTS\n<provided_inputs>\n- `{{GOAL}}`: Outcome to achieve or measure.\n- `{{SYSTEM}}`: Context/environment where goal is pursued.\n- `{{EXPERIMENT_TEMPLATE}}` (optional): Required template for experiment design output.\n</provided_inputs>\n\nGOAL\nDesign a robust, factor-based experiment program that tests what drives the target goal within the specified system.\nSuccess metric:\n- Key causal factors are identified and explained.\n- Each factor has a testable experiment design with rigorous controls and measurement.\n- If a template is provided, the final design is adapted to that template without losing rigor.\n\nCONSTRAINTS\n- Use only provided inputs; if missing/ambiguous details exist, state explicit assumptions.\n- First decompose the goal/system into influential factors before proposing experiments.\n- For each factor, define one concrete experiment including:\n- Hypothesis\n- Independent variable(s)\n- Dependent variable(s)\n- Control and experimental groups (or justified alternative when groups are not applicable)\n- Measurement method(s) and success metric(s)\n- Confounding variables and mitigation controls\n- Ensure experiments are specific, feasible, and directly linked to `{{GOAL}}`.\n- If `{{EXPERIMENT_TEMPLATE}}` is provided, produce an adapted version that maps identified factors/experiments into that structure.\n- Avoid generic methods and unsupported claims.\n\nFORMAT\nReturn exactly this structure:\n\n<experiment_design>\n\n<factor_breakdown>\n[Numbered list of key factors, each with a brief explanation of why it may influence the goal in this system.]\n</factor_breakdown>\n\n<experiment_program>\n[For each factor, include:\n- Factor\n- Hypothesis\n- Independent variable(s)\n- Dependent variable(s)\n- Control group / baseline\n- Experimental group(s) / treatment(s)\n- Measurement method and timeline\n- Confounding variables and control plan\n- Expected decision rule (what result confirms/refutes hypothesis)]\n</experiment_program>\n\n<template_design>\n[If `{{EXPERIMENT_TEMPLATE}}` is provided, present the adapted experiment design using that template; otherwise write `No template provided.`]\n</template_design>\n\n<assumptions>\n[List explicit assumptions made due to unclear or missing inputs; write `None.` if no assumptions were required.]\n</assumptions>\n\n</experiment_design>\n\nFAILURE\n- Output misses required top-level tags or required experiment fields.\n- Factors are generic, not tied to `{{GOAL}}`/`{{SYSTEM}}`, or missing rationale.\n- Experiments lack testability (unclear variables, no control/baseline, no measurable outcomes).\n- Confounders are ignored or not controlled.\n- Template is provided but not used in `<template_design>`.\n- Assumptions are needed but not explicitly listed."
    },
    {
      "path": "Prompts/User Research/Startup ideas from user responses.md",
      "title": "Startup ideas from user responses",
      "category": "User Research",
      "tags": [
        "user-research",
        "ideation",
        "startup"
      ],
      "content": "INPUTS\n<provided_inputs>\n- `{{USER_RESPONSES}}`: User answers describing goals, workflow, pain points, constraints, and attempted solutions.\n</provided_inputs>\n\nGOAL\nGenerate startup software product ideas grounded in user responses and priced at clear bargain-value for approximately $30/month.\nSuccess metric:\n- Ideas directly map to concrete pains/opportunities in the provided responses.\n- Output includes exactly ten distinct ideas with clear value propositions.\n- Each idea is concise, specific, and formatted exactly as required.\n\nCONSTRAINTS\n- Use only `{{USER_RESPONSES}}`; if information is missing, state assumptions briefly before the ideas.\n- Analyze responses for:\n- User's overall goal.\n- Process steps and current stage.\n- Workflow location of the problem.\n- Time/money-heavy pain points.\n- Problem frequency.\n- Previously attempted solutions.\n- Propose only software product concepts (conceptual feasibility is acceptable).\n- Generate diverse ideas (avoid minor variants of the same concept).\n- Each idea must include:\n- A unique number.\n- A catchy product name.\n- A 40-80 word description.\n- Each description must explain how the idea reduces friction, time, cost, or risk in the user's workflow.\n\nFORMAT\nReturn exactly ten separate `<idea>` blocks in this pattern:\n\n<idea>\n[Number]. [Name]: [Description in 40-80 words]\n</idea>\n\nRules:\n- Numbering must run from `1` to `10` with no gaps or duplicates.\n- Each `<idea>` block must be a separate paragraph.\n\nFAILURE\n- Fewer or more than 10 ideas are returned.\n- Any idea is missing number, name, or description.\n- Any description is outside 40-80 words.\n- Ideas are generic, repetitive, or not grounded in `{{USER_RESPONSES}}`.\n- Output does not use the required `<idea>` block format.\n- Assumptions are needed but not explicitly stated."
    },
    {
      "path": "Prompts/User Research/Structured interview notes from transcript using flexible frameworks.md",
      "title": "Structured interview notes from transcript using flexible frameworks",
      "category": "User Research",
      "tags": [
        "user-research",
        "interviews",
        "transcripts"
      ],
      "content": "INPUTS\n<provided_inputs>\n- `{{INTERVIEW_TRANSCRIPT}}`: Source interview transcript.\n- `{{NOTE_TAKING_MODE}}`: One of `Chronological`, `Topical`, `AEIOU Framework`, `Empathy Map`.\n</provided_inputs>\n\nGOAL\nConvert interview transcripts into concise, evidence-grounded structured notes using a selected note-taking framework.\nSuccess metric:\n- Notes are concise, atomic, and traceable to transcript content.\n- Organization strictly follows the selected note-taking mode.\n- Output uses the required tagged structure and one-column table format.\n\nCONSTRAINTS\n- Use only provided inputs; if data is unclear, include explicit assumptions inside `<notes>` under an `Assumptions` subsection.\n- Output only final notes wrapped in `<notes>` tags.\n- Every note must:\n- Capture exactly one idea.\n- Be under 250 characters.\n- Be grounded in transcript evidence.\n- Use one-column markdown tables with clear category headers.\n- Apply mode-specific organization:\n- `Chronological`: single table ordered by transcript sequence.\n- `Topical`: separate tables by major themes.\n- `AEIOU Framework`: exactly five tables: Activities, Environments, Interactions, Objects, Users.\n- `Empathy Map`: exactly eight tables: Thinks, Feels, Says, Does, Sees, Hears, Pains, Goals.\n- If `{{NOTE_TAKING_MODE}}` is invalid or missing, default to `Topical` and record this in `Assumptions`.\n\nFORMAT\nReturn exactly this structure:\n\n<notes>\n[Mode label]\n\n[Category Header]\n| Note |\n| --- |\n| [One atomic note under 250 chars] |\n| [One atomic note under 250 chars] |\n\n[Repeat tables according to selected mode]\n\nAssumptions (only if needed)\n| Note |\n| --- |\n| [Explicit assumption due to missing/ambiguous data] |\n</notes>\n\nFAILURE\n- `<notes>` wrapper is missing or malformed.\n- Tables are missing, not one-column, unlabeled, or not aligned with selected/default mode.\n- Required mode categories are missing (AEIOU or Empathy Map).\n- Notes exceed 250 characters, combine multiple ideas, or are not transcript-grounded.\n- Output includes analysis/explanations outside structured notes.\n- Assumptions are needed but not explicitly listed."
    }
  ]
}
